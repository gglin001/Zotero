A Novel Mobile Phone Application for Pulse Pressure Variation Monitoring Based on Feature Extraction Technology: A Method Comparison Study in a Simulated Environment
Olivier Desebbe, MD,*† Alexandre Joosten, MD,‡ Koichi Suehiro, MD, PhD,§ Sari Lahham, BS,* Mfonobong Essiet, MS,* Joseph Rinehart, MD,* and Maxime Cannesson, MD, PhD¶

BACKGROUND: Pulse pressure variation (PPV) can be used to assess fluid status in the operating
room. This measurement, however, is time consuming when done manually and unreliable through
visual assessment. Moreover, its continuous monitoring requires the use of expensive devices.
Capstesia™ is a novel Android™/iOS™ application, which calculates PPV from a digital picture of
the arterial pressure waveform obtained from any monitor. The application identifies the peaks and
troughs of the arterial curve, determines maximum and minimum pulse pressures, and computes
PPV. In this study, we compared the accuracy of PPV generated with the smartphone application
Capstesia (PPVapp) against the reference method that is the manual determination of PPV (PPVman). METHODS: The Capstesia application was loaded onto a Samsung Galaxy S4TM phone. A physi-
ologic simulator including PPV was used to display arterial waveforms on a computer screen.
Data were obtained with different sweep speeds (6 and 12 mm/s) and randomly generated PPV
values (from 2% to 24%), pulse pressure (30, 45, and 60 mm Hg), heart rates (60–80 bpm),
and respiratory rates (10–15 breaths/min) on the simulator. Each metric was recorded 5 times
at an arterial height scale X1 (PPV5appX1) and 5 times at an arterial height scale X3 (PPV5appX3). Reproducibility of PPVapp and PPVman was determined from the 5 pictures of the same hemodynamic profile. The effect of sweep speed, arterial waveform scale (X1 or X3), and number of
images captured was assessed by a Bland-Altman analysis. The measurement error (ME) was
calculated for each pair of data. A receiver operating characteristic curve analysis determined
the ability of PPVapp to discriminate a PPVman > 13%. RESULTS: Four hundred eight pairs of PPVapp and PPVman were analyzed. The reproducibility of PPVapp and PPVman was 10% (interquartile range, 7%–14%) and 6% (interquartile range, 3%–10%), respectively, allowing a threshold ME of 12%. The overall mean bias for PPVappX1 was 1.1% within limits of −1.4% (95% confidence interval [CI], −1.7 to −1.1) to +3.5% (95% CI, +3.2
to +3.8). Averaging 5 values of PPVappX1 with a sweep speed of 12 mm/s resulted in the smallest bias (+0.6%) and the best limits of agreement (±1.3%). ME of PPVapp was <12% whenever 3, 4, or 5 pictures were taken to average PPVapp. The best predictive value for PPVapp to detect a PPVman > 13% was obtained for PPVappX1 by averaging 5 pictures showing a PPVapp threshold of 13.5% (95% CI, 12.9–15.2) and a receiver operating characteristic curve area of 0.989 (95%
CI, 0.963–0.998) with a sensitivity of 97% and a specificity of 94%.
CONCLUSIONS: Our findings show that the Capstesia PPV calculation is a dependable sub-
stitute for standard manual PPV determination in a highly controlled environment (simulator
study). Further studies are warranted to validate this mobile feature extraction technology to
predict fluid responsiveness in real conditions.  (Anesth Analg 2016;XXX:00–00)

Invasive arterial pulse pressure variation (PPV) is based on the cardiopulmonary interactions in mechanically ventilated patients under general anesthesia.1 In specific settings,2 PPV can predict fluid responsiveness (FR).3 Although various techniques can be used to measure PPV at the bedside without specialized monitoring devices, these techniques cannot discriminate between responders

and nonresponders to volume expansion.4 Moreover, visual determination of PPV is not reliable,5 and thus, PPV measurement requires manual calculation, a dedicated monitoring system, or additional devices. These approaches are often time consuming, not always available, and costly. A new Android™/ iOS™ application called Capstesia™ (GalenicApp, Vitoria, Spain), running on commercially

From the *Department of Anesthesiology, University of California at Irvine School of Medicine, Orange, California; †Department of Anesthesiology and Intensive Care, Clinique de la Sauvegarde, Lyon, France; ‡Department of Anesthesiology and Perioperative Care, CUB ERASME, Free University of Brussels, Brussels, Belgium; §Department of Anesthesiology and Perioperative Care, University of California Irvine, Orange, California; and ¶Department of Anesthesiology and Perioperative Medicine, David Geffen School of Medicine at UCLA, Los Angeles, California.
Koichi Suehiro, MD, PhD, is currently affiliated with the Department of Anesthesiology, Osaka City University Graduate School of Medicine, Osaka, Japan.
Copyright © 2016 International Anesthesia Research Society DOI: 10.1213/ANE.0000000000001282

Accepted for publication February 17, 2016.
Funding: None.
Conflict of Interest: See Disclosures at the end of the article.
Supplemental digital content is available for this article. Direct URL citations appear in the printed text and are provided in the HTML and PDF versions of this article on the journal’s website (www.anesthesia-­ analgesia.org).
Reprints will not be available from the authors.
Address correspondence to Olivier Desebbe, MD, Department of Anesthesiology and Intensive Care, Clinique de la Sauvegarde, 29 av des Sources, 69009 Lyon, France. Address e-mail to oldesebbe@yahoo.com.

XXX 2016 • Volume XXX • Number XXX

www.anesthesia-analgesia.org

1

Copyright © 2016 International Anesthesia Research Society. Unauthorized reproduction of this article is prohibited.

A Mobile Phone App for Pulse Pressure Variation Monitoring

available mobile phones, calculates PPV using a digital photograph of the arterial waveform displayed by any monitor. The application measures PPV (pulse pressure variation calculated by the Capstesia application [PPVapp]) by detecting peaks and troughs of the arterial curve, but it has not been tested against manual calculation of PPV (PPVman).
The goal of our study was to assess reproducibility, accuracy, and precision of PPVapp when compared with PPVman in a simulation environment by altering hemodynamic values, components of the arterial waveform (sweep speed and arterial scale), and the number of values to average the final PPVapp value.
METHODS Description of the Smart Phone Application Capstesia is a new smart phone application (version 1.1.1), functioning on iOS or Android. Launching this application displays the camera mode with a focus. The entire monitor screen is photographed, prompting a green box signal to crop the image including only the arterial pressure wave. The cropped picture of the arterial waveform is adjusted to exclude any other trace, and 10 arterial peaks are selected. The picture is then sent to proprietary software through WiFi, and the determination of PPV is generated by digitalization of the arterial waveform. Of note, the application’s PPV calculation does not require hemodynamic data. The result displays a PPV value (PPVapp). The corresponding file on the phone provides access to the screen picture and cropped image, and arterial pressure waveform (Fig. 1). This scan displays circles placed on peak values and arrows placed on minimal arterial values. Figure 2 represents the different steps required to obtain a PPVapp value (Supplemental Digital Content, Video, http://links.lww. com/AA/B412).
Description of the PPV Generated by the Hemodynamic Simulator The arterial waveforms were displayed by a hemodynamic simulator on a computer screen (Dell™, Round Rock, TX). This simulator has been described elsewhere6,7 and was previously used as a reference for visual estimation.8 The display mode allows setting of the following hemodynamic values: systolic and diastolic arterial pressure (SAP and DAP, respectively), heart rate (HR), central venous pressure, systolic and diastolic pulmonary pressure, respiratory rate (RR), tidal volume, and PPV. Briefly, the waveform PPV appearance is generated in 3 steps. First, the length of the respiratory cycle is determined (equal to 60/RR) in seconds. Once the cycle length is known, a sine wave is extrapolated over the length of the cycle going from 0 to 1 and back. The sine value at any point on the wave is subtracted from 1, and this value is multiplied by the percent PPV output by the simulator, and the waveform height at that point is reduced by the resulting proportion, creating systolic pressure variation. Finally, the baseline of the waveform is modulated in the same way, but at only 20% of the height effect. The net modifications result in a smooth graphical waveform that, when measured, yielded the PPV dictated by the simulator.
The arterial waveform in the display mode is specifically dependent on the following variable settings: SAP, DAP,

HR, RR, and PPV. The sweep speed and scale of the arterial pressure waveform can also be adjusted. Because the arterial waveform is generated by the simulator software, there is no time variability of the waveform shape. A sample screen from the hemodynamic simulator is presented in Appendix 1.

Study Protocol The study protocol was devised to assess the repeatability, accuracy, and precision of PPVapp compared with PPVman. The smart phone was fastened to a tripod at a fixed distance from the simulator screen (0.6 m). A Samsung Galaxy S4™ (Daegu, South Korea) with Android version 4.4.2, and a camera resolution of 13 megapixels was used. Luminosity of 105 lux was maintained throughout the experiment without use of the camera zoom function. A Dell monitor (dimensions: 14.5 inches width × 12 inches height) displayed hemodynamic data from the simulator. Twenty-four series of measurements in 17 values of PPV predefined by the simulator were tested (2%, 4%, 5%, 7%, 8%, 9%, 10%, 11%, 12%, 13%, 14%, 15%, 16%, 17%, 19%, 21%, and 24%). For each series, some combination of the following hemodynamic variables and arterial waveforms was set on the simulator: SAP value (90 or 120 mm Hg), DAP value (45 or 60 mm Hg), HR value (60 or 80 bpm), RR value (10 or 15 per minute), sweep speed of the arterial waveform (6 or 12 mm/s, to obtain at least 10 arterial peaks on the computer screen), and height of arterial waveform (nonoptimized scale [1X] or optimized scale [3X]).
Nonoptimized (PPVappX1) and optimized scale PPVapp (PPVappX3) were recorded as either 1 reading (PPV1app) or the average of 2, 3, 4, or 5 values (PPV5app) within the same hemodynamic profile. The number of attempts required to obtain an acceptable PPVapp value (defined as a scan showing circles placed on peak values and arrows placed on minimal arterial values) and the time (for the first 200 PPVapp determinations) between the snapshot and the displayed value for each specific hemodynamic combination were also recorded. PPVman values were considered the reference method against PPVapp. PPVman was calculated by measuring the amplitude of the maximum and the minimum pulse pressures during a respiratory cycle on the screen capture from the monitor immediately after the photograph was taken to generate the PPVapp. Therefore, 1 PPVman was calculated for each PPVapp. For example, PPVman was calculated 5 times for PPV5app. This calculation was done off-line by an observer blinded to the results of PPVapp (AJ).

Statistical Analyses Distributions of values were evaluated by a KolmogorovSmirnov test. Values were expressed in mean (± SD) or median (interquartile range) according to their distribution.

Repeatability of PPVapp and PPVman Repeatability was assessed as precision error, measured by
calculating the variation of 5 PPV values within the same
hemodynamic profile. Precision error (%) at each time point
was calculated using:

Precision

error

=

1.96

×

CV n

,(1)

2   www.anesthesia-analgesia.org

anesthesia & analgesia

Copyright © 2016 International Anesthesia Research Society. Unauthorized reproduction of this article is prohibited.

  

Figure 1. Two examples of pictures digitalized by the Capstesia. A, Sweep speed 12 mm/s; arterial waveform scale X1. B, Sweep speed 6 mm/s; arterial waveform scale X3. PPV = 24%; SAP = 90 mm Hg; DAP = 60 mm Hg; HR = 80 bpm; RR = 10 breaths/min. Notes: The arterial waveform pictured has been obtained after an initial focus of a screen image. The automated scan identifies peaks (circles) and troughs (crosses) to generate a pulse pressure variation (PPV) value. These 2 pictures have been obtained with a predefined PPV displayed by the simulator of 24%. Note that a low definition of the arterial waveform (sweep speed 6, scale X3) of the simulator can drive an erroneous PPVapp value. DAP = diastolic arterial pressure; HR = heart rate; RR = respiratory rate; PPV = pulse pressure variation; SAP = systolic arterial pressure.

where CV is the coefficient of variation of each measurement (CV = SD ) and n is the number of replications kept
Mean for each measurement.9 To evaluate the maximal variation of PPVapp and PPVman (i.e., the maximal change because of random error with a probability of 95%), we calculated the least significant changes of PPV proposed by Cecconi et al.,9 where
LSC(%) = Precision error × 2.
Mean and SD or median and interquartile range of precision error and least significant changes were then calculated according to the mean values of each time plot.
Agreement and Responsiveness The agreement between the measurements obtained with PPVapp and those obtained with PPVman was determined using the coefficient of determination (R2) and the BlandAltman method.10 If the mean difference between PPVman and PPVapp (bias) was normally distributed, the mean bias and limits of agreement (LOA; 1.96 × SD of the bias) were calculated.11 In addition, the measurement error (ME) was computed for each set of data as follows12:
ME = PPVapp -PPVman × 100. 0.5*(PPVapp+PPVman )
This calculation of ME is possible regardless of the distribution of the bias (PPVapp − PPVman), and ME is also impacted by the range of mean PPV [(PPVapp + PPVman) × 0.5].13 Distribution of the ME was expressed in median (95% confidence interval [CI]). Because the ME depends on the precision of each technique,9 we calculated a posteriori the threshold ME value to accept a good agreement between PPVapp and PPVman according to the formula13:

Upper limit of the 95% CI of ME (2)
< Precision PPVm2an + precision PPVa2pp.
ME was calculated for each component of PPVapp: scale optimization (X1 or X3), number of PPVapp values averaged (mean of 2, 3, 4, or 5 PPVapp values), and sweep speed (6 or 12 mm/s). In addition, the relationship between PPVman and ME was assessed with the coefficient of determination R2.
Ability of PPVapp to Discriminate a PPVman > 13% To assess the ability of PPVapp to identify a PPVman > 13%, receiver operating characteristic (ROC) curves were generated. The areas under the ROC curves were calculated for 3 different components of determining PPVapp (scale, sweep speed, and average) and compared as described previously.14 The Youden Index was determined for each ROC curve (the maximum difference between sensitivity and 1 − specificity).15 Ninety-five percent CI of the threshold PPVapp value was considered the gray zone.16
Sample Size Estimation Because the precision of each PPV calculation (PPVman and PPVapp) was unknown before performing the experiment, we estimated a precision error of 20% (Equation 1) for both PPV calculations for sample size determination. Therefore, an acceptable ME would have an upper limit of the 95% CI of 28% according to the Equation 2. Considering a potential large distribution of the ME (SD of 25%) and a mean ME of 20%, we needed to compare 41 pairs of data by subgroup analyses (sweep speed, height of scale) according to the following calculation:
Upper limit of the 95% CI of the ME
= 0.28 = ME + 1.96 × SD , √n

XXX 2016 • Volume XXX • Number XXX

www.anesthesia-analgesia.org  3

Copyright © 2016 International Anesthesia Research Society. Unauthorized reproduction of this article is prohibited.

A Mobile Phone App for Pulse Pressure Variation Monitoring

Figure 2. Steps to obtain a PPVapp value. PPVapp = pulse pressure variation calculated by the Capstesia™ application.

where n is the number of data pairs, ME is the expected mean value of the ME, and SD is the standard deviation of the ME. Because PPVapp was also averaged from 5 values, we needed at least 205 pictures by subgroup analyses.
All analyses were performed using MedCalc Statistical Software version 14.8.1 (MedCalc® Software bvba, Ostend, Belgium). P < 0.05 was considered as significant.
RESULTS Two thousand one hundred pictures were recorded, of which 60 (3%) were excluded because of scan process error in the application. Eight hundred sixteen pairs of data (PPVapp versus PPVman) were ultimately evaluated.
The median time to obtain a PPVapp value in the app was 24 seconds (21–28 seconds). Figure 3 describes the number of PPVapp values according to the setting of the simulator. Precision error of PPVapp and PPVman was 10% (7%–14%) and 6% (3%–10%), respectively (Table 1). An acceptable threshold value for ME between PPVapp and PPVman was then calculated at 12%. Mean values of PPVapp and coefficient of determination between PPVapp and PPVman are presented in Table 2. Distribution of PPVappX3 bias was not normally distributed. Figure 4 displays Bland-Altman analysis for 1 value (Fig. 4A) and for 5 averaged values (Fig. 4B) of PPVapp at scale X1. The least ME was obtained with a sweep speed of 12 mm/s and the average of 5 values (ME = 6%; 95% CI, 5–10; Table 2). Upper limit of 95% CI of ME was <12% when 3, 4, or 5 pictures were obtained to average PPVapp (Appendix 2) at scale X1. There was a significant relationship between ME and PPVman (R2 = 0.38, P < 0.001; Fig. 5). Areas under ROC curves for each type of PPVapp are presented in Appendix 3. The greatest area was obtained with PPV5appX1.

DISCUSSION The main finding of this pilot study is that, in a highly controlled environment, PPVapp shows an acceptable accuracy with PPVman when at least 3 pictures are taken to average PPVapp at scale X1 (upper limit of the 95% CI of the ME <12%). The best accuracy is obtained with a sweep speed of 12 mm/s with 5 averaged PPVapp. Second, with a low rate of unsuccessful scan process (3%) and a short period of time to obtain a PPV value (24 seconds), PPVapp determination is feasible. Finally, a PPVapp threshold of 13.5% (gray zone, 12.9%–15.2%) is potentially able to discriminate FR (PPVman > 13%).
Cardiac output (CO) optimization has the potential to decrease postoperative complications17; however, CO measurement lacks reliability and is expensive.18 By predicting FR, PPV is an acceptable surrogate for CO optimization.19 Therefore, the promise of an easy-to-use pocket application capable of guiding fluid therapy is valuable. Also, by providing other advanced hemodynamic variables (CO and inotropy), this application questions the need to buy supplemental equipment for advanced monitoring. However, the accuracy of these advanced hemodynamic variables was not evaluated in this study. More generally, feature extraction technologies are becoming readily available in health care delivery and could soon be an essential tool for the anesthesiologist.20–22
Nevertheless, PPVapp determination requires a WiIFi connection, and the picture needs careful attention: avoiding light glares, holding the smart phone parallel to the screen (otherwise at risk of disturbing the ratio between maximal and minimal pulse pressure), and preventing image obstruction by other artifacts in the selected box. A confirmatory visualization of the processed scan

4   www.anesthesia-analgesia.org

anesthesia & analgesia

Copyright © 2016 International Anesthesia Research Society. Unauthorized reproduction of this article is prohibited.

  

Figure 3. Flowchart of the study protocol. Notes: The first picture obtained by the Capstesia™ application was kept to calculate PPV1app. Five successive pictures of the screen displaying the same hemodynamic variables were averaged to calculate PPV5app (1020 pictures). Note that the PPVapp value obtained by the first picture to calculate PPV1app was also averaged with the 4 following values to calculate PPV5app. Not shown is that PPVman was calculated 2040 times, at the time of each PPVapp determination, by manually measuring the amplitude of the maximum
and the minimum pulse pressures during a respiratory cycle on a corresponding screen capture. PPVapp = pulse pressure variation calculated by the Capstesia application; PPV1appX1 = pulse pressure variation displayed by the smart phone application from 1 value at scale X1; PPV5appX1 = average of 5 pulse pressure variation values displayed by the smart phone application at scale X1; PPV1appX3 = pulse pressure variation displayed by the smart phone application from 1 value at scale X3; PPV5appX3 = average of 5 pulse pressure variation values displayed by the smart phone application at scale X3.

Table 1.  Random Error (Reproducibility) of PPVapp Measurement

PPV5appX1

PPV5appX3

PPVman

Coefficient of variation (%)

11 (8–16) 11 (7–22) 7 (4–11)

Precision error (%)

10 (7–14) 10 (6–19) 6 (3–10)

Least significant change (%) 14 (9–20) 13 (8–27) 9 (4–14)

Data are presented as median (interquartile range). Precision error = 1.96 × (coefficient of variation/√n); least significant change = precision error × √2 (95% confidence interval of the precision). The coefficient of variation (CV = SD/mean) was determined for each hemodynamic combination and n was the number of replications, 5 in our experiment; the precision error was <20%.
PPVapp = pulse pressure variation calculated by the Capstesia™ application; PPV5appX1 = average of 5 pulse pressure variation values displayed by the smart phone application at scale X1; PPV5appX3 = average of 5 pulse pressure variation values displayed by the smart phone application at scale X3; PPVman = manual determination of pulse pressure variation.

also ensures that there is no misinterpreted or erroneous data (Fig. 2). Contrary to our assumptions, increasing the scale and decreasing the sweep speed worsened the LOA. These 2 modifications may have decreased the contrast between red pixels (representing the arterial waveform) and the black screen and also decreased the definition of the waveform. It may, consequently, have altered the scan process. Averaging the number of PPVapp values increased the accuracy of the application, consistent with a study demonstrating that determinations of PPV averaged on 3 respiratory cycles were better than 1.23 Particularly, it has recently been shown that the ability to predict FR depends

on the period of averaging the PPV, a greater interval worsening the results.4
In a 1999 meta-analysis, on CO measurement, Critchley and Critchley13 introduced the notion of percentage error (PE) to propose an acceptable threshold derived from the LOA of the Bland-Altman analysis. The PE is based on the 95% confidence interval of the bias and on the mean CO (of both methods) of each data set. This value is, therefore, calculated after all the comparisons have been made. It provides a rough estimate against which other clinical study results can be compared at a level that most clinicians can use. However, PE presents some intrinsic limits. First, PE does not consider the range of CO.24 Second, PE is based on LOA, thus considering that the bias between the 2 assessed methods is normally distributed. Notably, numerous recent method comparison studies did not test the distribution of the bias, with a risk of using inappropriate statistical tools (LOA, 95% CI, PE).25–27 Finally, PE is a value with no dispersion dimension. To overcome these 3 limits (consider the range of CO, nonnormal distribution of the bias, dispersion of the error measurement between 2 techniques), we calculated the ME that is based on each individual set of data, used in 199212 and also described in metaanalysis by Critchley and Critchley.13 Noteworthy is the citation stating that one should calculate the “percentage error for each set of data rather than calculating a single percentage error from the averaged data.”13 Interestingly,

XXX 2016 • Volume XXX • Number XXX

www.anesthesia-analgesia.org  5

Copyright © 2016 International Anesthesia Research Society. Unauthorized reproduction of this article is prohibited.

A Mobile Phone App for Pulse Pressure Variation Monitoring

Table 2.  Method Comparison Evaluation Between PPVman and PPVapp

Coefficient of Bias (%),

Median or

determination mean or SD or IR of

mean (%) SD or IR

(R2)

median

the bias

PPVman (n = 204) PPV1appX1 (n = 204)

12.9

7.4; 17.0

13.8

8.8; 18.5

0.92

1.2

1.9

PPV1appX3 (n = 204) PPV5appX1 (n = 204)

14.3 13.8

9.1; 19.5 8.7; 18.3

0.72 0.96

1.3

−0.1; 2.5

1.1

1.3

PPV5appX3 (n = 204) PPV5appX1 (sweep speed = 6
mm/s; n = 51)
PPV5appX1 (sweep speed = 12 mm/s; n = 51)

14.2 14.1
13.7

9.4; 19.4 6.7
6.7

0.90 0.96
0.97

1.2

0.4; 2.5

1.1

1.5

0.6

1.1

Limits of agreement, % (95% CI) of the bias
−2.6 (−2.1 to −3.0) +5.0 (+4.5 to +5.4)
−1.4 (−1.7 to −1.1) +3.5 (+3.2 to +3.8)
−1.9 (−2.6 to −1.2) +3.9 (+3.2 to +4.7) −1.6 (−2.1 to −1.0) +2.8 (+2.3 to +3.4)

Measurement of error, % (95% CI)
13 (11 to 15)
12 (11 to 14) 9 (7 to 10)
11 (9 to 14) 10 (5 to 14)
7 (5 to 10)*

All the coefficients of determination were statistically significant (P < 0.001). The bias is the mean difference between PPVman and PPVapp. PPVapp values with scale X3 were not normally distributed. The ME was calculated for each pair of data (ME = difference of PPVapp and PPVman/ mean of PPVapp and PPVman); SD of the ME ranged from 19% for PPV5appX1, 23% for PPV5appX3 and PPV1appX1, and 25% for PPV1appX3.
CI = confidence interval; IR = interquartile range; ME = measurement error; PPVapp = pulse pressure variation calculated by the Capstesia™ application; PPV1appX1 = pulse pressure variation displayed by the smart phone application from 1 value at scale X1; PPV5appX1 = average of 5 pulse pressure variation values displayed by the smart phone application at scale X1; PPV1appX3 = pulse pressure variation displayed by the smart phone application from 1 value at scale X3; PPV5appX3 = average of 5 pulse pressure variation values displayed by the smart phone application at scale X3; PPVman = manual determination of PPV.
*P = 0.036 compared with PPV5appX1 at sweep speed 6 mm/s.

Figure 4. Bland-Altman plots showing the accuracy and the agreement between PPV1appX1 and PPVman (A) and between PPV5appX1 and PPVman (B). PPV1appX1 = pulse pressure variation displayed by the smart phone application from 1 value at scale X1; PPV5appX1 = average of 5 pulse pressure variation values displayed by the smart phone application at scale X1; PPVman = manual determination of pulse pressure variation.

the ME depends on the value of PPVman (Fig. 5), indicating that unacceptable high ME values involved low PPVman values, wherein its exact value has limited clinical relevance. It has also been proposed that the LOA be defined a priori.28 However, the LOA and the ME depend on the precision error of both methods. Therefore, if precision error of each technique can be quantified, the interchangeability of 2 methods should be accepted if the 95% CI of the ME are equal to or less than the square root of both square precision techniques [√(precision PPVman2+precision PPVapp2)].13
LIMITATIONS OF THE STUDY We tested PPVapp in an ideal simulation environment. The arterial waveform displayed by the simulator is consistent over time, without the effect of other physiologic variables (sympathetic tone, HR variability).29 We did

not choose the PPV displayed by the simulator (PPVsim) as the reference method for 2 main reasons. First, PPVsim has never been validated. Second, the PPVsim is determined according to a 20% variation between the height and the bottom of the arterial waveform; therefore, it can differ according to the dimensions of the screen on which it is displayed or according to the height of the arterial scale. To avoid any confounding bias between the generated PPVsim and the one actually displayed, recalculating PPVman for each displayed screenshot allowed us to achieve a robust comparison. However, as PPVman was calculated within 1 respiratory cycle, we did not specifically select 10 heart beats contrary to the determination of PPVapp. These differences in the generation of PPVman and PPVapp may have altered the agreement between both PPV determinations. Accordingly, PPVapp manufacturers recommend selection of only 7 to 8 peaks to avoid the

6   www.anesthesia-analgesia.org

anesthesia & analgesia

Copyright © 2016 International Anesthesia Research Society. Unauthorized reproduction of this article is prohibited.

  

pollution by low arterial frequencies, which could alter the peak and the trough arterial values. Furthermore, PPV applicability may vary in an operating room environment where light reflection is greater, and the conditions of use are not respected (smart phone parallel to the screen for instance). Finally, other computer monitors may produce different results because of variability in definition and resolution.

Figure 5. Relationship between the measurement of error of PPV5appX1 and the PPVman. Note: For clinical decision making (PPVman > 9%), only 5% (8/166) of data pairs presented a measurement error >20%. ME = mea-
surement error; PPV5appX1 = average of 5 pulse pressure variation values displayed by the smart phone application at scale X1; PPVman = manual determination of pulse pressure variation.

CONCLUSIONS With a low precision error and accurate LOA compared with manual PPV, PPVapp could predict FR. We demonstrated that an arterial scale of 1X combined with an average of at least 3 pictures of the same screen were the best conditions for obtaining a valuable PPVapp, especially for a sweep speed of 12 mm/s. Nonetheless, real conditions are warranted to test this application with these settings.
Testing PPVapp during general anesthesia and test FR is the next step to validate this tool before its wider use can be
recommended. E

Appendix 1

Example of a Screen Displaying a PPV Value of 16%

Notes: The sweep speed is 12 mm/s, allowing to crop 10 peaks to determine the PPVapp. PPVapp = pulse pressure variation calculated by the Capstesia application.

Appendix 2.  Relationship Between PPVman and PPVapp According to the Number of Averaged Values (1, 2, 3, 4, or 5 Pictures), with a 1X Arterial Scale

Median (%)

IR (%)

Coefficient of determination (R2) Bias (%) SD (%)

Limits of agreement, % (95% CI)

Measurement error, % (95% CI)

PPVman PPV1app (n = 204)
PPV2app (n = 204)
PPV3app (n = 204)

12.9 13.8
13.9
13.9

7.4 to 17.0 8.8 to 18.5
8.7 to 18.6
8.7 to 18.4

0.92 0.96 0.96

1.2

1.9 −2.6 (−2.1 to −3.0)

5.0 (4.5 to 5.4)

1.2

1.4 −1.7 (−2.0 to −1.3)

4.0 (3.6 to 4.3)

1.1

1.4 −1.6 (−1.9 to −1.3)

3.7 (3.4 to 4.0)

13 (11 to 15) 11 (9 to 13) 10 (8 to 12)

PPV4app (n = 204)

13.8

8.8 to 18.3

0.96

1.1

1.3 −1.5 (−1.8 to −1.2)

3.6 (3.3 to 3.9)

9 (8 to 11)

PPV5app (n = 204)

13.8

8.7 to 18.3

0.96

1.1

1.3 −1.4 (−1.7 to −1.1)

3.5 (3.2 to 3.8)

9 (7 to 10)

All the coefficients of determination were statistically significant (P < 0.001). The bias is the mean difference between PPVman and PPVapp values, and it was normally distributed. The limits of agreement are calculated as 1.96 × SD of the bias; upper and lower limits of agreement are presented with the 95% CI. The
upper limit of 95% CI of the ME was ≤12% for 3, 4, or 5 averaged value of PPVappX1, showing an acceptable accuracy against PPVman.
CI = confidence interval; IR = interquartile range; PPVapp = PPV displayed by the smartphone application; mean of 2 (PPV2app), 3 (PPV3app), 4 (PPV4app), and 5 (PPV5app) pulse pressure variations values (arterial scale X1) calculated by the smartphone application per hemodynamic combination; n = numbers of PPV values obtained; PPVman = manual determination of PPV.

XXX 2016 • Volume XXX • Number XXX

www.anesthesia-analgesia.org  7

Copyright © 2016 International Anesthesia Research Society. Unauthorized reproduction of this article is prohibited.

A Mobile Phone App for Pulse Pressure Variation Monitoring

Appendix 3 ROC Curves Comparing the Ability of PPVapp to Discriminate Between PPVman Under or Upper 13%
CI = confidence interval; PPVapp = pulse pressure variation calculated by the Capstesia™ application; PPV1appX1 = pulse pressure variation displayed by the smart phone application from 1 value at scale X1; PPV5appX1 = average of 5 pulse pressure variation values displayed by the smartphone application at scale X1; PPV1appX3 = pulse pressure variation displayed by the smart phone application from 1 value at scale X3; PPV5appX3 = average of 5 pulse pressure variation values displayed by the smartphone application at scale X3; ROC = receiver operating characteristic curve. DISCLOSURES Name: Olivier Desebbe, MD. Contribution: This author was the first author and helped design the study, conduct the study, data collection, data analysis, and manuscript preparation. Attestation: Olivier Desebbe approved the final manuscript, attests to the integrity of the original data and the analysis reported in this manuscript, and is the archival author. Conflicts of Interest: Olivier Desebbe declares no conflicts of interest. Name: Alexandre Joosten, MD. Contribution: This author helped design the study, conduct the study, data collection, data analysis, and manuscript preparation. Attestation: Alexandre Joosten approved the final manuscript and attests to the integrity of the original data and the analysis reported in this manuscript. Conflicts of Interest: Alexandre Joosten is a consultant for Edwards Lifesciences™. Name: Koichi Suehiro, MD, PhD. Contribution: This author helped design the study, conduct the study, analyze the data, and write the manuscript.

Attestation: Koichi Suehiro has seen the original study data, reviewed the analysis of the data, approved the final manuscript, and is the author responsible for archiving the study files. Conflicts of Interest: Koichi Suehiro declares no conflicts of interest. Name: Sari Lahham, BS. Contribution: This author helped conduct the study and write the manuscript. Attestation: Sari Lahham approved the final manuscript. Conflicts of Interest: Sari Lahham declares no conflicts of interest. Name: Mfonobong Essiet, MS. Contribution: This author helped conduct the study and write the manuscript. Attestation: Mfonobong Essiet approved the final manuscript. Conflicts of Interest: Mfonobong Essiet declares no conflicts of interest. Name: Joseph Rinehart, MD. Contribution: This author helped conduct the study and write the manuscript. Attestation: Joseph Rinehart approved the final manuscript. Conflicts of Interest: Joseph Rinehart has an ownership interest in Sironis™ and is a consultant for Edwards Lifesciences™. Name: Maxime Cannesson, MD, PhD. Contribution: This author helped conduct the study and write the manuscript. Attestation: Maxime Cannesson approved the final manuscript. Conflicts of Interest: Maxime Cannesson is a consultant for Masimo™, Edwards Lifesciences™, and Covidien™. He is has an ownership interest in Sironis™ and Gauss Surgical™. He benefits research funding from Masimo™ and Edwards™. The Galenic App Company distributed to this author the Capstesia™ application without control concerning its use, implementation, or conduction, and results of this study.
RECUSE NOTE Dr. Maxime Cannesson is the Section Editor for Technology, Computing, and Simulation for Anesthesia & Analgesia. This manuscript was handled by Dr. Steven L. Shafer, Editor-inChief, and Dr. Cannesson was not involved in any way with the editorial process or decision.
REFERENCES
1. Michard F, Boussat S, Chemla D, Anguel N, Mercat A, Lecarpentier Y, Richard C, Pinsky MR, Teboul JL. Relation between respiratory changes in arterial pulse pressure and fluid responsiveness in septic patients with acute circulatory failure. Am J Respir Crit Care Med 2000;162:134–8
2. Maguire S, Rinehart J, Vakharia S, Cannesson M. Technical communication: respiratory variation in pulse pressure and plethysmographic waveforms: intraoperative applicability in a North American academic center. Anesth Analg 2011;112:94–6
3. Yang X, Du B. Does pulse pressure variation predict fluid responsiveness in critically ill patients? A systematic review and meta-analysis. Crit Care 2014;18:650
4. Lansdorp B, Lemson J, van Putten MJ, de Keijzer A, van der Hoeven JG, Pickkers P. Dynamic indices do not predict volume responsiveness in routine clinical practice. Br J Anaesth 2012;108:395–401
5. Cannesson M, Le Manach Y, Hofer CK, Goarin JP, Lehot JJ, Vallet B, Tavernier B. Assessing the diagnostic accuracy of pulse pressure variations for the prediction of fluid responsiveness: a “gray zone” approach. Anesthesiology 2011;115:231–41
6. Rinehart J, Alexander B, Le Manach Y, Hofer C, Tavernier B, Kain ZN, Cannesson M. Evaluation of a novel closed-loop fluid-administration system based on dynamic predictors of

8   www.anesthesia-analgesia.org

anesthesia & analgesia

Copyright © 2016 International Anesthesia Research Society. Unauthorized reproduction of this article is prohibited.

  

fluid responsiveness: an in silico simulation study. Crit Care 2011;15:R278 7. Rinehart J, Lee C, Cannesson M, Dumont G. Closed-loop fluid resuscitation: robustness against weight and cardiac contractility variations. Anesth Analg 2013;117:1110–8 8. Rinehart J, Islam T, Boud R, Nguyen A, Alexander B, Canales C, Cannesson M. Visual estimation of pulse pressure variation is not reliable: a randomized simulation study. J Clin Monit Comput 2012;26:191–6 9. Cecconi M, Rhodes A, Poloniecki J, Della Rocca G, Grounds RM. Bench-to-bedside review: the importance of the precision of the reference technique in method comparison studies—with specific reference to the measurement of cardiac output. Crit Care 2009;13:201 10. Bland JM, Altman DG. Statistical methods for assessing agreement between two methods of clinical measurement. Lancet 1986;1:307–10 11. Bland JM, Altman DG. Agreement between methods of measurement with multiple observations per individual. J Biopharm Stat 2007;17:571–82 12. Shoemaker WC, Wo CC, Bishop MH, Appel PL, Van de Water JM, Harrington GR, Wang X, Patil RS. Multicenter trial of a new thoracic electrical bioimpedance device for cardiac output estimation. Crit Care Med 1994;22:1907–12 13. Critchley LA, Critchley JA. A meta-analysis of studies using bias and precision statistics to compare cardiac output measurement techniques. J Clin Monit Comput 1999;15:85–91 14. Hanley JA, McNeil BJ. A method of comparing the areas under receiver operating characteristic curves derived from the same cases. Radiology 1983;148:839–43 15. Youden WJ. Index for rating diagnostic tests. Cancer 1950;3:32–5 16. Cannesson M, Aboy M, Hofer CK, Rehman M. Pulse pressure variation: where are we today? J Clin Monit Comput 2011;25:45–56 17. Pearse RM, Harrison DA, MacDonald N, Gillies MA, Blunt M, Ackland G, Grocott MP, Ahern A, Griggs K, Scott R, Hinds C, Rowan K; OPTIMISE Study Group. Effect of a perioperative, cardiac output-guided hemodynamic therapy algorithm on outcomes following major gastrointestinal surgery: a randomized clinical trial and systematic review. JAMA 2014;311:2181–90 18. Peyton PJ, Chong SW. Minimally invasive measurement of cardiac output during surgery and critical care: a meta-analysis of accuracy and precision. Anesthesiology 2010;113:1220–35

19. Cannesson M. Arterial pressure variation and goal-directed fluid therapy. J Cardiothorac Vasc Anesth 2010;24:487–97
20. Konig G, Holmes AA, Garcia R, Mendoza JM, Javidroozi M, Satish S, Waters JH. In vitro evaluation of a novel system for monitoring surgical hemoglobin loss. Anesth Analg 2014;119:595–600
21. Pronovost PJ, Bo-Linn GW, Sapirstein A. From heroism to safe design: leveraging technology. Anesthesiology 2014;120:526–9
22. Cannesson M, Tanabe M, Suffoletto MS, McNamara DM, Madan S, Lacomis JM, Gorcsan J III. A novel two-dimensional echocardiographic image analysis system using artificial intelligence-learned pattern recognition for rapid automated ejection fraction. J Am Coll Cardiol 2007;49:217–26
23. Kim HK, Pinsky MR. Effect of tidal volume, sampling duration, and cardiac contractility on pulse pressure and stroke volume variation during positive-pressure ventilation. Crit Care Med 2008;36:2858–62
24. Preiss D, Fisher J. A measure of confidence in Bland-Altman analysis for the interchangeability of two methods of measurement. J Clin Monit Comput 2008;22:257–9
25. Yamada T, Tsutsui M, Sugo Y, Sato T, Akazawa T, Sato N, Yamashita K, Ishihara H, Takeda J. Multicenter study verifying a method of noninvasive continuous cardiac output measurement using pulse wave transit time: a comparison with intermittent bolus thermodilution cardiac output. Anesth Analg 2012;115:82–7
26. Bubenek-Turconi SI, Craciun M, Miclea I, Perel A. Noninvasive continuous cardiac output by the Nexfin before and after preload-modifying maneuvers: a comparison with intermittent thermodilution cardiac output. Anesth Analg 2013;117:366–72
27. Wagner JY, Sarwari H, Schön G, Kubik M, Kluge S, Reichenspurner H, Reuter DA, Saugel B. Radial artery applanation tonometry for continuous noninvasive cardiac output measurement: a comparison with intermittent pulmonary artery thermodilution in patients after cardiothoracic surgery. Crit Care Med 2015;43:1423–8
28. Mantha S, Roizen MF, Fleisher LA, Thisted R, Foss J. Comparing methods of clinical measurement: reporting standards for Bland and Altman analysis. Anesth Analg 2000;90:593–602
29. Akselrod S, Gordon D, Ubel FA, Shannon DC, Berger AC, Cohen RJ. Power spectrum analysis of heart rate fluctuation: a quantitative probe of beat-to-beat cardiovascular control. Science 1981;213:220–2

XXX 2016 • Volume XXX • Number XXX

www.anesthesia-analgesia.org  9

Copyright © 2016 International Anesthesia Research Society. Unauthorized reproduction of this article is prohibited.

