Deep Learning Innovations and Their Convergence With Big Data
S. Karthik SNS College of Technology, Anna University, India Anand Paul Kyungpook National University, South Korea N. Karthikeyan Mizan-Tepi University, Ethiopia
A volume in the Advances in Data Mining and Database Management (ADMDM) Book Series

Published in the United States of America by IGI Global Information Science Reference (an imprint of IGI Global) 701 E. Chocolate Avenue Hershey PA, USA 17033 Tel: 717-533-8845 Fax: 717-533-8661 E-mail: cust@igi-global.com Web site: http://www.igi-global.com

Copyright © 2018 by IGI Global. All rights reserved. No part of this publication may be reproduced, stored or distributed in any form or by any means, electronic or mechanical, including photocopying, without written permission from the publisher. Product or company names used in this set are for identification purposes only. Inclusion of the names of the products or companies does not indicate a claim of ownership by IGI Global of the trademark or registered trademark.

			

Library of Congress Cataloging-in-Publication Data

Names: Karthik, S., 1977- editor. | Paul, Anand, editor. | Karthikeyan, N., 1977- editor.
Title: Deep learning innovations and their convergence with big data / S. Karthik, Anand Paul, and N. Karthikeyan, editors.
Description: Hershey, PA : Information Science Reference, [2018] | Includes bibliographical references.
Identifiers: LCCN 2017011947| ISBN 9781522530152 (hardcover) | ISBN 9781522530169 (ebook)
Subjects: LCSH: Machine learning--Technological innovations. | Big data. Classification: LCC Q325.5 .D44 2018 | DDC 006.3/1--dc23 LC record available at https://lccn.loc. gov/2017011947

This book is published in the IGI Global book series Advances in Data Mining and Database Management (ADMDM) (ISSN: 2327-1981; eISSN: 2327-199X)

British Cataloguing in Publication Data A Cataloguing in Publication record for this book is available from the British Library.
All work contributed to this book is new, previously-unpublished material. The views expressed in this book are those of the authors, but not necessarily of the publisher.
For electronic access to this publication, please contact: eresources@igi-global.com.

Advances in Data Mining and Database Management
(ADMDM) Book Series
ISSN:2327-1981 EISSN:2327-199X

Editor-in-Chief: David Taniar, Monash University, Australia
Mission
With the large amounts of information available to organizations in today’s digital world, there is a need for continual research surrounding emerging methods and tools for collecting, analyzing, and storing data.
The Advances in Data Mining & Database Management (ADMDM) series aims to bring together research in information retrieval, data analysis, data warehousing, and related areas in order to become an ideal resource for those working and studying in these fields. IT professionals, software engineers, academicians and upper-level students will find titles within the ADMDM book series particularly useful for staying up-to-date on emerging research, theories, and applications in the fields of data mining and database management.

Coverage

• Factor Analysis • Association Rule Learning • Heterogeneous and Distributed Databases • Database Testing • Data Analysis • Predictive analysis • Text mining • Data quality • Data mining • Enterprise systems

IGI Global is currently accepting manuscripts for publication within this series. To submit a proposal for a volume in this series, please contact our Acquisition Editors at Acquisitions@igi-global.com or visit: http://www.igi-global.com/publish/.

The Advances in Data Mining and Database Management (ADMDM) Book Series (ISSN 2327-1981) is published by IGI Global, 701 E. Chocolate Avenue, Hershey, PA 17033-1240, USA, www.igi-global.com. This series is composed of titles available for purchase individually; each title is edited to be contextually exclusive from any other title within the series. For pricing and ordering information please visit http://www.igi-global.com/book-series/advances-data-miningdatabase-management/37146. Postmaster: Send all address changes to above address. ©© 2018 IGI Global. All rights, including translation in other languages reserved by the publisher. No part of this series may be reproduced or used in any form or by any means – graphics, electronic, or mechanical, including photocopying, recording, taping, or information and retrieval systems – without written permission from the publisher, except for non commercial, educational use, including classroom teaching purposes. The views expressed in this series are those of the authors, but not necessarily of IGI Global.

Titles in this Series
For a list of additional titles in this series, please visit: https://www.igi-global.com/book-series/advances-data-mining-database-management/37146
Data Visualization and Statistical Literacy for Open and Big Data Theodosia Prodromou (University of New England, Australia) Information Science Reference • ©2017 • 365pp • H/C (ISBN: 9781522525127) • US $205.00
Web Semantics for Textual and Visual Information Retrieval Aarti Singh (Guru Nanak Girls College, Yamuna Nagar, India) Nilanjan Dey (Techno India College of Technology, India) Amira S. Ashour (Tanta University, Egypt & Taif University, Saudi Arabia) and V. Santhi (VIT University, India) Information Science Reference • ©2017 • 290pp • H/C (ISBN: 9781522524830) • US $185.00
Advancing Cloud Database Systems and Capacity Planning With Dynamic Applications Narendra Kumar Kamila (C.V. Raman College of Engineering, India) Information Science Reference • ©2017 • 430pp • H/C (ISBN: 9781522520139) • US $210.00
Web Data Mining and the Development of Knowledge-Based Decision Support Systems G. Sreedhar (Rashtriya Sanskrit Vidyapeetha (Deemed University), India) Information Science Reference • ©2017 • 409pp • H/C (ISBN: 9781522518778) • US $165.00
Intelligent Multidimensional Data Clustering and Analysis Siddhartha Bhattacharyya (RCC Institute of Information Technology, India) Sourav De (Cooch Behar Government Engineering College, India) Indrajit Pan (RCC Institute of Information Technology, India) and Paramartha Dutta (Visva-Bharati University, India) Information Science Reference • ©2017 • 450pp • H/C (ISBN: 9781522517764) • US $210.00
Emerging Trends in the Development and Application of Composite Indicators Veljko Jeremic (University of Belgrade, Serbia) Zoran Radojicic (University of Belgrade, Serbia) and Marina Dobrota (University of Belgrade, Serbia) Information Science Reference • ©2017 • 402pp • H/C (ISBN: 9781522507147) • US $205.00
Web Usage Mining Techniques and Applications Across Industries A.V. Senthil Kumar (Hindusthan College of Arts and Science, India) Information Science Reference • ©2017 • 424pp • H/C (ISBN: 9781522506133) • US $200.00
For an enitre list of titles in this series, please visit: https://www.igi-global.com/book-series/advances-data-mining-database-management/37146
701 East Chocolate Avenue, Hershey, PA 17033, USA Tel: 717-533-8845 x100 • Fax: 717-533-8661
E-Mail: cust@igi-global.com • www.igi-global.com

Editorial Advisory Board
Syed M. Bukhari, King Abdulaziz University, Saudi Arabia Xiao-Zhi Gao, Aalto University, Finland Heba A. Hassen, Dhofar University, Oman Dilip Malai, Mekelle University, Ethiopia Sigurd Meldal, San Jose State University, USA Vijay Singh Rathore, Rajasthan Institute of Engineering and Technology, India Jung Soon-Ki, Kyungpook National University, South Korea Lipo Way, Nanyang Technological University, Singapore Ahmed F. Zobaa, Brunel University, UK
List of Reviewers
A. S. N. Chakravarthy, JNTU, India T. Hanumanthappa, Bangalore University, India T. Senthil Kumar, Amrita Vishwa VidhyaPeetham, India Palaniswamy, Government College of Engineering Tamilnadu, India Madhan Kumar Srinivasan, Global Science and Technology, Singapore

Table of Contents
Preface................................................................................................................. xv
Acknowledgment............................................................................................... xxii
Chapter 1 Advanced Threat Detection Based on Big Data Technologies...............................1
Madhvaraj M. Shetty, Mangalore University, India Manjaiah D. H., Mangalore University, India
Chapter 2 A Brief Review on Deep Learning and Types of Implementation for Deep Learning................................................................................................................20
Uthra Kunathur Thikshaja, Kyungpook National University, South Korea
Anand Paul, Kyungpook National University, South Korea
Chapter 3 Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks...............................................................................................................33
Punam Dutta Choudhury, Gauhati University, India Ankumoni Bora, Gauhati University, India Kandarpa Kumar Sarma, Gauhati University, India
Chapter 4 Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms............................................................................................................61
Murad Khan, Sarhad University of Science and Information Technology, Pakistan
Bhagya Nathali Silva, Kyungpook National University, South Korea Kijun Han, Kyungpook National University, South Korea

﻿
Chapter 5 Digital Investigation of Cybercrimes Based on Big Data Analytics Using Deep Learning......................................................................................................79
Ezz El-Din Hemdan, Managlore University, India Manjaiah D. H., Mangalore University, India
Chapter 6 Classifying Images of Drought-Affected Area Using Deep Belief Network, kNN, and Random Forest Learning Techniques................................................102
Sanjiban Sekhar Roy, VIT University, India Pulkit Kulshrestha, VIT University, India Pijush Samui, NIT Patna, India
Chapter 7 Big Data Deep Analytics for Geosocial Networks.............................................120
Muhammad Mazhar Ullah Rathore, Kyungpook National University, South Korea
Awais Ahmad, Yeungnam University, South Korea Anand Paul, Kyungpook National University, South Korea
Chapter 8 Data Science: Recent Developments and Future Insights:.................................141
Sabitha Rajagopal, SNS College of Technology, Anna University, India
Chapter 9 Data Science and Computational Biology..........................................................152
Singaraju Jyothi, Sri Padmavati Mahila University, India Bhargavi P, Sri Padmavati Mahila University, India
Chapter 10 After Cloud: In Hypothetical World...................................................................173
Shigeki Sugiyama, Independent Researcher, Japan
Chapter 11 Cloud-Based Big Data Analytics in Smart Educational System........................189
Newlin Rajkumar Manokaran, Anna University – Coimbatore, India Venkatesa Kumar Varathan, Anna University – Coimbatore, India Shalinie Deepak, United Institute of Technology, India

﻿
Related References............................................................................................ 200 Compilation of References............................................................................... 237 About the Contributors.................................................................................... 256 Index.................................................................................................................. 263

Detailed Table of Contents
Preface................................................................................................................. xv
Acknowledgment............................................................................................... xxii
Chapter 1 Advanced Threat Detection Based on Big Data Technologies...............................1
Madhvaraj M. Shetty, Mangalore University, India Manjaiah D. H., Mangalore University, India
Today constant increase in number of cyber threats apparently shows that current countermeasures are not enough to defend it. With the help of huge generated data, big data brings transformative potential for various sectors. While many are using it for better operations, some of them are noticing that it can also be used for security by providing broader view of vulnerabilities and risks. Meanwhile, deep learning is coming up as a key role by providing predictive analytics solutions. Deep learning and big data analytics are becoming two high-focus of data science. Threat intelligence becoming more and more effective. Since it is based on how much data collected about active threats, this reason has taken many independent vendors into partnerships. In this chapter, we explore big data and big data analytics with its benefits. And we provide a brief overview of deep analytics and finally we present collaborative threat Detection. We also investigate some aspects of standards and key functions of it. We conclude by presenting benefits and challenges of collaborative threat detection.

﻿
Chapter 2 A Brief Review on Deep Learning and Types of Implementation for Deep Learning................................................................................................................20
Uthra Kunathur Thikshaja, Kyungpook National University, South Korea
Anand Paul, Kyungpook National University, South Korea
In recent years, there’s been a resurgence in the field of Artificial Intelligence and deep learning is gaining a lot of attention. Deep learning is a branch of machine learning based on a set of algorithms that can be used to model high-level abstractions in data by using multiple processing layers with complex structures, or otherwise composed of multiple non-linear transformations. Estimation of depth in a Neural Network (NN) or Artificial Neural Network (ANN) is an integral as well as complicated process. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. This chapter describes the motivations for deep architecture, problem with large networks, the need for deep architecture and new implementation techniques for deep learning. At the end, there is also an algorithm to implement the deep architecture using the recursive nature of functions and transforming them to get the desired output.
Chapter 3 Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks...............................................................................................................33
Punam Dutta Choudhury, Gauhati University, India Ankumoni Bora, Gauhati University, India Kandarpa Kumar Sarma, Gauhati University, India
The present world is data driven. From social sciences to frontiers of research in science and engineering, one common factor is the continuous data generation. It has started to affect our daily lives. Big data concepts are found to have significant impact in modern wireless communication systems. The analytical tools of big data have been identified as full scale autonomous mode of operation which necessitates a strong role to be played by learning based systems. The chapter has focused on the synergy of big data and deep learning for generating better efficiency in evolving communication frameworks. The chapter has also included discussion on machine learning and cognitive technologies w.r.t. big data and mobile communication. Cyber Physical Systems being indispensable elements of M2M communication, Wireless Sensor Networks and its role in CPS, cognitive radio networking and spectrum sensing have also been discussed. It is expected that spectrum sensing, big data and deep learning will play vital roles in enhancing the capabilities of wireless communication systems.

﻿
Chapter 4 Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms............................................................................................................61
Murad Khan, Sarhad University of Science and Information Technology, Pakistan
Bhagya Nathali Silva, Kyungpook National University, South Korea Kijun Han, Kyungpook National University, South Korea
Big Data and deep computation are among the buzzwords in the present sophisticated digital world. Big Data has emerged with the expeditious growth of digital data. This chapter addresses the problem of employing deep learning algorithms in Big Data analytics. Unlike the traditional algorithms, this chapter comes up with various solutions to employ advanced deep learning mechanisms with less complexity and finally present a generic solution. The deep learning algorithms require less time to process the big amount of data based on different contexts. However, collecting the accurate feature and classifying the context into patterns using neural networks algorithms require high time and complexity. Therefore, using deep learning algorithms in integration with neural networks can bring optimize solutions. Consequently, the aim of this chapter is to provide an overview of how the advance deep learning algorithms can be used to solve various existing challenges in Big Data analytics.
Chapter 5 Digital Investigation of Cybercrimes Based on Big Data Analytics Using Deep Learning......................................................................................................79
Ezz El-Din Hemdan, Managlore University, India Manjaiah D. H., Mangalore University, India
Big Data Analytics has become an important paradigm that can help digital investigators to investigate cybercrimes as well as provide solutions to malware and threat prediction, detection and prevention at an early stage. Big Data Analytics techniques can use to analysis enormous amount of generated data from new technologies such as Social Networks, Cloud Computing and Internet of Things to understand the committed crimes in addition to predict the new coming severe attacks and crimes in the future. This chapter introduce principles of Digital Forensics and Big Data as well as exploring Big Data Analytics and Deep Learning benefits and advantages that can help the digital investigators to develop and propose new techniques and methods based on Big Data Analytics using Deep Learning techniques that can be adapted to the unique context of Digital Forensics as well as support performing digital investigation process in forensically sound and timely fashion manner.

﻿
Chapter 6 Classifying Images of Drought-Affected Area Using Deep Belief Network, kNN, and Random Forest Learning Techniques................................................102
Sanjiban Sekhar Roy, VIT University, India Pulkit Kulshrestha, VIT University, India Pijush Samui, NIT Patna, India
Drought is a condition of land in which the ground water faces a severe shortage. This condition affects the survival of plants and animals. Drought can impact ecosystem and agricultural productivity, severely. Hence, the economy also gets affected by this situation. This paper proposes Deep Belief Network (DBN) learning technique, which is one of the state of the art machine learning algorithms. This proposed work uses DBN, for classification of drought and non-drought images. Also, k nearest neighbour (kNN) and random forest learning methods have been proposed for the classification of the same drought images. The performance of the Deep Belief Network(DBN) has been compared with k nearest neighbour (kNN) and random forest. The data set has been split into 80:20, 70:30 and 60:40 as train and test. Finally, the effectiveness of the three proposed models have been measured by various performance metrics.
Chapter 7 Big Data Deep Analytics for Geosocial Networks.............................................120
Muhammad Mazhar Ullah Rathore, Kyungpook National University, South Korea
Awais Ahmad, Yeungnam University, South Korea Anand Paul, Kyungpook National University, South Korea
Geosocial network data provides the full information on current trends in human, their behaviors, their living style, the incidents and events, the disasters, current medical infection, and much more with respect to locations. Hence, the current geosocial media can work as a data asset for facilitating the national and the government itself by analyzing the geosocial data at real-time. However, there are millions of geosocial network users, who generates terabytes of heterogeneous data with a variety of information every day with high-speed, termed as Big Data. Analyzing such big amount of data and making real-time decisions is an inspiring task. Therefore, this book chapter discusses the exploration of geosocial networks. A system architecture is discussed and implemented in a real-time environment in order to process the abundant amount of various social network data to monitor the earth events, incidents, medical diseases, user trends and thoughts to make future real-time decisions as well as future planning.

﻿
Chapter 8 Data Science: Recent Developments and Future Insights:.................................141
Sabitha Rajagopal, SNS College of Technology, Anna University, India
Data Science employs techniques and theories to create data products. Data product is merely a data application that acquires its value from the data itself, and creates more data as a result; it’s not just an application with data. Data science involves the methodical study of digital data employing techniques of observation, development, analysis, testing and validation. It tackles the real time challenges by adopting a holistic approach. It ‘creates’ knowledge about large and dynamic bases, ‘develops’ methods to manage data and ‘optimizes’ processes to improve its performance. The goal includes vital investigation and innovation in conjunction with functional exploration intended to notify decision-making for individuals, businesses, and governments. This paper discusses the emergence of Data Science and its subsequent developments in the fields of Data Mining and Data Warehousing. The research focuses on need, challenges, impact, ethics and progress of Data Science. Finally the insights of the subsequent phases in research and development of Data Science is provided.
Chapter 9 Data Science and Computational Biology..........................................................152
Singaraju Jyothi, Sri Padmavati Mahila University, India Bhargavi P, Sri Padmavati Mahila University, India
Data Science and Computational biology is an interdisciplinary program that brings together the domain specific knowledge of science and engineering with relevant areas of computing and bioinformatics. Data science has the potential to revolutionise healthcare, and respond to the increasing volume and complexity in biomedical and bioinformatics data. From genomics to clinical records, from imaging to mobile health and personalised medicine, the data volume in biomedical research presents urgent challenges for computer science. This chapter elevates the researchers in what way data science play important role in Computational Biology such as Biomolecular Computation, Computational Photonics, Medical Imaging, Scientific Computing, Structural Biology, Bioinformatics and Bio-Computing etc. Big data analytics of biological data bases, high performance computing in large sequence of genome database and Scientific Visualization are also discussed in this chapter.

﻿
Chapter 10 After Cloud: In Hypothetical World...................................................................173
Shigeki Sugiyama, Independent Researcher, Japan
It is just now at the top of an aggregation point of globalization’s era in terms of things and living creatures. And the communication methods including in many sorts of transfers like commodity, facility, information, system, thought, knowledge, human, etc. may cause many kinds of and many types of interactions among us. And those many kinds of and many types of interactions have been again causing many sorts of problems. Under these situations, Cloud has come out as a smart solution to these problems. However, “Cloud is the final ultimate solution to offer to these problems’ solving?” On this chapter, this question is deeply concerned from various aspects. And it is studied on this regard for getting a new paradigm.
Chapter 11 Cloud-Based Big Data Analytics in Smart Educational System........................189
Newlin Rajkumar Manokaran, Anna University – Coimbatore, India Venkatesa Kumar Varathan, Anna University – Coimbatore, India Shalinie Deepak, United Institute of Technology, India
In this modern Digital era, Technology is a key player in transforming the educational pedagogy for the benefit of students and society at large. Technology in the classroom allows the teacher to deliver more personalized learning to the student with better interaction through the internet. Humongous amount of digital data collected day by day increases has led to the use of big data. It helps to correlate the performance and learning pattern of individual students by analysing large amount of stored activity of the students, offering worthwhile feedback etc. The use of big data analytics in a cloud environment helps in providing an instant infrastructure with low cost, accessibility, usability etc. This paper presents an innovative means towards providing a smarter educational system in schools. It improves individual efficiency by providing a way to monitor the progress of individual student by maintaining a detailed profile. This framework has been established in a cloud environment which is an online learning system where the usage pattern of individual students are collected.
Related References............................................................................................ 200
Compilation of References............................................................................... 237
About the Contributors.................................................................................... 256
Index.................................................................................................................. 263

xv
Preface
Big Data technologies have gone from the realm of hype to one of the core descriptors of the new digital age. The digital data have proliferated nine times in volume in just five years and by 2020, researchers are suggesting that its volume will increase at a rapid rate and will almost reach 35 trillion gigabytes (IDC, 2014). In this paradigm shift, a research portrays that, 90% of all the data in the world was created in this past 2 years and it is obvious that we are living a data cascade era (SINTEF, 2013). This outburst of data exploding trend embarks ample opportunities and considerable transformation in various sectors such as enterprises, healthcare, industrial manufacturing, and Transportation. Big data endows a novel technique of probability to collect, manage and analyze the vast quantities of data, which indeed offers an understanding of context towards diverse applications. In big data analytics, deep learning is a set of machine-learning techniques based on neural networking, is still evolving but shows great potential for solving business problems. Deep learning enables computers to recognize items of concern in large quantities of unstructured and binary data and to deduce relationships without needing specific models or programming instructions (Arel, Rose, & Karnowski, 2010).
Furthermore, deep learning has an integral part in the advancement in speech recognition, Computer Vision and Natural Language Processing in the last decade (Li, 2015). Using deep learning methodologies few long standing issues were sorted out in speech recognition (Hinton et al., 2012). Companies like Google and Microsoft has already deployed deep learning based speech recognition systems in their products. In computer vision, feature engineering plays a significant role which some resistance for feature learning. Further, in Natural Language Processing language model, machine translation and question answering (Domingo, 2012). Deep learning paly a predominate role in Science, it is used for a various application like protein structure prediction, analysis of genomic data, predicting chemical reactions and detecting exotic particles.
This handbook on research looks to discuss and address first in understanding on how deep analytics applied to an understanding of context provides the preconditions for a world of smart technologies. This combines with various advanced algorithms

Preface
that allow systems to understand their environment, learn for themselves, and act autonomously, which offer intellectual data agility measurement as a contrast to the storage and management of key data sources, provide a concrete understanding of data management with respects to various applications.
THE CHALLENGES
In Big Data Analytics particularly in deep learning method, deep unsupervised learning requires special attention. Further, incorporating deep discriminative learning method with Bayesian models is essential. In addition, integrating neural representation with deep symbolic learning is predominant. One of the major challenges in big data analytics is with the streaming data which is used in real time processing. It is essential that big data adapts deep learning to handle fat moving or streaming data. Hence, there is a need for deep learning algorithm for fast moving data. Finally, from a computation and analytics point of view, lager scale models of Deep Learning method needs specific attention.
OBJECTIVE OF THE BOOK
The main objective of this book is to capture the state-of-the-art trends and advancements in Big Data Analytics, its technologies, and applications. The book also aims to identify potential research directions and technologies that will facilitate insight generation in various domains of science, industry, business, and consumer applications. We expect the book to serve as a reference for a larger audience, such as systems architects, practitioners, developers, new researchers and graduate level students. The book will cover fundamental to advanced concepts necessary to comprehend current Deep learning issues, challenges and possible solutions as well as future trends in big data Analytics.
ORGANIZATION OF THE BOOK
The book is organized into 11 chapters. A brief description of each of the chapters follows:
Chapter 1 is “Advanced Threat Detection Based on Big Data Technologies.” Today, a constant increase in a number of cyber threats apparently shows that current countermeasures are not enough to defend it. With the help of huge generated data, big data brings the transformative potential for various sectors. While many are
xvi

Preface
using it for better operations, some of them are noticing that it can also be used for security by providing a broader view of vulnerabilities and risks. Meanwhile, deep learning is coming up as a key role by providing predictive analytics solutions. Deep learning and big data analytics are becoming two high-focus of data science. Threat intelligence becoming more and more effective since it is based on how much data collected about active threats, this reason has taken many independent vendors into partnerships. In this chapter, the author explores big data and big data analytics with its benefits. And the authors provide a brief overview of deep analytics and finally we present collaborative threat Detection. Further, investigation on some aspects of standards and key functions of it is discussed and conclude by presenting benefits and challenges of collaborative threat Detection.
Chapter 2 is “A Brief Review on Deep Learning and Types of Implementation for Deep Learning.” In recent years, there’s been a resurgence in the field of Artificial Intelligence and deep learning which gains a lot of attention. Deep learning is a branch of machine learning based on a set of algorithms that can be used to model high-level abstractions in data by using multiple processing layers with complex structures or otherwise composed of multiple non-linear transformations. Estimation of depth in a Neural Network (NN) or Artificial Neural Network (ANN) is an integral as well as the complicated process. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. This chapter describes the motivations for deep architecture, the problem with large networks, the need for deep architecture and new implementation techniques for deep learning. Finally, an algorithm to implement the deep architecture using the recursive nature of functions and transforming them to get the desired output is proposed.
Chapter 3 is “Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks.” The present world is data driven. From social sciences to frontiers of research in science and engineering, one common factor is the continuous data generation. It has started to affect our daily lives. Big data concepts are found to have a significant impact in modern wireless communication systems. The analytical tools of big data have been identified as a full scale autonomous mode of operation which necessitates a strong role to be played by learning based systems. The chapter has focused on the synergy of big data and deep learning for generating better efficiency in evolving communication frameworks. The chapter has also included discussion on machine learning and cognitive technologies w.r.t. big data and mobile communication. Cyber Physical Systems being indispensable elements of M2M communication, Wireless Sensor Networks and its role in CPS, cognitive radio networking and spectrum sensing have also been discussed. It is expected that spectrum sensing, big data and deep learning will play vital roles in enhancing the capabilities of wireless communication systems.
xvii

Preface
Chapter 4 is “Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms.” Big Data and deep computation are among the buzzwords in the present sophisticated digital world. Big Data has emerged with the expeditious growth of digital data. This chapter addresses the problem of employing deep learning algorithms in Big Data analytics. Unlike the traditional algorithms, this chapter comes up with various solutions to employ advanced deep learning mechanisms with less complexity and finally present a generic solution. The deep learning algorithms require less time to process the big amount of data based on different contexts. However, collecting the accurate feature and classifying the context into patterns using neural networks algorithms require high time and complexity. Therefore, using deep learning algorithms in integration with neural networks can bring optimize solutions. Consequently, the aim of this chapter is to provide an overview of how the advance deep learning algorithms can be used to solve various existing challenges in Big Data analytics.
Chapter 5 is “Digital Investigation of Cybercrimes Based on Big Data Analytics Using Deep Learning.” Big Data Analytics has become an important paradigm that can help digital investigators to investigate cybercrimes as well as provide solutions to malware and threat prediction, detection and prevention at an early stage. Big Data Analytics techniques can use to analysis enormous amount of generated data from new technologies such as Social Networks, Cloud Computing, and Internet of Things to understand the committed crimes, in addition, to predict the new coming severe attacks and crimes in the future. This chapter introduce principles of Digital Forensics and Big Data as well as exploring Big Data Analytics and Deep Learning benefits and advantages that can help the digital investigators to develop and propose new techniques and methods based on Big Data Analytics using Deep Learning techniques that can be adapted to the unique context of Digital Forensics as well as support performing digital investigation process in forensically sound and timely fashion manner.
Chapter 6 is “Classifying Images of Drought-Affected Area Using Deep Belief Network, kNN, and Random Forest Learning Techniques.” Drought is a condition of land in which the ground water faces a severe shortage. This condition affects the survival of plants and animals. Drought can impact ecosystem and agricultural productivity, severely. Hence, the economy also gets affected by this situation. This chapter proposes Deep Belief Network (DBN) learning technique, which is one of the state of the art machine learning algorithms. This proposed work uses DBN, for classification of drought and non-drought images. Also, k nearest neighbour (kNN) and random forest learning methods have been proposed for the classification of the same drought images. The performance of the Deep Belief Network(DBN) has been compared with k nearest neighbour (kNN) and random forest. The data set has
xviii

Preface
been split into 80:20, 70:30 and 60:40 as train and test. Finally, the effectiveness of the three proposed models has been measured by various performance metrics.
Chapter 7 is “Big Data Deep Analytics for Geosocial Networks.” Geosocial network data provides the full information on current trends in human, their behaviors, their living style, the incidents and events, the disasters, current medical infection, and much more with respect to locations. Hence, the current geosocial media can work as a data asset for facilitating the national and the government itself by analyzing the geosocial data at real-time. However, there are millions of geosocial network users, who generates terabytes of heterogeneous data with a variety of information every day with high-speed, termed as Big Data. Analyzing such big amount of data and making real-time decisions is an inspiring task. Therefore, this book chapter discusses the exploration of geosocial networks. A system architecture is discussed and implemented in a real-time environment in order to process the abundant amount of various social network data to monitor the earth events, incidents, medical diseases, user trends, and thoughts to make future real-time decisions as well as future planning.
Chapter 8 is “Data Science: Recent Developments and Future Insights.” Data Science employs techniques and theories to create data products. A data product is merely a data application that acquires its value from the data itself, and creates more data as a result; it’s not just an application with data. Data science involves the methodical study of digital data employing techniques of observation, development, analysis, testing and validation. It tackles the real-time challenges by adopting a holistic approach. It ‘creates’ knowledge about large and dynamic bases, ‘develops’ methods to manage data and ‘optimizes’ processes to improve its performance. The goal includes vital investigation and innovation in conjunction with functional exploration intended to notify decision-making for individuals, businesses, and governments. This chapter discusses the emergence of Data Science and its subsequent developments in the fields of Data Mining and Data Warehousing. The research focuses on need, challenges, impact, ethics and progress of Data Science. Finally, the insights of the subsequent phases in research and development of Data Science is provided.
Chapter 9 is “Data Science and Computational Biology.” Data Science and Computational biology is an interdisciplinary program that brings together the domain specific knowledge of science and engineering with relevant areas of computing and bioinformatics. Data science has the potential to revolution the healthcare, and respond to the increasing volume and complexity of biomedical and bioinformatics data. From genomics to clinical records, from imaging to mobile health and personalized medicine, the data volume in biomedical research presents urgent challenges for computer science. This chapter elevates the researchers in what way data science play important role in Computational Biology such as Bio-molecular
xix

Preface
Computation, Computational Photonics, Medical Imaging, Scientific Computing, Structural Biology, Bioinformatics and Bio-Computing, etc. Big data analytics of biological data bases, high performance computing in a large sequence of genome database and Scientific Visualization are also discussed in this chapter.
Chapter 10 is “After Cloud: In Hypothetical World.” It is just now at the top of an aggregation point of globalization’s era in terms of things and living creatures. And the communication methods including in many sorts of transfers like commodity, facility, information, system, thought, knowledge, human, etc. may cause many kinds of and many types of interactions among us. And those many kinds of and many types of interactions have been again causing many sorts of problems. Under these situations, Cloud has come out as a smart solution to these problems. However, “Cloud is the final ultimate solution to offer to these problems’ solving?” On this chapter, this question is deeply concerned from various aspects. And it is studied in this regard for getting a new paradigm.
Chapter 11 is “Cloud-Based Big Data Analytics in Smart Educational System.” In this modern Digital era, Technology is a key player in transforming the educational pedagogy for the benefit of students and society at large. Technology in the classroom allows the teacher to deliver more personalized learning to the student with better interaction through the internet. A humongous amount of digital data collected day by day increases has led to the use of big data. It helps to correlate the performance and learning pattern of individual students by analyzing a large amount of stored activity of the students, offering worthwhile feedback etc. The use of big data analytics in a cloud environment helps in providing an instant infrastructure with low cost, accessibility, usability, etc. This chapter presents an innovative means towards providing a smarter educational system in schools. It improves individual efficiency by providing a way to monitor the progress of individual student by maintaining a detailed profile. This framework has been established in a cloud environment which is an online learning system where the usage pattern of individual students is collected.
REFERENCES
Arel, I., Rose, D. C., & Karnowski, T. P. (2010). Deep machine learning-A new frontier in artificial intelligence research. IEEE Comput Intell, 5(4), 13–18. doi:10.1109/ MCI.2010.938364
Domingos, P. (2012). A few useful things to know about machine learning. Communications of the ACM, 55.
xx

Preface
Hinton, G., Deng, L., Yu, D., Mohamed, A.-R., Jaitly, N., Senior, A., & Kingsbury, B. et al. (2012). Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. Signal Process Mag IEEE, 29(6), 82–97. doi:10.1109/MSP.2012.2205597 IDC. (2014). The digital universe of opportunities: Rich data and the increasing value of the internet of things. Retrieved from https://www.emc.com/leadership/ digital-universe/2014iview/executive-summary.htm Li, W. (2015). Artificial intelligence laboratory. Retrieved from https://ai.arizona. edu/sites/ai/files/resources/chen_deep_learningapril2015.pptx SINTEF. (2013). Retrieved from https://www.sciencedaily.com/ releases/3013/05/130522085217.html
xxi

xxii
Acknowledgment
The editors would like to acknowledge the help of all the individuals involved in this project and, more specifically, to the SNS Institutions for their complete support and encouragement, authors and reviewers that took part in the review process. Without their support, this book would not have become a reality. First, the editors would like to thank each one of the authors for their contributions. Our sincere gratitude goes to the chapter’s authors who contributed their time and expertise to this book. Second, the editors wish to acknowledge the valuable contributions of the reviewers regarding the improvement of quality, coherence, and content presentation of chapters. Most of the authors also served as referees; we highly appreciate their double task. I would like to show my warm thank to IGI Global publications who supported me at every bit and without whom it was impossible to accomplish the end task.
S. Karthik SNS College of Technology, Anna University, India
Anand Paul Kyungpook National University, South Korea
N. Karthikeyan Mizan-Tepi University, Ethiopia

1
Chapter 1
Advanced Threat Detection Based on Big
Data Technologies
Madhvaraj M. Shetty Mangalore University, India
Manjaiah D. H. Mangalore University, India
ABSTRACT Today constant increase in number of cyber threats apparently shows that current countermeasures are not enough to defend it. With the help of huge generated data, big data brings transformative potential for various sectors. While many are using it for better operations, some of them are noticing that it can also be used for security by providing broader view of vulnerabilities and risks. Meanwhile, deep learning is coming up as a key role by providing predictive analytics solutions. Deep learning and big data analytics are becoming two high-focus of data science. Threat intelligence becoming more and more effective. Since it is based on how much data collected about active threats, this reason has taken many independent vendors into partnerships. In this chapter, we explore big data and big data analytics with its benefits. And we provide a brief overview of deep analytics and finally we present collaborative threat Detection. We also investigate some aspects of standards and key functions of it. We conclude by presenting benefits and challenges of collaborative threat detection.
DOI: 10.4018/978-1-5225-3015-2.ch001
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.

Advanced Threat Detection Based on Big Data Technologies
INTRODUCTION
In past few years, increase in the number of network intrusions has become severe threat to the safety and privacy of computer users. Billions of malicious cyber attacks are reported in each year (Fossi et al, 2011; Wood, et al, 2012). These attacks are becoming more stealthy and advanced, driven by an “underground economy” (Fossi et al, 2008).. Today hackers not only collecting private information from the compromised nodes, but also they are using these nodes to launch attacks such as distributed denial-of-service (DDoS) attacks. As a defence to these attacks, Intrusion Detection Systems (IDS) are used widely. These systems identify intrusions by comparing observable behavior against suspicious patterns. Traditional IDSs can monitor activities on a single host or network traffic in a sub-network only. They do not have capabilities of a global view of intrusions in a network; therefore it is not effective in detecting new or unknown threats (Fung & Boutaba, 2013).
The rest of this chapter is organized as follows: firstly, provides background about cyber threats. Secondly, introduces big data with its analytics while deep learning concepts are presented thirdly. Fourthly threat detection with collaborative method explained with its benefits and challenges. Finally, the chapter conclusion is presented.
BACKGROUND
At the recent World Economic Forum (WEF) 2016, the growing number of cyber attacks was a major topic of concern. According to its 11th annual global risks report, cyber-attacks are ranked in the list of top ten threats in 140 economies (“The Global Risks” 2016). Failure in addressing and understanding these cyber attacks could affect economic sectors, national economies and global enterprises. Most of the firewall and other network-based security products provide mature and robust logging capabilities. Since the perimeter security is not enough, most of the security programs start with analyzing logs from the devices at the edge of the network. Nowadays most of the hackers of cyber conflicts are well organized with specific objectives, goals and having strong teams that are heavily funded. They are targeting information and communication systems of industrial, government, military and other private organizations. Also they are willing to use any amount of money, time to become expertise to reach their goals.
So understanding the limitations and problems of current technologies facing against advanced persistent threats (APTs) is important. APTs are significantly different from traditional attacks due to their own characteristics (Virvilis et al, 2014).
2

Advanced Threat Detection Based on Big Data Technologies
• APTs can bypass the majority of network intrusion detection systems and signature-based end points because they are using zero-day.
• The time taken by these attacks is outside the limited window of time of these detection systems due to the fact that they are generally spread over a wide period of time.
• Attackers are willing to spend significant time on focusing a particular target and explore all possible attack paths until they manage to overcome its defence.
• Attacks are highly selective. Targeted victims are selected very carefully, usually departments of an organization which are less likely to identify and report an attack and are nontechnical.
• Based on the analysis of the major APT attacks, it is observed that they are wellsupported by nation-states that have significant capabilities enabled (covert physical access, manufacturing, intelligence collection) for cyber-attacks.
Due to these characteristics, present solutions of cyber security will fail to provide an effective defence against such attacks. Signature-based approach is used most widely used in intrusion detection. It is a simple testing methodology using known attack patterns where detection is based on small variations of attack patterns. But it has substantial limitations in intrusion detection systems against advanced persistent threats.
BIG DATA
Threat detection is a vision; it is the ability to discover significant action which requires immediate attention from the large number of activity across the enterprise. Today organizations are generating massive amounts of data, they can actually use those data to make intelligent security decisions and be more effective. The answers to many security questions related to user behavior, fraudulent activity, communications and security risks lie within these huge data sets (Fung & Boutaba, 2013). But multi-sources data generated from various sources such as the network, insider threats and third party vendors must be connected and correlated, then it must be analyzed to detect and mitigate threats which require high-speed analysis. The more data that is being analyzed – the more comprehensive are the results. While many companies are using big data technology to raise sales, for better operations and lower costs, at the same time many are noticing that it can also be used for security purpose by providing broader view of vulnerabilities and risks in networks (Ben-Zvi, 2016).. It can examine large amounts of data to discover hidden patterns, correlations and other insights in it.
3

Advanced Threat Detection Based on Big Data Technologies
For effective defenses against cyber-intrusions and to counter the cyber-crime wave, big data and analytics are developing more and more. With the help of big data, it is possible to identify suspicious behavior earlier by reducing the critical time between detection and remediation with faster, better, actionable security information. It provides ability to make connections between threats to create a prioritized list after analyzing massive numbers of potential security. Cyber security professionals considering proactive approach to prevent attacks with big data by connecting heterogeneous data from different sources (Wolfe, 2016).. It enables companies to preempt malicious activity on a wider and deeper scale with the help of robust risk and threat detection tools. Big data’s rapid analysis capabilities on massive volume of historic information facilitate cyber-security technology to detect new threats, identify complex patterns and to develop effective responses. It provides better understanding of approaches and attack methods; in addition this analysis can be done in real time or near real-time. As a result companies able to detect new types of potential attacks before hackers succeed in committing a cyber-crime during the penetration stage. Enterprises stay ahead and respond to evolving threats by these technological developments. We can preempt tomorrow’s potential cyber attack by comparing data from earlier periods to what is going on now.
So an effective big data solution able to store and analyze millions of transaction details in order to: predict/identify performance problems; detect infrastructure changes’ that effect on IT reliability and performing root cause analysis.
Big Data Analytics
To improve situational awareness and information security, big data analytics can be supplemented in enterprises. For example, it can be employed to analyze log files, financial transactions and network traffic to identify suspicious activities and anomalies suspicious activities and to correlate information from multiple sources into a coherent view. Data driven information security can be used for fraud detection in banks and anomaly based intrusion detection systems. Fraud detection is one of the most visible uses for big data analytics. In forensics and intrusion detection analyzing network packets, logs and system events has been a significant problem.
Because traditional technologies fail to provide the tools to support long-term, large-scale analytics for several reasons: (“Security Intelligence with Big Data”, 2016; “Big Data Working Group”, 2013).
• Historical data analysis has the potential of revealing long running attack methods and identifies relapses in security over time. So organization must keep its traditional security information for longer periods of time to perform analysis.
4

Advanced Threat Detection Based on Big Data Technologies
• Since storing large amount of data was not economically feasible, as a result, most event logs and other recorded computer activity were cleared after a fixed retention period (e.g., 90 days).
• Traditional tools are inefficient in performing analytics and complex queries on large, structured data sets.
• Analyzing and managing unstructured data using traditional tools is not possible.
• Since big data system used cluster computing infrastructures, they are more reliable, and guarantees that any complex queries on the systems are processed to completion.
New technologies like stream processing and hadoop ecosystem enabled storage and analysis of large heterogeneous data sets at an unprecedented speed and scale. These big data technologies will transform security analytics by: (“Big Data Working Group”, 2013).
1. Collecting data at a large scale from many external sources as well as internal sources such as vulnerability databases.
2. Conducting deeper analytics on the collected data. 3. Offering consolidated view of extracted security-related information. 4. Enabling real-time or near real-time analysis of streaming data.
Even after using predictive analytics and advanced statistical modeling, new unknown security threats still go undiscovered. Big data analytics can help to solve this problem by providing intelligence that detects potential threats and suspicious patterns by expanding the definition of security data to all parts of the business.
Benefits of Big Data Analytics
By collecting data such as network logs, DNS feed, network traffic, ip addresses big data analytics can help to wipe out cyber threats from organization, will be effective in identifying malware in earlier stages (Virvilis et al, 2014).
• Managing dynamic collection, correlation and consolidation of data from any number of data sources, such as network traffic, operating system artifacts and event data.
• Anomaly detection based on correlation of historical and recent events. For example, increase in the volume of traffic into Domain Name System (DNS) from a particular system for a small-time period can be legitimate user
5

Advanced Threat Detection Based on Big Data Technologies
actions. But, if such pattern also identified in historical traffic over a period of days, then it is a potential indication of suspicious behavior.
This ability to correlate data from a wide range of sources across significant time periods will result in a lower false-positive rate. Also allows signal of advanced persistent threat to be detected as a noise in authorized user activities. Collecting, analyzing and correlating should be completed within an acceptable time window to give the security professionals an early caution for the potential attacks against their infrastructure. Based on its capabilities, big data and its analytics can be used for following cases:
• Capturing, indexing, classifying and enriching all types of traffic data of network with threat intelligence framework.
• Continuously monitoring network for threat behaviors and suspicious activities.
• Understanding the behavior of the device in the network. • To take immediate action against threat actor such as stopping all
communications between the device and threat actor. • Analyzing payload content. • To detect, extract and classify suspicious or unknown files in real-time
automatically.
Before big data and its analytics can be used in operational environments for the detection of advanced threats, a few obstacles need to be overcome. In particular, there is a need for new sophisticated algorithms for detection which is capable of processing massive amounts of data from multi-data sources. Additionally, there is a need to further improvement in issues related to storage and processing performance, collecting information from untrustworthy sources, meaningful visualization of information, time synchronization and ensuring the security of sensitive indicators of compromise, among others. At present, part of developments has been done that shows promising results by utilizing big data analytics for security event. To create robust solutions that can address the multidimensional problem of APT, research on this field needs to be intensified (Virvilis et al, 2014).
DEEP ANALYTICS
In all shapes and sizes, digital data is growing at incredible rates. According to National Security Agency (NSA), in each day the internet is processing 1,826 petabytes of data (“National Security Agency”, 2013). Digital information has grown nine
6

Advanced Threat Detection Based on Big Data Technologies
times in size in just five years in 2011 (Gantz & Reinsel, 2001) and size of the data in world will reach 35 trillion gigabytes by 2020 (Gantz & Reinsel, 2010). In the rapidly growing digital world, big data and deep learning are two hottest trends. Big data has been referred as a tool to manage and analyze digital data with exponential growth and wide availability that are impossible or difficult using conventional technologies and software tools. Deep learning refers to a set of techniques from machine learning that learn representations from deep architectures in multiple (Chen & Lin, 2014). Deep learning algorithms are one promising approach of research in automated extraction of complex data representations/features at high levels of abstraction. These algorithms develop hierarchical, layered architecture of learning and representing data, where lower-level features are used to represent higher-level features (Bengio, LeCun, 2007; Arel, Rose, Karnowski, 2010).
Deep learning has the potential to solve any challenging questions in artificial intelligence and machine learning. Deep analytics facilitate better performance and decision-making by supporting meaningful analysis of data from business events to everyday customer interactions, no matter the source. It is the application of advanced data processing methodologies that analyzes, extracts targeted information from large data sets which is multi-source data that contain not only structured data but also unstructured/semi-structured data, often with requirements for real-time or near-real-time responses. It offers complete suite of products for monitoring, analysis, web mapping, visualization and delivering an unprecedented scope of information to its users with required competitive intelligence. Deep analytics conducted by some sectors such as scientific community, financial sector and the pharmaceutical/biomedical industries for some years with good outcome. In recent years, as the amount of corporate data generated has been increased and desire to extract business value from that data the practice of analytics has become increasingly common within the enterprise.
Relative to other machine learning techniques, deep learning has four key advantages: (Amabati, 2016).
• Its ability to work with unlabeled data. • Its ability to learn low-level features from minimally processed raw data. • Its ability to detect complex interactions among features. • Its ability to work with high-cardinality class memberships.
Deep learning analytics can be used in (Amabati, 2016) payment systems to identify suspicious transactions in real time and to analyze large data centers in organizations large. Also it can be used to mine log files and detect threats in any computer networks. Banks can seek better fraud protection with deep analytics.
7

Advanced Threat Detection Based on Big Data Technologies
Behavioral Analytics
Behavioral analytics (Ambati, 2016) is very important fraud detection tool which is increasingly used. For example, in banks behavioral analytics can continuously monitor activity across multiple channels to detect and suspect banking fraud and to respond more quickly by focusing on the observed characteristics of bank customers. Bank can alert the customer about the suspicious activity and block further transactions if the transaction of a customer is outside typical behavior, such as large number of transactions in a short period of time or expensive purchase, etc. Beyond examining number of transaction or frequency of transaction, behavioral analytics can also examine how users behave when using an mobile or online account. These tools can verify pattern at which users are navigating the site, entering input data and consistency in entering information, etc. It can also check for identical behavior pattern across multiple accounts. For example, a group of account holders making identical transactions could indicate a distributed attack on the system. Since fraudster uses each account only a few times, these attacks are invisible to traditional monitoring, but using analytics we can spot the related transactions across multiple accounts.
Graph Analytics
In graph analytics (“Effective Fraud” 2016) data is mapped to objects or nodes, and then the edges or a connection between these objects/nodes has been plotted. It also provides a visual representation of data from internal and external sources between any numbers of nodes. By visualizing data in this manner, it enables companies or banks to recognize relationships quickly that could indicate fraud.
COLLABORATIVE THREAT DETECTION
By its nature, threat intelligence gets more and more effective based on how much data it is able to collect about the active threats. But there is no single entity can be sure about collecting and processing all the intelligence related to cyber threats that is hidden or circulating out there on the internet. This reason has taken many independent vendors of security into partnerships, to get more value and benefit by gathering pieces of information about the malicious actors and threats that are exist in the internet. This collaboration of security vendors leads to more comprehensive and effective cyber security and can greatly benefit threat intelligence system. This is at beginning level of collaboration and it will be moved to highest level. It is a cooperative process; ability to coordinate two or more different resources to complete a goal.
8

Advanced Threat Detection Based on Big Data Technologies
Collaboration is the reasonable choice and effective control for cyber threat intelligence. Since it is a goal comprising multiple independent resources, it can greatly improve the efficiency of the implementation (Ma & Wang, 2013).. In order to counter attacks in government sectors and organizations, they must collaborate each other by sharing security intelligence. To be feasible at scale, it needs a system that allows organizations to collaborate and share threat intelligence information in a confidential, secure and timely manner. Then organizations able to respond quickly and effectively while detecting and identifying cyber threats. This research and open collaboration can help organizations to avoid falling to certain attacks which other organizations have already experienced. In addition to this, while sharing details of an attack, same platform can also be used to distribute the effort of analyzing evidence once they are developed. In some cases, better security intelligence can gathered by combining information from multiple organizations that cannot be obtained from individual organization (“Collaborative Defense, 2015).
In a distributed system, collaboration is an important method to ensure that the resource can be shared among entities and the services can accessed one another in the system. It is also an important technique for solving any complex problem. In particular to threat detection architecture, it means multiple independent detection systems can work together; they can get information as well as carry out operations that they cannot do by themselves independently. So collaboration can guide the overall situation, refine the information, and thus achieving faster and better detection results (“Collaborative Defense” 2015). Organizations belonging to the similar sectors (e.g., financial organizations) typically face from the same type of cyber crimes. Sharing and correlating such information about those could help others in detecting those crimes and mitigating the damages at early stages.
But architecture of collaboration needs certain requirements to be successful (Locasto, et al 2005):
• The exchange of information should not leak any potentially sensitive data. • Large alert rates may hide stealthy activity; so reasonable solution required to
reduce the effects of these rates. • Centralized repositories are single points of failure and likely to fail in
correlating the growing amount of alerts. • Exchanging alerts in a complex network may increase the complexity of the
problem, so it requires good management. • Requires solution for partitioning data among nodes about threat information
by disassociating evidence that considered in the same context.
9

Advanced Threat Detection Based on Big Data Technologies
Standards/Specifications for Cyber Information Sharing
Standardizing threat information is very important in this context. Defining fields, content and objects want to share when the incident occurred is bound to causes errors if it is without any standards or specifications. This is where the Cyber Observable Expression (CybOX), Trusted Automated Exchange of Indicator Information (TAXII) and Structured Threat Information Expression (STIX) come into picture (“Information Sharing” 2016; “Stix, Taxii” 2016). They are open community-driven technical specifications designed for real-time network defense, sophisticated threat analysis and to enable automated sharing for cybersecurity situational awareness. They allow cyberthreat information to be represented in a standardized format. They are standards that software can follow, not any pieces of software itself.
1. TAXII: It is a set of standards for exchanging cyberthreat information to help organizations share information with their partners. It does not define trust agreements and it is not an information sharing program.
2. CybOX: It is a standardized schema for the specification, characterization, capture, and communication of events that are observable in all system and network operations. CybOX objects can be a network connection that is established toward a specific address, email message that is received from a specific address, the MD5 hash of a file, a URI or the modification of a registry key, or a process. It can be used for threat assessment, malware characterization, log management, incident response, intrusion detection/prevention and in digital forensics.
3. STIX: Similar to TAXII, it is not a tool for sharing, but rather a component that supports programs or tools. It is a language for having a standardized communication for the representation of cyberthreat information. It has number of components.
Key Functions of Cyber Information Sharing and Analysis
For effective cyber information sharing and analysis, it is important to understand the various key functions required (“Health Industry” 2015). The Figure 1 identifies the key components.
1. Collection: In order to aggregate cyber threat information, organizations must have the ability to submit them securely and efficiently in a variety of standardized methods and formats such as STIX, TAXII, online portal, custom APIs.
10

Advanced Threat Detection Based on Big Data Technologies
Figure 1. Key functions of cyber information sharing and analysis
2. Analytics: This part takes the threat information collected and reviews them for completeness and other criteria to evaluate the probability of the threat, whereby providing highly reliable IOCs. This allows easy prioritization when it comes to assessing which threats need to be processed first and enables high quality data set to be maintained. A high false positive rate will be experienced without applying analytics to the data collected. In order to understand the magnitude of the threat, third party context and streamline analyst workflow is added to the intelligence ensuring that an analyst has enough information regarding the threat and that the IOCs are actionable.
3. Correlation, Threat Modeling, and Alerting: Threat modeling provides information related insights into the adversaries behind ongoing campaigns along with the general tactics they used for compromising targets. The threat correlation provides a vision on relationships between different threat model components. The alerting system assists cyber professionals with a warning that an adversary is attempting to access, is targeting the system or has already accessed organization’s infrastructure.
4. Distribution and Integration: Organization’s existing security infrastructure can be acted upon any attacks if there is timely and effective consumption of
11

Advanced Threat Detection Based on Big Data Technologies
information stored. So at minimum, TAXII, STIX and SIEM integration should be supported by the security system. 5. Collaboration: This is the final key function of the architecture which refers to the ability of collaborating with peers and sharing approaches, strategies and experiences about a specific threat or related experiences in secure manner. Information Sharing Architectures
Most sharing communities exchange information using some variant of the following basic information sharing architectures (Johnson, et al, 2014): (i) centralized; and (ii) peer-to-peer shown in Figure 2. Benefits of Cyber Threat Intelligence Sharing (“Health Industry”, 2015; Johnson et al, 2014)
The main advantage of a collaborative approach in intrusion detection system is better view of global network attack activities. Collecting more and more information gathered at a single site from across the network can provide a more precise model of an attacker’s behavior and his intent. Traditional IDS’s are generally constrained within one domain of administrative. So in such environment, information about the global state of attack patterns is unexamined. So by collaboration, this global information can support organizations in ranking and addressing threats that they do perceive. And alerting other organizations about that threats which would not recognized before.
• Improved Cyber Situational Awareness: Information sharing enables organizations to collect knowledge, experiences, and analytic capabilities from their sharing partners. Thereby enhancing the defensive capabilities
Figure 2. Information sharing architectures
12

Advanced Threat Detection Based on Big Data Technologies
of both organizations. Each member in the community can profit from the experience and knowledge of other community members. • Enhanced Understanding of Cyber Threats: By sharing threat intelligence information, organizations gain more understanding about the threat environment and are able to design and deploy countermeasures, security controls, corrective actions and detection methods, based on the changes observed in the threat environment. • Cyber Threat Correlation: When raw intelligence data in the form of apparently unrelated observations is shared and analyzed, it can be correlated with other remaining data sets to build robust sets of information that are associated with a specific incident or threat. • Greater Defensive Agility: As technology advances, adversaries continually adapt their TTPs to counter the protective and detective measures implemented by network defenders. So organizations that possess the ability to detect and respond to changes rapidly, can shift from reactive to proactive cyber security strategies. • Improved Decision Making: In general organizations that consume and act based on shared information are able to make decisions with greater confidence and speed. When strategies of adversaries are understood better, it is possible to predict their actions and deploy defensive measures before they act. • Efficient Handling of Information Requests: When investigating or reporting cyber security incidents that is criminal in nature, information sharing is essential. Because organizations that have tools, processes and trained team in place to exchange information are better trained to handle such information requests. Ensuring that artifacts and the computers involved in the incident are treated as evidence and should be handled in a proper manner. • Rapid Notifications: When a cyber crime event occurs, the incident results in releasing information about another victim, so organizations are required to notify their business partners or affected customers. Organizations that understand their requirements of notification and have contact information, notification procedures and communications channels in place are able to rapidly broadcast breach notifications to business partners or affected customers.
Challenges for Collaboration
While there are many benefits of sharing information, there are also a number of challenges to effective sharing and collaboration that must be addressed. These
13

Advanced Threat Detection Based on Big Data Technologies
problems must be addressed before collaborative system can safely distributed among cooperating sites (Johnson, 2014; “Collaborative Information”, 2014).
• Lack of Circles of Trust: Everyone agrees to exchange but nobody trusts anybody. There is a clear lack of confidence, so trust building is essential, so that future systems should facilitate the exchange of data at different levels of confidence. Trust relationships form the basis for information sharing, but it can be time consuming to establish.
• Lack of Interoperable Standards: Standardized transport protocols and data formats can help to facilitate the secure, automated exchange of incident data between organizations, repositories and tools. But agreement on protocols and formats requires careful analysis of benefits and costs. Meanwhile each organization has tried to impose its own format which leads to lack of agility and inefficiency in the system. As far as cyber threats are concerned, the industrial community is working on the reporting format and standards like STIX, IOCs, Cybox, etc. that will solve the problem of standards.
• Limitation of Information Sources: When we have multiple sources, it is important to know where to look for information. It is even more important to know how to analyze and correlate it. Hence collaboration of cyber threat intelligence must facilitate the exchange of information from global and specific sources. It is essential to obtain a larger volume of first-class information (freshness), so it will be useful in battling against cybercrime.
• Lack of Skills: The shared information may only and specifically for a sector (industrial, financial, critical infrastructure, etc) but it should be considered by all the other agents of different industries and be able to provide analysis to learn from experience.
• Legal and Organizational Restrictions: In an organization, the legal terms may restrict the types of information that the organization can share with others. It may include limits on the types of information and the level of technical detail can be provided. Such restrictions are may be appropriate when they are addressing legitimate legal or privacy concerns; but same restrictions may diminish the quality and timeliness of shared information.
• Risk of Information Leakage: Information about the hacker’s strategies is useful for a network defender but sharing this information it may put into risk by exposing the detective or protective capabilities of the organization which results in shifting threat by the hacker. Additionally, disclosure of sensitive information, such as Personally Identifiable Information (PII), trade secrets, intellectual property or other proprietary information can result in financial loss, loss of reputation, violation of sharing agreements, legal action.
14

Advanced Threat Detection Based on Big Data Technologies
• Preserving Privacy: Organizations can openly participate in information sharing system, but it still requires that their contributions remain anonymous and preserves its privacy.
• Producing and Consuming Information: Organizations looking for producing threat information must have the necessary tools, infrastructure and training to do so. It must also have the infrastructure needed to access external sources.
• Challenges in Validating Data Quality and Reliability: Organizations must validate data they have generated about threat intelligence before storing and sharing it with other parties, and also they must look up for the data reliability.
Some Existing Collaborative Models
IBM X-Force Exchange
The IBM X-Force Exchange (“IBM X-Force”, 2016) built by IBM Security, is a new cloud-based platform that allows organizations to easily collaborate on security incidents, as well as benefit from the ongoing contributions of IBM experts and community members. This platform provides access to volumes of actionable IBM and third-party threat data from across the globe, including real-time indicators of live attacks, which can be used to defend against cybercrimes. The X-Force Exchange builds on IBM’s tremendous scale in security intelligence, integrating its powerful portfolio of deep threat research data and technologies, thousands of global clients, and worldwide network of security analysts and experts from IBM managed security services. Leveraging the open and powerful infrastructure of the cloud, users can collaborate and tap into multiple data sources.
McAfee Threat Intelligence Exchange
McAfee Threat Intelligence Exchange (“McAfee Threat” 2016), which aggregates and shares file reputation intelligence across the entire security infrastructure. McAfee Threat Intelligence Exchange receives threat information from McAfee GTI, STIX file imports, threat feeds coming via McAfee Enterprise Security Manager, and information coming from endpoint, mobile devices, application control, gateway, sandboxing technologies, data centers and from both Intel Security solutions and solutions from other vendors. Collecting data from all points in infrastructure provides information on threats that may be present only in environment, as many targeted attacks tend to be. In addition, this file reputation information is instantly shared across the entire ecosystem to all products and solutions connected to McAfee
15

Advanced Threat Detection Based on Big Data Technologies
Threat Intelligence Exchange via the McAfee Data Exchange Layer. This includes data classifications, file reputations, application integrity, and user context data. Any product or solution can be integrated onto the McAfee Data Exchange Layer and after that it is configured to determine what data to publish to their system and what data to listen, subscribe from the system.
ThreatExchange
This is new collaborative threat-detection framework by Facebook (“Threat Exchange”, 2016), with its participants such as Twitter, Yahoo, Tumblr, Pinterest, Box and Bitly, among others. It works like an online hub where multiple organizations can sign up and store data pertaining to the types of hacks and malicious activities they have experienced. This data includes malicious URLs, bad domains, malware and any sort of analytical data related to any type of malware. Once all information is collected, Facebook’s graph-database technology can correlate all the data points together and figure out new relationships, such as which malware seems to be talking to a particular domain or if a domain happens to be hosted on a bad IP address. The aim of the project is straightforward: to allow any business or IT professional who is interested in current and potential cyber attacks to review and contribute any information they may have related to current attacks or other potential cyber threats. It can be used by subscribed users to work with the information for any legitimate purpose, including research and prevention of attacks.
These exchanges of cyber threat information can improve response time by making threat intelligence more widely available to more players. Even automating sharing processes can further quicken response times.
CONCLUSION
Undoubtedly, fraud incidents and security breaches will continue to make headlines. Even though organizations are considering steps to address APTs and other attacks, the fact remains same that traditional security has lack of advanced capabilities to detect and protect against such attacks. With the help of huge generated data, big data brings transformative potential and big opportunities for various sectors. Deep learning and big data analytics are becoming two high-focus of data science today. By utilizing big data, threat intelligence with collaboration, organizations can preempt malicious activity on a wider and deeper scale with the help of robust risk and threat detection tools. But analytics such as big data and deep analytics currently
16

Advanced Threat Detection Based on Big Data Technologies
faces a number of practical limitations and further research is needed for building an operational solution. Research on deep learning needed for further exploration to incorporate specific challenges introduced by big data analytics, including highdimensional data, streaming data, scalability of models and distributed computing.
REFERENCES
Ambati, S. (2016). Deep learning: A brief guide for practical problem solvers. InfoWorld. Retrieved 26 June 2016, from http://www.infoworld.com/article/3003315/ big-data/deep-learning-a-brief-guide-for-practical-problem-solvers.html.html
Arel, I., Rose, D. C., & Karnowski, T. P. (2010). Deep machine learning-a new frontier in artificial intelligence research [research frontier]. IEEE Comput Intell, 5(4), 13–18. doi:10.1109/MCI.2010.938364
Ben-Zvi, G. (2016). Big data to the Rescue? Cyber Attacks Rank as Major Global Threat in 2016 - SQream. SQream. Retrieved 26 June 2016, from http://sqream. com/big-data-to-the-rescue-cyber-attacks-rank-as-major-global-threat-in-2016/
Bengio, Y., & LeCun, Y. (2007). Scaling learning algorithms towards, AI. In L. Bottou, O. Chapelle, D. DeCoste, & J. Weston (Eds.), Large Scale Kernel Machines (Vol. 34, pp. 321–360). Cambridge, MA: MIT Press. Retrieved from http://www. iro.umontreal.ca/~lisa/pointeurs/bengio+lecun_chapter2007.pdf
Big Data Working Group. (2013). Big data analytics for security intelligence. Cloud Security Alliance.
Chen, X. W., & Lin, X. (2014). Big data deep learning: Challenges and perspectives. IEEE Access, 2, 514–525. doi:10.1109/ACCESS.2014.2325029
Collaborative Defense Enriched by Dynamic Analysis. (2015). Business white paper | Collaborative Defense Enriched by Dynamic Analysis, Threat Central, developed with HP Labs.
Collaborative Information Exchange Models to Fight Cyber Threats. (2016). Retrieved 26 June 2016, from https://www.blueliv.com/corporate/the-use-of-social-mediamodels-in-the-fight-against-cyber-threats/
Effective fraud protection relies on deep analytics. (2016). IBM Big data & Analytics Hub. Retrieved 26 June 2016, from http://www.ibmbigdatahub.com/blog/effectivefraud-protection-relies-deep-analytics
17

Advanced Threat Detection Based on Big Data Technologies
Fossi, Egan, Haley, Johnson, Mack, Adams, … McKinney. (2011). Symantec internet security threat report trends for 2010. Symantec.
Fossi, M., Johnson, E., Turner, D., Mack, T., Blackbird, J., McKinney, D., & Gough, J. et al. (2008). Symantec report on the underground economy: July 2007 to June 2008. Technical Report. Symantec Corporation.
Fung, C. J., & Boutaba, R. (2013, May). Design and management of collaborative intrusion detection networks. In 2013 IFIP/IEEE International Symposium on Integrated Network Management (IM 2013) (pp. 955-961). IEEE.
Gantz & Reinsel. (2011). Extracting Value from Chaos. Hopkinton, MA: EMC.
Gantz & Reinsel. (2010). The Digital Universe Decade: Are You Ready. Hopkinton, MA: EMC.
Health Industry Cyber Threat Information Sharing and Analysis, Annual Review of HITRUST Cyber Threat XChange (CTX) -Summary of Findings and Recommendations, Public Discussion Document. (n.d.). Retrieved from www. HITRUSTalliance.net
IBM X-Force Exchange. (2016). Retrieved 26 June 2016, from http://www-03.ibm. com/software/products/en/xforce-exchange
Information Sharing Specifications for Cybersecurity | US-CERT. (2016). Retrieved 26 June 2016, from https://www.us-cert.gov/Information-Sharing-SpecificationsCybersecurity
Johnson, C., Badger, L., & Waltermire, D. (2014). Guide to cyber threat information sharing (draft). NIST Special Publication 800-150 (Draft).
Locasto, M. E., Parekh, J. J., Keromytis, A. D., & Stolfo, S. J. (2005, June). Towards collaborative security and p2p intrusion detection. In Proceedings from the Sixth Annual IEEE SMC Information Assurance Workshop (pp. 333-339). IEEE.
Ma, D., & Wang, Y. (2013). Network Threat Behavior Detection and Trend Analysis Based on the TDLC Model. SmartCR, 3(4), 285–297. doi:10.6029/ smartcr.2013.04.007
McAfee Threat Intelligence Exchange | Intel Security Products. (2016). Retrieved 26 June 2016, from http://www.mcafee.com/in/products/threat-intelligence-exchange. aspx
18

Advanced Threat Detection Based on Big Data Technologies
National Security Agency. (2013). The National Security Agency: Missions, Authorities, Oversight and Partnerships. Available: http://www.nsa.gov/public_ info/__les/speeches_testimonies/2013_08_09_the_nsa_story.pdf Security Intelligence With Big Data: What You Need to Know. (2013). Security Intelligence. Retrieved 26 June 2016, from https://securityintelligence.com/securityintelligence-with-big-data-what-you-need-to-know/ STIX, TAXII and CybOX Can Help With Standardizing Threat Information. (2015). Security Intelligence. Retrieved 26 June 2016, from https://securityintelligence.com/ how-stix-taxii-and-cybox-can-help-with-standardizing-threat-information/ The Global Risks Report 2016, 11th Edition, Insight Report. (2016). World Economic Forum, REF: 080116. Threat Exchange | Threat Exchange - Facebook for Developers. (2016). Facebook Developers. Retrieved 26 June 2016, from https://developers.facebook.com/products/ threat-exchange Virvilis, N., Serrano, O., & Dandurand, L. (2014). Big data analytics for sophisticated attack detection. ISACA Journal, 3, 22–25. Wolfe, T. (2016). 6 Tips for Using Big data to Hunt Cyberthreats. Dark Reading. Retrieved 26 June 2016, from http://www.darkreading.com/analytics/6-tips-forusing-big-data-to-hunt-cyberthreats/a/d-id/1278970 Wood, Nisbet, Egan, Johnston, Haley, Krishnappa, … Hittel. (2012). Symantec internet security threat report trends for 2011. Symantec.
19

20
Chapter 2
A Brief Review on Deep Learning and Types
of Implementation for Deep Learning
Uthra Kunathur Thikshaja Kyungpook National University, South Korea
Anand Paul Kyungpook National University, South Korea
ABSTRACT In recent years, there’s been a resurgence in the field of Artificial Intelligence and deep learning is gaining a lot of attention. Deep learning is a branch of machine learning based on a set of algorithms that can be used to model high-level abstractions in data by using multiple processing layers with complex structures, or otherwise composed of multiple non-linear transformations. Estimation of depth in a Neural Network (NN) or Artificial Neural Network (ANN) is an integral as well as complicated process. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. This chapter describes the motivations for deep architecture, problem with large networks, the need for deep architecture and new implementation techniques for deep learning. At the end, there is also an algorithm to implement the deep architecture using the recursive nature of functions and transforming them to get the desired output.
DOI: 10.4018/978-1-5225-3015-2.ch002
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
INTRODUCTION
The increase in demand for organizing the data and analyzing them is mainly due to the abundance in the raw data generated by social network users. Not all the data generated are linear and hence the single perceptron layer network or the linear classifier as it is popularly known, cannot be used for data classification. No hidden layers are required when we have a linearly separable data. In most other cases, one hidden layer is enough for a majority of problems. In few problems, two hidden layers are used for full generality in multilayer perceptrons. But lots of random initializations or other methods for global optimization are required. Local minima with two hidden layers can have extreme blades or spikes even when the number of weights is much smaller than the number of training cases (Panchal, 2011). Deep learning is a new AI trend that uses multi-layer perceptron network. Multilayer sensor containing multiple hidden layers is a deep learning structure. Deep learning architecture is a good way to extract feature, it can be used for specific issues of classification, regression, information retrieval, speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics.
Motivation for Deep Architecture
There are three main reasons for us to have a deep network. The first one is that insufficient depth can hurt, i.e. when the depth is two, the number of nodes in the flow graph (used for representing deep architecture) may grow very large. Theoretical studies (Hastad’s theorems) have shown that the order of complexity in O (n) for depth d and O (2n) for depth d-1.
The next reason is that, the human brain itself has a deep architecture. The visual cortex is well-studied and shows a sequence of areas each of which contains a representation of the input, and signals flow from one to the next. Each level of this feature hierarchy represents the input at a different level of abstraction, with more abstract features further up in the hierarchy, defined in terms of the lower-level ones.
The last motivation for a deep architecture is that cognitive processes are deep. Humans organize their ideas and concepts hierarchically. Humans first learn simpler concepts and then compose them to build more abstract ones. Engineers break up solutions into multiple levels of abstraction and processing.
21

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
Problems With Large Networks
Increasing the depth decreases the complexity. However, there are also problems associated (Vasilev, 2015). when the number of hidden layers is increased (depth). The first one is the Vanishing Gradients. This is a problem when the transfer of data from output layer through the hidden layers to the input layer becomes more and more difficult as the number of hidden layers is increased. This concept is called back propagation. Another important concern is Over-fitting. It is the phenomenon of fitting the training data too closely. The training data may be fitted really close and good, but these will fail badly in real cases. Scientists came up with several architectures to overcome the above mentioned problems. The upcoming sections describe some of the most common deep learning methods in use.
Deep Learning Methods
Autoencoders
An autoencoder is typically a feedforward neural network which aims to learn a compressed, distributed representation (encoding) of a dataset. Conceptually, the network is trained to “recreate” the input, i.e. the input and the target data are the same. In other words, we are trying to output the same thing that was provided as the input, but compressed in some way.
Restricted Boltzmann Machines (RBM)
Restricted Boltzmann Machines is a generative stochastic neural network that can learn a probability distribution over its set of inputs. RBMs are composed of a hidden, visible, and bias layer. Unlike the feedforward networks, the connections between the visible and hidden layers are undirected (the values can be propagated in both the visible-to-hidden and hidden-to-visible directions) and fully connected.
Figure 1. Representation of a basic autoencoder
22

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
Figure 2. Restricted Boltzmann Machine
Training RBM Using Contrastive Divergence Contrastive Divergence
Markov chain Monte Carlo methods typically take a long time to converge on unbiased estimates, but Hinton (2002) showed that if the Markov chain is only run for a few steps, the learning can still work well and it approximately minimizes a different function called “contrastive divergence” (CD). CD learning has been successfully applied to various types of random fields. RBM and Contrastive Divergence
RBMs have connections only between the hidden and the visible layer. Boltzmann Machines (BMs) are a particular form of log-linear Markov Random Field (MRF), i.e., for which the energy function is linear in its free parameters. To make them powerful enough to represent complicated distributions (i.e., go from the limited parametric setting to a non-parametric one), we consider that some of the variables are never observed (they are called hidden). By having more hidden variables (also called hidden units), we can increase the modeling capacity of the Boltzmann Machine (BM). Restricted Boltzmann Machines further restrict BMs to those without visible-visible and hidden-hidden connections.
The energy function E(υ,h) of an RBM is defined as: E(υ,h) = −b′υ −c′h − h′W υ
where W represents the weights connecting hidden and visible units and b, c are the offsets of the visible and hidden layers respectively.
This translates directly to the following free energy formula:
23

A Brief Review on Deep Learning and Types of Implementation for Deep Learning

∑ ∑ F(υ) = −b′υ − log ehi(ci +Wiυ)

i

hi

Because of the specific structure of RBMs, visible and hidden units are conditionally independent given one-another. Using this property, we can write:
p(h | υ) = ∏ p(hi | υ) i
p(υ | h) = ∏ p(υj | h) j

The single step contrastive divergence algorithm works as follows (Vasilev, 2015):
1. Positive Phase: An input sample v is clamped to the input layer. v is propagated to the hidden layer in a similar manner to the feedforward networks. The result of the hidden layer activations is h.
2. Negative Phase: Propagate h back to the visible layer with result v’ (the connections between the visible and hidden layers are undirected and thus allow movement in both directions). Propagate the new v’ back to the hidden layer with activations result h’.
3. Weight Update: w(t + 1) = w(t) + a(vhT − v′h′T ) where A is the learning rate and v, v’, h, h’, and w are vectors. The intuition behind the algorithm is that the positive phase (h given v) reflects the network’s internal representation of the real world data. Meanwhile, the negative phase represents an attempt to recreate the data based on this internal representation (v’ given h). The main goal is for the generated data to be as close as possible to the real world and this is reflected in the weight update formula.

Figure 3. Stacked encoders

24

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
Stacked Autoencoders
This network consists of multiple stacked autoencoders. The hidden layer of autoencoder t acts as an input layer to autoencoder t + 1. The input layer of the first autoencoder is the input layer for the whole network. The greedy layer-wise training procedure works like this:
Train the first autoencoder but with an additional output layer individually using the backpropagation method with all available training data.
Train the second autoencoder t=2. Since the input layer for t=2 is the hidden layer oft=1 we are no longer interested in the output layer of t=1 and we remove it from the network. Training begins by clamping an input sample to the input layer of t=1, which is propagated forward to the output layer of t=2. Next, the weights (input-hidden and hidden-output) of t=2 are updated using backpropagation. t=2 uses all the training samples, similar to t=1.
Repeat the previous procedure for all the layers (i.e., remove the output layer of the previous autoencoder, replace it with yet another autoencoder, and train with back propagation).
Steps 1-3 are called pre-training and leave the weights properly initialized. However, there’s no mapping between the input data and the output labels. For example, if the network is trained to recognize images of handwritten digits it’s still not possible to map the units from the last feature detector (i.e., the hidden layer of the last autoencoder) to the digit type of the image. In that case, the most common solution is to add one or more fully connected layer(s) to the last layer. The whole network can now be viewed as a multilayer perceptron and is trained using backpropagation (this step is also called fine-tuning).
Convolution Neural Networks
A Convolutional Neural Network (CNN) is comprised of one or more convolutional layers (often with a subsampling step) and then followed by one or more fully connected layers as in a standard multilayer neural network. The architecture of a CNN is designed to take advantage of the 2D structure of an input image (or other 2D input such as a speech signal). There are four key ideas behind Convolution Nets that take advantage of the properties of natural signals: local connections, shared weights, pooling and the use of many layers (Cun et al, 2015). Another benefit of CNNs is that they are easier to train and have many fewer parameters than fully connected networks with the same number of hidden units.
25

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
Figure 4. Image classification using a Convolutional Neural Network
CNN Properties
Convolutional layers apply a number of filters to the input. The input to a convolutional layer is an m x m x r image where m is the height and width of the image and r is the number of channels, e.g. an RGB image has r=3. The convolutional layer will have k filters (or kernels) of size n x n x q where n is smaller than the dimension of the image and q can either be the same as the number of channels r or smaller and may vary for each kernel. Subsampling layers reduce the size of the input. The last subsampling (or convolutional) layer is usually connected to one or more fully connected layers, the last of which represents the target data. Training is performed using modified backpropagation that takes the subsampling layers into account and updates the convolutional filter weights based on all values to which that filter is applied.
Architecture
A CNN consists of a number of convolutional and subsampling layers optionally followed by fully connected layers. The convolutional and pooling layers in Convolution Nets are directly inspired by the classic notions of simple cells and complex cells in visual neuroscience (Hubel & Wiesel, 1962). The input to a convolutional layer is an m x m x r image where m is the height and width of the image and r is the number of channels, e.g. an RGB image has r=3. The convolutional layer will have k filters (or kernels) of size n x n x q where n is smaller than the dimension of the image and q can either be the same as the number of channels r or smaller and may vary for each kernel. The size of the filters gives rise to the locally connected structure which are each convolved with the image to produce k feature maps of size m−n+1. Each map is then subsampled typically with mean or max pooling over p x p contiguous regions where p ranges between 2 for small images (e.g. MNIST) and is usually not more than 5 for larger inputs. Either before or after the subsampling layer an additive bias and sigmoidal nonlinearity is applied to each feature map. The figure
26

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
below illustrates a full layer in a CNN consisting of convolutional and subsampling sublayers. Units of the same color have tied weights. After the convolutional layers there may be any number of fully connected layers. The densely connected layers are identical to the layers in a standard multilayer neural network. Convolution Nets were also experimented with in the early 1990s for object detection in natural images, including faces and hands (Vaillant et al, 1994; Nowlan & Platt, 1995) and for face recognition (Lawrence et al, 1997).
Reasons for the architecture to be best suited for images:
1. In array data such as images, local groups of values are often highly correlated, forming distinctive local motifs that are easily detected.
2. Second, the local statistics of images and other signals are invariant to location. In other words, if a motif can appear in one part of the image, it could appear anywhere, hence the idea of units at different locations sharing the same weights and detecting the same pattern in different parts of the array.
3. Deep neural networks exploit the property that many natural signals are compositional hierarchies, in which higher-level features are obtained by composing lower-level ones. In images, local combinations of edges form motifs, motifs assemble into parts, and parts form objects. Similar hierarchies exist in speech and text from sounds to phones, phonemes, syllables, words and sentences (Cun et al, 2015).
Recurrent Neural Networks
The idea behind RNNs is to make use of sequential information. Thanks to advances in their architecture (Hochreiter & Schmidhuber, 1997; ElHihi & Bengio, 1995).
Figure 5. Full layer in a CNN
27

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
and ways of training them (Sutskever, 2012; Pascanu et al, 2013) RNNs have been found to be very good at predicting the next character in the text (Sutskever et al, 2011; Mikolov et al, 2013). or the next word in a sequence (Mikolov et al, 2013). In a traditional neural network we assume that all inputs (and outputs) are independent of each other. But for many tasks that’s a very bad idea. If we want to predict the next word in a sentence it is better to know which words came before it. RNNs are called recurrent because they perform the same task for every element of a sequence, with the output being dependent on the previous computations. Another way to think about RNNs is that they have a “memory” which captures information about what has been calculated so far. In theory RNNs can make use of information in arbitrarily long sequences, but in practice they are limited to looking back only a few steps.
The above diagram shows a RNN being unrolled (or unfolded) into a full network. By unrolling we simply mean that we write out the network for the complete sequence. For example, if the sequence we care about is a sentence of 5 words, the network would be unrolled into a 5-layer neural network, one layer for each word. Types of RNN Bidirectional RNNs
Bidirectional RNNs are based on the idea that the output at time t may not only depend on the previous elements in the sequence, but also future elements. For example, to predict a missing word in a sequence you want to look at both the left and the right context. Bidirectional RNNs are quite simple. They are just two RNNs stacked on top of each other. The output is then computed based on the hidden state of both RNNs.
Figure 6. Representation of a RNN
28

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
Figure 7. Bidirectional RNNs
Deep (Bidirectional) RNNs Deep (Bidirectional) RNNs are similar to Bidirectional RNNs, only that we now have multiple layers per time step. In practice this gives us a higher learning capacity (but we also need a lot of training data). PROPOSED ALGORITHM FOR DEPTH ESTIMATION IN DEEP NETWORKS In this section, we present a detailed overview of our proposed scheme. In our scheme, we make use of the recursive nature of the functions and transform them to implement the multiple hidden layers in a NN. Each function has a complex computation to perform and the result of one function is passed on to the next function recursively, similar in a way data is propagated in a multilayer perceptron network. The same process is repeated until the computation is complete (Sheperdson, 1963). Now, the Figure 8. Deep RNNs
29

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
Algorithm 1. Transcursive algorithm for data propagation
For (every input) { If (function1 produces desirable output) { Pass the result of function1 to function2 } Else { Transform the function Pass the result of function1 to function2} End for
final output is propagated back to the main function (similar to back propagation in multilayer perceptron network). Whenever there is an undesirable output, we transform the function (similar to modifying the weights in a NN) and pass the results of this newly modified function the next layer (Thikshaja et al, 2016). This process is repeated until we get the desired output. This scheme provides an effective way of data propagation without or negligible loss in data.
RESULTS AND CONTRIBUTION We compare the complexity of the transcursive algorithm that we have proposed with the complexity of the existing recursive algorithms (Vasilev, 2015). It is an ongoing research and the order of complexities of the transcursive algorithm will be less when compared to the existing ones as it uses the transformation function to effectively modify so that it can provide the desired output. Table 1 shows the
Figure 9. Recursive model used for data propagation
30

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
Table 1. Complexities of recursive functions

Type of Algorithms Binary Search Sequential Search Tree Traversal Selection Sort Merge Sort Fibonacci recursion Transcursive function where T(x) is the transformation function.

O(log n) O(n) O(n) O(n^2) O(n log n) O(2^n) T(x) O(2^n)

Complexity

complexity of different recursive functions. We can see from the table that algorithms like Selection sort and Fibonacci recursion have higher complexity, so does the transcursive function. Though the order of complexity of the transcursive function is also high, it will yield better results because of its adaptive nature and the data loss will be less as the function is transformed to produce output similar to the expected results. Figure 3 shows the graphical representation of the different time complexities of the functions listed in the table.

CONCLUSION
Deep learning has definitely got many advantages than the existing learning methods and will yield success. It is still in its initial stage of development and a lot of research has to go into it to make the fullest use of the advantages offered by deep learning. This paper illustrates the necessity of introducing deep learning by analyzing the advantages of deep learning to the shallow learning, introduces several typical deep learning models in detail, and introduces effective training methods. There is still a lot of work to be studied for deep learning, using efficient parallel algorithms to improve the training speed.

REFERENCES
ElHihi, S., & Bengio, Y. (1995). Hierarchical recurrent neural networks for longterm dependencies. Proc. Advances in Neural Information Processing Systems, 8. Retrieved from http://papers.nips.cc/paper/1102-hierarchical-recurrent-neuralnetworks-for-long-term-dependencies
31

A Brief Review on Deep Learning and Types of Implementation for Deep Learning
Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural Computation, 9(8), 1735–1780. doi:10.1162/neco.1997.9.8.1735 PMID:9377276 Hubel, D. H., & Wiesel, T. N. (1962). Receptive fields, binocular interaction, and functional architecture in the cats visual cortex. The Journal of Physiology, 160(1), 106–154. doi:10.1113/jphysiol.1962.sp006837 PMID:14449617 Lawrence, S., Giles, C. L., Tsoi, A. C., & Back, A. D. (1997). Face recognition: A convolutional neural-network approach. IEEE Transactions on Neural Networks, 8(1), 98–113. doi:10.1109/72.554195 PMID:18255614 Mikolov, T., Sutskever, I., Chen, K., Corrado, G., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. Proc. Advances in Neural Information Processing Systems, 26, 3111–3119. Panchal, Ganatra, Kosta, & Panchal. (2011). Behavioral Analysis of Multilayer Perceptrons with Multiple hidden neurons and hidden layers. IJCTE, 3(2). Pascanu, R., Mikolov, T., & Bengio, Y. (2013). On the difficulty of training recurrent neural networks. Proc. 30th International Conference on Machine Learning, 1310– 1318. Sheperdson, J.C, & Sturgis, H.E. (1963). Computability of recursive functions. ACM Digital Library, 10(2). Sutskever, I. (2012). Training Recurrent Neural Networks (PhD thesis). Univ. Toronto. Sutskever, I., Martens, J., & Hinton, G. E. (2011). Generating text with recurrent neural networks. Proc. 28th International Conference on Machine Learning, 1017– 1024. Thikshaja, U. K., Paul, A., Rho, S., & Bhattacharjee, D. (2016). An adaptive transcursive algorithm for depth estimation in deep networks. IEEE Conference Publications. doi:10.1109/PlatCon.2016.7456783 Vaillant, R., Monrocq, C., & LeCun, Y. (1994). Original approach for the localisation of objects in images. Proc. Vision, Image, and Signal Processing, 141, 245–250. doi:10.1049/ip-vis:19941301 Vasilev. (2015). An introduction to deep learning from perceptrons to deep networks. Toptal.
32

33
Chapter 3
Big Spectrum Data and Deep Learning Techniques for
Cognitive Wireless Networks
Punam Dutta Choudhury Gauhati University, India
Ankumoni Bora Gauhati University, India
Kandarpa Kumar Sarma Gauhati University, India
ABSTRACT The present world is data driven. From social sciences to frontiers of research in science and engineering, one common factor is the continuous data generation. It has started to affect our daily lives. Big data concepts are found to have significant impact in modern wireless communication systems. The analytical tools of big data have been identified as full scale autonomous mode of operation which necessitates a strong role to be played by learning based systems. The chapter has focused on the synergy of big data and deep learning for generating better efficiency in evolving communication frameworks. The chapter has also included discussion on machine learning and cognitive technologies w.r.t. big data and mobile communication. Cyber Physical Systems being indispensable elements of M2M communication, Wireless Sensor Networks and its role in CPS, cognitive radio networking and spectrum sensing have also been discussed. It is expected that spectrum sensing, big data and deep learning will play vital roles in enhancing the capabilities of wireless communication systems.
DOI: 10.4018/978-1-5225-3015-2.ch003
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
INTRODUCTION
The present world is data driven. From social sciences and humanities to frontiers of research in science and engineering, one common factor that is emerging is the continuous data generation (Cui, Yu and Yan, 2016). It has started to affect our daily lives. The scanned copies of old books and digital versions of recent editions in libraries, fluctuations in stock markets, daily transaction of banks, high definition movies and audio content, continuous multimedia interaction over internet, super resolution television broadcasts, diagnostic records etc are some of the major factors that are generating a significant portion of data. More importantly, some other generators are related to internet based social media services especially Facebook, Tweeter etc. which contribute (30 billion pieces of content per day for Facebook, over 90 million tweets in a day by Tweeter etc.) huge volumes of data daily. A very busy stock exchange like the one in New York generates 1 Terabytes of data daily while a single flight of the Airbus A 380 generates 640 Terabytes of data (Bi, Zhang, Ding & Cui, 2015). This voluminous expansion of data has been a decisive factor which has contributed towards the emergence of new areas of research that have significant linkages with data. In a worldwide scale, number of internet users is increasing day by day. More than 4 million users use internet daily. It is assumed that by 2020, 50 billion numbers of devices will be attached with internet and it will require separate slots for use of spectrum both in wired and wireless modes and need high end support for storage of information (Kadir, Shamsuddin, Rahman & Ismail, 2015). In Nature and another leading science and technology magazines, several special issues have been published and indicators identified to enlarge the scope of big data related research in technological domains. The most significant driving factor behind the importance being attached to big data is the fact that it is unlike the presently known forms of data blocks and along with present day technology, creates an opportunity to formulate innovative means of data driven applications. Actually big data presents a very large system which is complicated to handle using traditional data base management systems. According to popular definitions, big data has been popularized with ‘five Vs’. These are volume, value, variety, velocity and veracity. Big data is a continuously expanding data base that consists of large number of data from our surroundings collected from several sources like sensors, media, videos etc. In modern wireless communication system, big data concepts are likely to have significant impact and are becoming an interesting domain of research. Communication especially wireless and mobile, are expected to be transformed due to the use of big data concepts. It is expected to be an aid to the overall quality of service (QoS) in terms of better spectrum management, call handovers, link adaptability and reliability, channel assignments, geo-location and traffic management, routing, etc. to name a few. Much of the deployment and
34

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
design of emerging wireless and mobile networks are expected to go through a paradigm shift due to the use of big data concepts. The present era is also known for the evolution of smart technologies and one such development which has brought cognition in the lives of the people worldwide is Cyber Physical Systems. Around 2006, it was National Science Foundation (NSF) that coined this term. Since then, wide and deep research activities on CPS have been carried out by industries and academicians. The developments in this domain have been fuelled by the advances taken place in the genres of embedded systems, communications, sensor networks, computing and control engineering. CPS have emerged as a vital technology that can enhance human-to-human, human-to-object and object-to-object interactions. Big data,, Cyber Physical System (CPS) and deep learning are expected to contribute significantly towards the evolution of a new generation of communication technologies which will nullify most of the constrain currently encountered and improve QoS, bandwidth utilization and lower power consumption to levels previously unheard of.
This review attempts to summarize basic concepts of big data, the evolution trends, big data in communication scenario, deep learning based analytics of big data and its relevance for big data and its relevance for emerging communication scenario, CPS and it concludes with the current trends of big data and the architectural changes being formulated for use in upcoming high data rate mobile communication.
Basic Terminologies Related to Big Data
Big data, the expanding data set is defined in many ways. The big data concept with three Vs characteristics was first formulated by Doug Laney, system analyst of Gartner (earlier known as META group) in 2001 (Manyika, Chui, Brown, Bughin, Dobbs, Roxburgh and Byers, 2011). According to Laney, ‘Big data is a high volume, high velocity and high variety information assets that demand cost effective, innovative forms of information processing for enhanced insight and decision making’. Gartner is known as the pioneer of big data research. Actually, these three Vs concept is not sufficient to explain big data. Later on, IBM, Microsoft etc used this concept with some extending ideas to describe big data after ten years. In 2011, International Data Corporation (IDC); an American market research, advisory and analysis firm, defined big data as ‘Big data technologies designed to economically extract value from very large volumes of a wide variety of data, by enabling high-velocity capture, discovery, and/or analysis (Gantz and Reinsel, 2011). Figure 1 shows different sources of big data. The five Vs characterizing big data are discussed below:
• Volume: It is related to the content size, occurs naturally and represents its enormous and expanding ingredients. As the size become larger, storage and processing need to change. Data volume is related to real world. In big
35

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Figure 1. Sources of big data
institute or in a big industry, huge amounts of data are produced every day. In Tweeter, daily almost millions of users sent text messages, videos and images daily. Similarly, in other social media like Facebook, Gmail etc. the processing mechanisms encounter huge amounts of data. Traditional database systems are not oriented to deal with such huge and expanding volumes of such data. It is assumed that the business data volume of companies all over the world may double in every 1.2 years (Chen, Mao and Liu, 2014). The presently used 3G/4G and legacy wireless/ mobile communication devices are expected to contribute significantly to this growth. With uploaddownload speeds varying between 10 Mbps to 60 Mbps, 4G enabled mobile systems are fast accelerating accumulation of big data. This aspect will be further accelerated with the deployment of milimetric wave (mMW) based 5G technologies when internet of thing (IoT) concepts will enhance manmachine interfaces (MMI). The increasing volume of data is to be dealt with cognitive analytics which will enable devices to use predictive approaches of processing, increasing reliability significantly.
36

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
• Variety: The information sources produce many types of data formats. Numeric data are structured in conventional formats. The data types like audio, email, video etc represent unstructured format. Unstructured data increases rapidly due to the rising demand of uses of mobile, internet, video calling, social media like Facebook, Twitter etc. As for example, in Facebook, 34,722 likes are registered in one minute; Twitter has 645 million users all over the world with multiple orientations and profiles (Chen, Mao and Liu, 2014). Therefore, various types of data formats are required to be handled. To manage and combine such types of data, we need big data oriented tools. A few are batch processing, real time processing, hybrid processing etc. With 4G and 5G mobile technologies data variety shall increase further. Most of the applications in communication domain will require support from machine learning (ML) tools to develop proper understanding about data variety and its handling.
• Velocity: Data come from various sources with varying rates of recovering, storage and demonstrate irregularity in velocities of acquisition and distribution. In real time applications, the sources like sensors, transducers etc give data streams in unpredictable speeds. To generate response appropriately and to provide quick reaction, data velocity is a challenging factor for the big data applications. Big data tools like real time processing, hybrid processing etc. is able to handle the velocity aspect of expanding data volumes (Casado and Younas, 2014).
• Veracity: It is also one of the parameters of big data. Data types, volume etc parameters create the complicacy issues in big data. Transformations of data, network link modification, distribution etc are difficult because of the variety of sources. Therefore, it is also a challenge to reduce this complication. The authenticity aspect places a critical role in applications. This aspect is integral to big data tools. Veracity factor is common for real time processing, batch processing and hybrid processing tools. Newly evolving coding and cryptographic aids including stenography shall be critical in enhancing reliability of such systems. The authenticity aspect of big data is being handled by currently available and evolving technologies some of which are designed to work on autonomous modes. Some of the works related to big data characteristics are as mentioned in Table 1.
Big Data: Evolving Scenario
The evolution of big data is considered according to its size and processing or storing methods. From 1980, till the present times, the sizes of big data have changed from megabyte (MB) to exabyte (XB). Similarly, processing techniques are also changing
37

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Table 1. A few works related to big data characteristics

Sl No. 1 2
3
4
5
6

Author
Cui, L., Yu, F. R. & Yan, Q.
Kadir, E. A., Shamsuddin, S. M., Rahman, T. H. and Ismail A. S.
Casado R. & Younas M.,

Year 2016 2015
2014

Chen, M. & Mao S. & Liu Y

2014

Manyika, J., Chui, M., Brown, B., Bughin, 2011 J., Dobbs, R., Roxburgh, C., & Byers, A. H.

Gantz, J. & Reinsel, D.

2011

Contribution
Review of big data and SDN
Explanation on big data architecture and relation with b5G communication.
Described the characteristics of big data and processing tools.
Review of big data and connecting technologies.
Work includes meaning of big data and the challenges of application.
Discussion about the trend of big data analysis and trend of some data base system.

day by day. Earlier in business sector, in institutions, medical or in banks, data records were manageable. As the demand of digitization is increasing, the data used in every field is changing from hard copy to soft one. So now hard copy garbage is reduced but softcopy storing problem is increasing fast. Because of this, big data concepts are getting introduced in all sectors like business, medical, education, administration, scientific research etc. In this review, the evolution is presented in terms of size and processing tools of big data. The evolving stages of big data have been shown in Figure 2.
In the late 1970’s, the business data records presented the earliest form of and ‘big data’ the sizes started to grow from megabyte (MB) to gigabyte (GB) range. The ‘database machine’ concept launched in that time (Bi, Zhang, Ding & Cui, 2015). This technology could assemble hardware and software parts of a system. The aim of this assembling was to process big data at low cost. But hardware based system could not process and store efficiently as data continued to grow. In 1980s, people introduced parallel data base system (Gray & Gray, 1992) to fulfil the requirements of the big volumes of data. This is due to the fact that in the late 1980, size of big data started to turn to the terabyte (TB). This type of big data handling is impossible with normal processing in earlier generation, computing machines. To store and handle such growing data, cluster based architecture is required and the framework should have its own processor, storing device and disk. The parallel database processing have been used to increase the storage performance, data distribution and related processing tasks. A new transition was seen in 1990s. It was a transform from TB to petabyte (PB). With structured and unstructured web pages, it become difficult to handle only with parallel databases because structured data handling is quite easier than unstructured data (Jardak, Mähönen, & Riihijärvi, 2014). As the internet
38

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Figure 2. Big data evolution with respect to its size
became more and more popular and available almost everywhere, the search engines like Google faced challenges to store data. Therefore, Google created Google File System (GFS) to handle big data (Hu, Wen, Chua & Li, 2014; Gantz & Reinsel, 2011) NoSQL is another database system with high storage capacity of big data, reliable and has fast operation ability. In the year 2007, database software pioneer, Jim Gray called this shifting of architecture as ‘fourth paradigm’ (Hey, Tansley & Tolle 2009). In coming years, as the development in big data storage and processing continued, it also saw a further increase in the data size turning from PB to XB. Though the TB data handling is simple nowadays, but for XB size, till now very few reliable methods are openly available. Major IT corporate houses like Oracle, IBM, Google etc. have started research to formulate solutions for such big data. IBM invested USD 30 billion in the research of big data (Gantz & Reinsel, 2011). Several governments such as United States have put stress on big data issues. Such efforts are likely to provide solutions and convergence mechanisms to support the enormous surge in data uses that are probable with the deployment of 4G and 5G mobile technologies all over the world. Mostly with 5G communication, huge data records will be created and it will require processing handled by big data methods. Obama government announced a USD 200 million investment in big data research. It was started on March 2012. After that, in Japan, the big data development process also started in July 2012. These are some examples of governments attaching
39

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
importance to big data. In 2012, United Nations also produced a report on big data utilization for social benefits (Gantz & Reinsel, 2011).
There are some analytical tools to deal with big data. These algorithms help to design big data according to its definition. Stochastic model is a tool to estimate probability distribution of information having random variations of more than one value over time. Such random variations occur due to the fluctuation of the past values during a time period. Large scale data analysis related to big data treatment makes information more meaningful and well organized in nature. Data mining enables analysis in different perspectives including that available in compressed forms for storage and presented in uncompressed structure during retrieval. Data mining is useful to extract data from a set huge storage. Machine learning (ML) is also a tool for big data analysis which is based on pattern recognition and computational learning theory. ML solutions are preferred for retrieving data from big storages. Some related works are summarized in Table 2.

BIG DATA, MACHINE LEARNING, DEEP LEARNING, AND COGNITIVE TECHNOLOGIES FOR BETTER MAN MACHINE INTERACTION (MMI)
As mentioned earlier, big data represents a massively expanding collection of data related management with five distinct characteristics. Such data sets are expectedly difficult to handle with traditional processing and management methods and require special mechanisms. With a high volume, high velocity and increasing varieties in data, it requires new processing methods so that big data provides an increase

Table 2. A few works related to big data evolution

Sl No. 1 2
3
4 5

Author
Bi S., Zhang, R., Ding, Z. & Cui, S.
Jardak, C., Mähönen, P. & Riihijärvi, J.
Hu, H., Wen, Y., Chua, T. S., & Li, X.
Hey, T., Tansley, S., & Tolle, K. M.
DeWitt, D., & Gray, J.

Year 2015 2014
2014
2011 1992

Contribution Discussion on the challenges and opportunities in the designing of wireless communication networks to handle big data trouble. Processing mechanism of big data in terms of wireless communication aspect. Hadoop and HBase are two parallel processing tools to analyze big data. Survey of big data analytical platforms and discussion on a systematic framework with four modules.
Explanation of ‘fourth paradigm’ for scientific exploration.
Proposed parallel data base system (first time in the computing).

40

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
in performance in decision making and enhance the processing of information in various industries, social networks like Facebook, Twitter etc. Big data with high velocity, high volume, high value, variety and veracity needs better management tools for making them beneficial for specific applications. Due to the exponential growth of data we have to train computers more than like human as part of ML methods and formulate approaches for big data handling. ML is an approach having pattern recognition, classification, prediction etc. attributes and can generate as human like decision making.
Machine Learning (ML)
ML mimics human like behaviour with training and some mathematical representation of data and the ultimate result of achieving greater efficiency and autonomy in decision making. Sources of big data are always different. Data from sensors, satellites, media etc are of different form. So it is a challenging task to organize and prepare data for storage and processing to store or process. But ML algorithms have this ability to manage it. Arthur Samuel defined machine learning as ‘Field of study that gives computers the ability to learn without being explicitly programmed’ (Dean and Ghemawat, 2008). ML consists of five different methods. These are Artificial Neural Network (ANN), Artificial Neuro Fuzzy System (ANFS), Genetic Algorithm (GA), combination of ANN, ANFS, GA and clustering of all these four methods.
ANNs are learning based non-parametric predictive tools that capture variations in model free data applied to them. The basic analogy is linked to the biological neural network which is based on parallel processing. Similarly, ANNs work generating parallel processing by linking layers of artificial neurons tracking variations in input data by resorting to connectionists computing. In situations, it either requires a reference (supervised learning) or may avoid references (unsupervised learning). Once configured properly and trained adequately, ANNs can be reliable tools in big data set-ups.
Fuzzy systems are known to deal with uncertainty and can handle finer variations. Their limitations are that these cannot learn or retain the learning which ANNs do. Therefore, Fuzzy systems in combination with ANNs provide advantages of both the domains which configured as neuro fuzzy systems (NFS) or fuzzy neural systems (FNS). In fuzzy based ML system, there are fuzzification or defuzzification block, a rule base and an inference system. At the end of the learning phase (which is fast), the fuzzy based systems demonstrate the abilities to track finer variations and deal with uncertainity, fast processing, adaptability, ability to handle real time data and decision support. NFS or FNS have been explored as part of big data frameworks. In Kala, Shukla and Tiwari (2009), authors discussed neuro fuzzy system for machine learning for big data system. Actually as the data size become larger, training time
41

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
is also become long. Therefore traditional ANN failed to train these types of huge data. In Eibagi (2014), authors analysed big data using fuzzy classification system. This powerful system is the combination system of two methods namely, if then rules and linguistic variable. In Bharill, and Tiwari (2016), big data treatment is done using fuzzy based classification system.
Cognitive Computing
It has deep relation to big data treatment. Simply speaking, this is a method of a self learning system. In cognitive computation, data mining, pattern recognition, natural language processing (NLP) etc are used to study and mimic human brain functions. Cognitive computing enacts human and machine interaction and penetrates the complexities of big data. Actually, cognitive computing is a method which has the capability to react just like the thoughts of the human brain itself. As already mentioned, cognitive technology can be used in processing of big data in several fields. In bank sector, online payment operation, speech recognition as a response to a call at customer care and for caller identification, voice recognition etc have used cognitive computing. Among scientific domains, astronomy is one of the areas where big data has been associated from early days. The telescope named (LOFAR) produces 100TB data set per day (Garrett, 2014). Similarly another telescope named Square Kilometer Array (SKA) produce more than billions of data bytes per day (Garrett, 2014) etc. Due to the quantity, dynamic nature of data generation and variation in data types astronomical data are treated as big data. Cognitive computing is used to analyze these data. In Mane and Salian (2015), authors discussed about the application of cognitive computing and big data to optimized decision states.
Deep Learning
It is a part of ML. The traditional ANN has two prominent parts; hard craft feature extractor (in terms of hidden layer) and trainable classifier (in terms of the output layer). ANNs with many hidden layers is usually called a Deep Neural Network (DNN) and the associated learning is usually called deep learning. According to many researchers the word ‘deep’ in deep learning means that the ANN has more than two hidden layer. Sometimes, cascaded ANN structures are used to form deep learning architectures (Agarwalla and Sarma, 2016). For another group of researchers, the word ‘deep’ in deep learning is due to some unlabelled data. Some people think that this ‘deep’ means that there is no need for human invented features in deep learning (Kriegeskorte, 2015). The learning of a deep network is formulated in such a way that the intermediate feature extractors are also trainable. In deep learning, a trainable feature extractor stage enables learn various levels of features. Actually
42

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
deep learning is a hierarchical representation of features based on conditions of learning. Huge amounts of unsupervised data are used in deep learning to extract complex representation automatically.
Deep learning has some special characteristics to make it different from other learning approaches. Two layered network cannot be considered as deep learning because there is no feature hierarchy. Kernel and SVM methods of traditional ANN are also not in the deep learning category. Deep learning has three types of architectures. These are feed forward, feed-back and bidirectional learning. DNNs perform learning without requiring external feature extractors and in certain cases labeled data to follow the patterns. Deep learning is an acceptable solution for big data handling problem. Practitioners and specialist of big data analytics are using deep learning to handle real world problems. For some useful operations, like decision making, information processing and related purposes deep learning can be considered as practical source of knowledge. In Mane and Salian (2015), some aspects of deep learning and big data are discussed. The most important nature of deep learning is that it can automatically extract data from a large volume of unsupervised data. In big data analysis, streaming and fast moving of input data is a challenging task. For these types of operations, deep learning is an essential way of handling expanding volumes of data. In Agarwalla and Sarma (2016), authors explained about the work of deep learning in big data processing is effective used to obtain efficient processing. In Chen and Lin (2014), authors reviewed the performance of deep networks on big data. Here, they discussed that deep learning can be applied in all characteristics of big data like volume, variety, veracity etc. Some related works on big data and machine learning are summarized in Table 3.
BIG DATA AND DEEP LEARNING IN EMERGING MOBILE COMMUNICATION SCENARIO
In mobile communication era, users always have the expectation of increase in the capacity and speeds of data services. Wireless communication started with the first generation techniques which evolved through each subsequent generation to offer increasing speeds and better capacity in terms of data transmission and reception. Up to 2006, the peak data rate was around 54 Mbps which during the last decade evolved at explosive rate to reach the present state where fourth generation (4G) data speeds touched 600 Mbps. At the end of 2007, 295 million users were using 3G networks (Dehuri and Sanyal, 2015) and by 2015 this figure multiplied several times with the availability of 3G/4G hand held devices, legacy systems and penetration of Wi-Fi/ WiMax services. It has been predicted that by 2020, around 20 billion devices will be in connected state and a huge portion of there will be using 3G/4G/5G and Wi-Fi
43

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Table 3. A few works related to big data and machine learning

Sl No.

Author

1

Agarwalla, S., & Sarma, K. K.

2

Bharill. N. & Tiwari, A.

3

Mane D. & Salian S.

4

Kriegeskorte, N

5

Hasan. M.

6

Xu, Y., Zeng, M., Liu, Q., &

Wang, X.

7

Kune R., Konugurthi P.K.,

Agarwal, R. Rao C. & Buyya R.

8

Yang Xu, Mingming Zeng,

Quanhui Liu & Xiaofeng Wang

9

Chen, X. W. & Lin, X.

10 Garrett M.A.

11 Eibagi, A.

12 Dean J & Ghemawat S.

13 Kala, R., Shukla, A., Tiwari, R.

14 Leung, S.T. & Gobioff, H.

Year 2016 2016 2015 2015 2014 2014 2014
2014 2014 2014 2014 2008 2009 2003

Contribution
Application of deep learning based technique in big data in case of speaker recognition.
Fuzzy based classifier to handle big data.
Describes the benefit of combination of big data, cognitive computing and big data testing.
Explanation related to DNN.
Explanation of application of GA to analyze big data.
Discussion on neuro- Fuzzy system on big data analysis.
GA based technique for big data cloud where decoupled computational and data services are offered.
GA based multilevel association method in case of big data analysis.
Big data processing with focus on future trends.
Explanation on the treatment of big data of astronomical research.
Discussion on hybrid intelligent system like hybrid neuro fuzzy system to analyze big data.
Discussed about ML based map reduce programming model.
Mentioned a concept on FNN to deal with large data set.
Mentioned Google file system

infrastructure. This expansion ensured that accumulated data continuously increased in size necessitating formulation of more reliable and efficient analytic tools. The upcoming technologies in wireless communication known as fifth generation or 5G are likely to provide data rates around 1Gbps which shall complicate matters further. Communication shall be taking place through dense networks requiring link adaptability for better QoS. In such a scenario, viable solutions and efficient analytic tools are likely to be autonomous the working of which shall be driven by deep learning based processing.
The accumulation of digital data through mobile communication set-ups has made it necessary to develop and deploy analytic tools that work with very less latency. Certain researches are going on in this domain. In Suzhi, Zhang, Ding and Cui (2015), authors proposed a framework of big data driven mobile network for 5G communication network optimization. The 5G communication is expected to be
44

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
increasing data communication speeds (≅1Gps) and have ten times more connections with better QoS in comparison with 4G/legacy communications (Hasan, 2014). Big data with structured and unstructured content need high transmission rates. The 5G attributes (Eibagi, 2014) including network function virtualization (NFV), cloud computing (CC), machine to machine (M2M) communication, massive MIMO etc. essentially shall be closely linked to big data situations. In case of transmission rate, spectral density, delay, reliability and battery life expected etc, the 5G performance promises to be considerably better than 4G/ legacy systems (Eibagi, 2014). Similarly, big data also need better mobile communication systems to store, analyze and process data. Better communication links shall ensure smooth flow of data from various sources which will get accumulated for processing by cognitive analytic tools. In this respect, 4G/5G mobile communication and big data shall be closely linked and gelled well by deep learning techniques.
Upcoming and legacy standards of wireless networks are attached with wireless sensor networks (WSN), Wi-Fi etc. The forth coming 5G communication and milimetric wave (mMW) line of sight (LoS) Wi-Fi with the expected data speeds in gigabits per second (Gbps) range is likely to inundate presents day bases data. In such a scenario, data analysis shall be highly dependent on intelligent approaches most of which are likely to be based on deep learning. In 5G standard, WSNs are expected to play important roles in data sensing, accumulation, processing and distribution. For WSN, data management and post processing are also big tasks. Above all, the collected data volume shall be huge and continuously expanding. Exploring innovative data mining methods and deployment of appropriate infrastructure are gearing up to meet such challenges but intelligent solutions shall become indispensible. Due to the particular nature, the traditional data mining methods are not suitable for WSNs. Therefore, some modifications are required in the process of data mining. In Casado and Younas (2015), these methods are discussed. According to Casado and Younas (2015), data mining in WSN is the process of extracting information related with application and pattern and process it in new data streams. In same work, authors explain algorithms and direction of approaches of data mining for WSN with different choices of the solution. A more noticeable aspect shall be the role played by deep learning in modeling stochastic wireless channels. This aspect is discussed next. A conceptual diagram depicting 5G communication and big data is shown in Figure 3.
The emerging scenario of 5G communication shall be characterized by relentless M2M communication links. There shall be wireless communication in Personal Area Networks (PAN), Neighbourhood Area Network (NAN) and Local Area Networks (LAN) supported by 1 to 10 Gbps links based on mMW and optical fiber backbones (Peng, Li, Zhao and Wang, 2015). Banking, scientific institutions, computational clusters etc. linked to central routing and access hubs are likely to be provided by
45

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Figure 3. 5G communication and big data
10 to 100 Gbps links as per requirements. These wireless/wired connections are likely to generate huge volumes of data and the analytics shall be based on cognitive principles. In the PAN and WAN levels, there shall be multiple microcells each generating considerable data with M2M connections. Spectrum conservation shall be a sought after process and it will be driven by cognitive sensing techniques. Deep learning based methods will determine traffic loads, predict congestion and find routing paths enabling free flow of data between source and destination. Proper wireless profiling and link adoption will ensure better QoS. In each of these areas, deep learning will play significant roles by providing forecast, prediction and representative models for visualization, planning, resource utilization and provide enhanced performance.
Similarly a probable scheme of 5G communication and big data in smart city application is shown in Figure 4.
46

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Figure 4. 5G communication and big data in smart city application
Huge data flow from several sources like small (mobile phone, personal computers etc. in residential blocks) and large (banking hub, commercial complex, medical facilities etc.) computation and communication intensive units accumulated in structured and unstructured forms shall be stacked, processed, manipulated, retrieved and distributed using cognitive principles of data mining. The complete collection shall represent big data and its analytics shall be based on deep learning principles. These data are to be maintained and deciminated using advanced techniques like deep learning and cloud computing. Deep learning will provide autonomy in data applications. For example, if fading in wireless channels are severe, deep learning based stochastic models will provide approximate representation of channels and help in better recovery of transmitted blocks without relying much on pilot carriers
47

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
which is the conventional practice. It will result in spectrum conservation. This is because of the fact that the deep learning based tools will locally provide the channel state which shall be generated from continuous background training, recording and sharing of the knowledge regarding the dynamically changing wireless profile. It will have significant changes in the methods of data recovery like lowering dependence on pilot retransmissions, unblocking a channel slot for communicating with transmission for reference symbols during data recovery and reduced computational cycles while extracting required portions of data from transmitted blocks. It shall lead to significant changes in receiver architecture designs.
Rise in data flow will be commonly observed phenomena in the immediate future. Residential blocks are likely to be provided with 1-10 Gbps links to fulfil requirements. All transportation resources like trains, buses, cars etc. provided with mobile wireless communication are supposed to be covered by 1 Gbps links. Scientific and commercial clusters may have multiple cells with PAN and NAN topologies provided with high data rate mobile or wireless access using 100 Gbps links to central communication units. All data from each section are to be controlled by specially designed Cognitive Radio Access Network (CRAN) architectures. CRAN and central communication facilities are to be linked with 50-100 Gbps connections and work as relay for subsequent network links and ensure seamless data flow between neighbourhoods, cities, states and countries of all over the world. A list of probable domains in which big data and deep learning resources will be commonly observed and supported by 5G links are summarizes in Table 4.
In commercial sectors, all money transactions, buying or selling, order placing or confirmation and product details etc. constitute big data with a large area coverage which expands continuously. These data flow, based on 5G communication technique (Prasad & Aithal, 2015) shall make commercial linkages interactive. Money transaction, advanced ATM services, biometric verification, credit card scanning etc. are the upcoming technologies which are to be made further efficient using 5G communication (Prasad and Aithal, 2015). All these facilities will have big data dimensions and the analytics part shall require support of deep learning. Decision support and autonomous operation will be ensured by deep learning structures which shall enable real-time interaction between man and machine resulting in high reliability in operations.
In hospitals real time health care monitoring systems are becoming increasingly popular (Aminian and Naji, 2013). Patient health condition diagnostics etc. can be monitored and intervened using 5G communication. A significant portion of it will be WSN based and driven by IoT protocols. Processing conditions shall continuously change which will require predictive decision support. The deep learning based architectures aid by 5G links in M2M interaction mode shall prove handy. In Aminian and Naji (2013) authors report the design of Body WSN (BWSN) to
48

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Table 4. Summary of probable applications domain of deep learning and emerging wireless or mobile communication technologies

Transport

Public sector
Booking, check in/ out

Private sector
Fuel position

Location acceleration details

Baggage Environment details control

CC TV Parking coverage details

Speed limit

Speed limit

Residential Application Laptop, PC
Gaming consoles
SHD TV
Smart phone, tablets
Toys (with Zigbee, IR links) Appliances (Fridge, AC, Washing machine, Water heater)

Commercial Application Transactions (banking etc.) Billing/ selling
Order placing/ confirmation
Inventory update
Quality of Service confirmation Product details

Medical Section
Patient condition
Instrument details
Doctor records in hospitals
CC TV coverage
Emergency service confirmation
Medicine details

Scientific Sector
Neuro science
Biological science and Genetic Engineering
Telecommunication
Robotics and Astronomical system design
Physical science
Chemical science

Energy Sector Distribution grid. Wind, solar and biological sources. Nuclear
Thermal
Hydro
------------

monitor patient’s blood pressure, heart beat and some critical medical conditions. This monitoring system is controlled by some coordinating mechanism with base station. Data sensing in the area of e -Health is a common practice but now huge data generated and its continuous transmission and accumulation is becoming a critical aspect. Predictive diagnostics based on ML and autonomous systems are increasingly making inroads in this regard. Further, in medical practices, data analysis and decision support can be facilitated using deep learning. In Wang, Shao, Shu, Zhu and Zhang (2016), authors proposed a three layer based architecture called ‘interest based reduced variable neighbourhood search (RVNS) queue architecture (IRQA)’ to handle large volume of e health big data. This is an important addition to the list of tools helpful for big data.
Smart city infrastructures include smart home terminologies (Lynggaard and Skouby, 2015). The smart home application is based on Smart Home Network (SHN) technologies (Lynggaard and Skouby, 2015). The IoT interconnection is provided by SHN technologies. According to Lynggaard and Skouby (2015), a simulated model is published regarding this smart home and it extends towards smart city. The model is simulated on a mathematical tool and run it on a normal PC. Smart home

49

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
appliances with IoT like personal computers, tablets, mobiles, SHD TV, heating or cooling systems are interconnected by SHN. These network turns to the internet cloud services. All smart homes are interconnected by cloud of things (CoT) and consume big data produces by all IoT of smart home. Smart city concept is formed from these big data.
Another emerging application is in energy sector where high data rate communication, big data attributes and deep learning shall enable design and deployment of efficient smart grids. Power grid system is constituted by two types of energy producers, small and large. The small energy producers are like wind turbine and solar panels. Similarly, large energy producers are like coal hydro and nuclear plants. These energy producers need to change power production rate and have a dynamic load distribution mechanism coordinating with the requirements of the power consumers. The coordination of energy producers is possible by exchanging the data of the sources, distributors, grid state, demand forecast etc. Predictive approaches can prevent distribution mismanagement and losses which shall enable the design of efficient power grids distributed over countries and continents. Such a mechanism for predictive power management and interfacing with different relevant constituents in real time using high speed data access and decision support from deep learning shall make power generation, distribution and utilization (Gungor, Lu, & Hancke, 2010) conservation oriented and efficient.
Several scientific institutions are already using high data rate mobile/wireless links to accelerate research outcome. Big data and deep learning have become integral parts of it. National Aeronautics and Space Administration (NASA), USA uses around 100 Gbps wireless connectivity. European Council for Nuclear Research (Counsil European pour la Recherche Nucleaire) (CERN) carries out experiments using similar wireless technology. In TERENA conference, 2013 (TNC 2013), for the first time, six of the world’s top most leading groups of research and education networks with other two commercial partners illustrated 100 Gbps transmission link between North America and Europe. In this demonstration, to transmit big data between Maastricht and Chicago it took a few minutes rather than a few hours over the public internet. The 100 Gbps wireless connection is also known as Advanced North Atlantic 100G Pilot Project (ANA-100G) and it has been used for emerging scientific application related to e-health, software defined monitoring etc. In all these cases, the most decisive factor linked with high data rate communication have been real time processing, interactive resource management and access to critical assets with no latency. It has enabled the growth of autonomous operation which most of time, is based on tools like deep learning. Some of the works related to big data and 5G communication are as mentioned in Table 5.
50

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Table 5. A few works related to big data and 5G communication

Sl No. 1 2 3 4 5 6 7 8

Author
Wang, K., Shao, Y., Shu, L., Zhu,C. & Zhang, Y. Tseng, Y. L.

Year of Publication 2016
2015

Prasad, K. K. & Aithal, P. S.

2015

Peng, M., Li, Y., Zhao, Z., 2015 & Wang, C.

Lynggaard, P. & Skouby, 2015 K. E.

Aminian, M. & Naji, H. R.

2013

Rappaport T. S.

2012

Gungor, V. C., Lu, B., Hancke, G.P.

2010

Contribution
Three layer based architecture for mobile e health network.
Vehicle to vehicle communication or vehicle to other services using LTE communication.
Focussed on the new banking technologies using 5G communication.
A discussion on 5G based recent technologies on high through put and low power consumption.
A technique for smart home and later smart city application using 5G communication.
Discussion on the patient health care monitoring system in a hospital using WSN based system.
Wireless communication and new 5 G communication.
Discussion on challenges and application of WSN on smart grid.

Cognitive Radio Networking and Spectrum Sensing
Cognitive networking speaks about an intelligent communication system, consisting of both the wire line and/or the wireless connections, that is aware of its transmission environment, both internal and external, and acts adaptively and autonomously to attain its intended goal(s). This implies that all the network nodes and the end devices are self-aware and context-aware all of the time. The interest in cognitive networking is mainly driven from the need to manage the increasing complexity and the efficient utilization of available resources to deliver applications and services as economically as possible. WSN is one of the areas where there is highest demand for cognitive networking. There are several reasons among which the recourse constraints (spectrum and power) are the most appealing one. Although in WSN, the nodes are constrained in resources mainly in terms of battery power but these days there is scarcity increasing in terms of spectrum availability also. Traditionally, the WSN work in ISM band (2.4 GHz), but in the same band we have many competing technologies working simultaneously like WLAN 802.11 a/b/g and ZigBee (802.15.4), Wi-Fi, Bluetooth. Hence, in an environment where all these competing technologies are working simultaneously, it becomes difficult to find free spectrum to transmit without an error. Also at the same time, the licensed mobile communication bands are almost free for 85% of the time w.r.t. spatial and

51

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
temporal terms. Hence there can be two motives: either to find a free channel in the unlicensed band and do wireless transmission or to find a free channel in the licensed band and do communication. Also it will be strictly needed that whenever the licensed user comes back the cognitive user backs-off from the channel and switch to another free channel without creating any difficulty to the primary user. Another important thing is that if the cognitive user finds several free channels then it can go for the best available channel to do communication. Another important scheme is there in which both the primary and secondary exist simultaneously as long as the QoS of the primary user is not compromised. If the interference created from the power transmitted by the secondary user still remains below some threshold, then this scheme can be helpful. Adding cognition to the existing WSN infrastructure will bring about many benefits. CWSN will enable current WSN to overcome the spectrum scarcity as well as node energy problem. The cognitive technology will not only provide access to new spectrum but with better propagation characteristics too. Also by adaptively changing the systems parameters like modulation schemes, Transmit power, carrier frequency, constellation size a wide variety of data rates can be achieved. These will certainly improve the power consumption and network life time in a WSN. It will also help in coping with the fading (frequency selective/ flat) (Akyildiz, Lee, Vuran & Mohanty, 2006; Akyildiz, Lo & Balakrishnan, 2011).
Spectrum sensing and frequency agility are the two key features of Cognitive WSN. On one hand, spectrum sensing involves monitoring a spectral band for its availability without causing any interference to the primary user, while frequency agility involves switching capabilities in case the spectrum becomes unavailable due to the presence of a primary user. Over the years, a number of spectrum sensing techniques have been developed. Among all such techniques, primary transmitter detection, cooperative detection and interference detection are the conventional ones. Other signal processing approaches for performing spectrum sensing includes multi-taper spectrum sensing and estimation, filter bank based sensing, wavelet based detection, random Hough transform based detection and radio identification based detection (Fanan, Riley, Mehdawi, Ammar & Zolfaghari, 2014; Kaur & Aulakh, 2015). Some of the works related to Cognitive radio networking are as mentioned in Table 6.
Spectrum Sensing: Review of Current Research Trends
Over the years, various spectrum sensing techniques were proposed to identify the presence of primary user signal as well as to exploit the spectrum by secondary user when the primary user is absent. The most popular spectrum sensing techniques are classified under three major categories: non-cooperative detection, cooperative
52

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Table 6. A few works related to cognitive radio networking

Sl No. 1

Author Kaur, N. & Aulakh, I. K.

Year of Publication
2015

2

Fanan, A. M., Riley, N. G., 2014

Mehdawi, M., Ammar, M.

& Zolfaghari, M.

3

Akyildiz, I. F., Lo, B. F. & 2011

Balakrishnan, R.

4

Akyildiz, I. F., Lee, W.,

2006

Vuran, M. C. & Mohanty,

S.

Contribution
A Survey of Cooperative Spectrum Sensing in Cognitive Radio Networks Survey: A Comparison of Spectrum Sensing Techniques in Cognitive Radio
Cooperative spectrum sensing in cognitive radio networks: A survey NeXt generation/dynamic spectrum access/cognitive radio wireless networks: A survey

detection and interference based detection. This survey mainly emphasizes on the different types of non-cooperative detection, i.e., energy detection, matched filter detection and cyclostationary feature detection (Ariananda, Lakshmanan & Nikookar, 2009; Zeng, Liang, Hoang & Zhang, 2009).
The energy detection is a non coherent detection technique where the primary user detection and its statistics do not need any prior knowledge of the primary user signal to determine whether the channel is occupied or not. Consequently, it is considered the one of simplest techniques of spectrum sensing to detect primary user transmitter. In the past various literatures have reported theoretical and practical findings on energy detection. The advantages of using energy detection are low computational cost, easy implementation and less complexity. Moreover, it does not need any prior knowledge of primary user (PU) as the technique solely depends on the power of PU signal, i.e., whether the signal is present or absent, these advantages makes energy detection the simplest method to detect primary user signal. In contrast, in this technique, the signal detection depends on comparing power of the received signal to the threshold level, while, the threshold level rely on the noise floor which can be estimated. But the signal power is difficult to be estimated as it changes depending on two factors: distance between primary user and cognitive radio as well as ongoing transmission characteristics. As a consequence, the selection of an appropriate threshold level caused some drawbacks in the energy detection. If the threshold is too low then, it causes false alarm. On the other hand, when the threshold is too high, the missed detection will occur because weak primary signals will be ignored. Therefore the performance of energy detection is dependent on the suitable selection of the threshold in the frequency domain. Another disadvantage is the accuracy of signal detection which is found to be low as compared to other techniques.
53

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Another technique of the spectrum sensing is Matched filter Detection (MFD), which is known as optimum method to detect primary users when the transmitted signal is known. This technique is commonly used in radar transmission. MFD is considered as a linear filter designed in digital signal processing (DSP) which is used to maximize the output signal to noise ratio for given input signal. However, it requires proper demodulation of the primary user signal. Consequently, this technique requires a perfect prior knowledge of a primary user such as modulation type and order, bandwidth, operating frequency, pulse shaping and frame format. The advantages of this method are that the detection process requires short sensing time and low number of samples to meet required level of false alarm or missed detection. Moreover, it has high processing gain and high accuracy compared with other techniques. Its major drawback is its power consumption which is large in different receiver algorithms that are implemented to detect primary users. Match filter requires a dedicated receiver for every signal type of primary user. The implementation complexity of sensing unit is impractically large. Thus, from its requirements, advantages and disadvantages, it can be concluded that the performance of matched filter relies on the availability of perfect prior knowledge of primary users which lead to increasing cost and more complexity. Hence, the good performance and high accuracy in MFD is achieved at the expense of increased cost and complexity.
An alternative detection method is the cyclostationary feature detection. Modulated signals are, in general, coupled with sine wave carriers, pulse trains, repeating spreading, hopping sequences, or cyclic prefixes, which result in built-in periodicity. These modulated signals are characterized as cyclostationary since their mean and autocorrelation exhibit periodicity. These features are detected by analyzing a spectral correlation function. The main advantage of the spectral correlation function is that it differentiates the noise energy from modulated signal energy, which is a result of the fact that the noise is a wide-sense stationary signal with no correlation, while modulated signals are cyclostationary with spectral correlation due to the embedded redundancy of signal periodicity. Therefore, a cyclostationary feature detector can perform better than the energy detector in discriminating against noise due to its robustness to the uncertainty in noise power. However, it is computationally complex and requires significantly long observation time. For more efficient and reliable performance, the enhanced feature detection scheme combining cyclic spectral analysis with pattern recognition based on neural networks is proposed by Fehske, Gaeddart and Reed (2005). Distinct features of the received signal are extracted using cyclic spectral analysis and represented by both spectral coherent function and spectral correlation density function. The neural network, then, classifies signals into different modulation types (Akyildiz, Lee, Vuran & Mohanty, 2008; Liang,
54

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Zeng, Peh & Hoang, 2008; Zhang, Mallik & Lataeif, 2009; Subhedar & Birajdar, 2011; Jaiswal & Sharma, 2013). Some of the works related to spectrum sensing are as mentioned in Table 7.

CONCLUSION
In this chapter, we have discussed the background of big data and its association with deep learning and the linkages with the evolving scenario of wireless/mobile communication. Of late there has been an enormous growth in wireless/mobile devices and related applications which have aided the expansion of big data infrastructure. It has been observed that analytic tools of big data are gearing up for acquiring a full scale autonomous mode of operation which necessitates a strong role to be played by learning based systems. Of late, deep learning networks have been accepted to be useful for such scenarios. The chapter has focused in some depth on the synergy of big data and DWN for generating better efficiency in existing and evolving communication frameworks. The chapter has also included discussion on ML and cognitive technologies with respect to big data and mobile communication. As CPS are emerging as indispensible elements of M2M communication, certain discussion

Table 7. A few works related to spectrum sensing

Sl No. 1 2 3
4 5

Author
Jaiswal, M. & Sharma, A. K.
Subhedar, M. & Birajdar, G.
Ariananda, D. D., Lakshmanan, M. K. & Nikookar, H.
Zeng, Y., Liang, Y., Hoang, A. T. & Zhang, R.
Zhang, W., Mallik, R. K. & Lataeif, K.B.

Year of Publication 2013 2011 2009
2009 2009

6

Akyildiz, I. F., Lee, W.,

2008

Vuran, M. C. & Mohanty,

S.

7

Liang, Y., Zeng, Y., Peh, E. 2008

C. Y. & Hoang, A. T. H.

Contribution
A Survey on Spectrum Sensing Techniques for Cognitive Radio Spectrum Sensing Techniques in Cognitive Radio Networks: A Survey A Survey on Spectrum Sensing Techniques for Cognitive Radio
A Review on Spectrum Sensing for Cognitive Radio:Challenges and Solutions Optimization of Cooperative Spectrum Sensing with Energy Detection in Cognitive Radio Networks A Survey on Spectrum Management in Cognitive Radio Networks
Sensing-Throughput Tradeoff for Cognitive Radio Networks

55

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
on this aspect as also been included. Subsequently, WSN and its convergence with CPS, cognitive radio networking and evolving scenario of spectrum sensing have also been covered. It is expected that the emerging scenario of spectrum sensing, big data and deep learning will play significant roles in enhancing the capabilities of wireless/mobile communication systems which will integrate WSNs as part of CPS set ups to facilitate the design of reliable M2M interaction frameworks.
REFERENCES
Agarwalla, S., & Sarma, K. K. (2016). Machine learning based sample extraction for automatic speech recognition using dialectal Assamese speech. Neural Networks, 78, 97–111. doi:10.1016/j.neunet.2015.12.010 PMID:26783204
Akyildiz, I. F., Lee, W., Vuran, M. C., & Mohanty, S. (2006). NeXt generation/dynamic spectrum access/cognitive radio wireless networks: A survey. Elsevier Journal on Computer Networks, 50(13), 2127–2159. doi:10.1016/j.comnet.2006.05.001
Akyildiz, I. F., Lee, W., Vuran, M. C., & Mohanty, S. (2008). A Survey on Spectrum Management in Cognitive Radio Networks. IEEE Communications Magazine, 46(4), 40–48. doi:10.1109/MCOM.2008.4481339
Akyildiz, I. F., Lo, B. F., & Balakrishnan, R. (2011). Cooperative spectrum sensing in cognitive radio networks: A survey. Physical Communication, 4(1), 40–62. doi:10.1016/j.phycom.2010.12.003
Aminian, M., & Naji, H. R. (2013). A Hospital Healthcare Monitoring System Using Wireless Sensor Networks, Health &. Medical Informatics, 4(2).
Ariananda, D. D., Lakshmanan, M. K., & Nikookar, H. (2009). A Survey on Spectrum Sensing Techniques for Cognitive Radio. Proceedings of second International Workshop on Cognitive Radio and Advanced Spectrum Management (CogART), 74-79. doi:10.1109/COGART.2009.5167237
Baheti, R., & Gill, H. (2011). Cyber-physical systems. The Impact of Control Technology, IEEE, 161-166.
Bharill, N., & Tiwari, A. (2016). Handling Big Data with Fuzzy Based Classification Approach. Academic Press.
Bi, S., Zhang, R., Ding, Z., & Cui, S. (2015). Wireless communications in the era of big data. IEEE Communications Magazine, 53(10), 190–199. doi:10.1109/ MCOM.2015.7295483
56

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Casado, R., & Younas, M. (2015). Emerging trends and technologies in big data processing. Concurrency and Computation, 27(8), 2078–2091. doi:10.1002/cpe.3398
Chen, M., Mao, S., & Liu, Y. (2014). Big data: A survey. Mobile Networks and Applications, 19(2), 171–209. doi:10.1007/s11036-013-0489-0
Chen, X. W., & Lin, X. (2014). Big data deep learning: Challenges and perspectives. IEEE Access, 2, 514–525. doi:10.1109/ACCESS.2014.2325029
Cui, L., Yu, F. R., & Yan, Q. (2016). When big data meets software-defined networking: SDN for big data and big data for SDN. IEEE Network, 30(1), 58–65. doi:10.1109/MNET.2016.7389832
Dean, J., & Ghemawat, S. (2008). MapReduce: Simplified data processing on large clusters. Communications of the ACM, 51(1), 107–113. doi:10.1145/1327452.1327492
Dehuri, S., & Sanyal, S. (2015). Computational Intelligence for Big Data Analysis. Springer International Publishing.
DeWitt, D., & Gray, J. (1992). Parallel database systems: The future of high performance database systems. Communications of the ACM, 35(6), 85–98. doi:10.1145/129888.129894
Eibagi, A. (2014). Big Data Analysis Using Neuro-Fuzzy System (Thesis). San Jose State University.
Eldar, Y. C., & Kutyniok, G. (2012). Compressed Sensing: Theory and Applications. Cambridge, UK: Cambridge University Press. doi:10.1017/CBO9780511794308
Fanan, A. M., Riley, N. G., Mehdawi, M., Ammar, M., & Zolfaghari, M. (2014). Survey: A Comparison of Spectrum Sensing Techniques in Cognitive Radio. Proceedings of International Conference on Image Processsing, Computers and Industrial Engineering (ICICIE), 65-69.
Gantz, J., & Reinsel, D. (2011). Extracting value from chaos. IDC Review, 1142, 1-12.
Garrett, M. A. (2014). Big Data analytics and Cognitive Computing: future opportunities for Astronomical research. IOP Conference Series Materials Science and Engineering, 67(1). doi:10.1088/1757-899X/67/1/012017
Gunes, V., Peter, S., Givargis, T., & Vahid, F. (2014). A Survey on Concepts, Applications, and Challenges in Cyber-Physical Systems. Transactions on Internet and Information Systems (Seoul), 8(12), 4242–4268.
57

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Gungor, V. C., Lu, B., & Hancke, G. P. (2010). Opportunities and Challenges of Wireless Sensor Networks in Smart Grid. IEEE Transactions on Industrial Electronics, 57(10), 10. doi:10.1109/TIE.2009.2039455
Guturu, P., & Bhargava, B. (2011). Cyber-Physical Systems: A Confluence of Cutting Edge Technological Streams. Proceedings of International Conference on Advances in Computing and Communication ICACC-11.
Hasan, M. (2014). Genetic Algorithm and its application to Big Data Analysis. International Journal of Scientific & Engineering Research, 5(1).
Hey, T., Tansley, S., & Tolle, K. M. (2009). The fourth paradigm: Data-intensive scientific discovery (Vol. 1). Redmond, WA: Microsoft Research.
Hu, H., Wen, Y., Chua, T. S., & Li, X. (2014). Toward scalable systems for big data analytics: A technology tutorial. IEEE Access, 2, 652–687. doi:10.1109/ ACCESS.2014.2332453
Jaiswal, M., & Sharma, A. K. (2013). A Survey on Spectrum Sensing Techniques for Cognitive Radio. In Proceedings of Conference on Advances in Communication and Control Systems (CAC2S). Atlantis Press.
Jardak, C., Mähönen, P., & Riihijärvi, J. (2014). Spatial big data and wireless networks: Experiences, applications, and research challenges. IEEE Network, 28(4), 26–31. doi:10.1109/MNET.2014.6863128
Kala, R., Shulkla, A., & Tiwari, R. (2009, March). Fuzzy Neuro systems for machine learning for large data sets. Advance Computing Conference, 2009. IACC 2009. IEEE International, 541-545. doi:10.1109/IADCC.2009.4809069
Kaur, N., & Aulakh, I. K. (2015). A Survey of Cooperative Spectrum Sensing in Cognitive Radio Networks. International Journal on Recent and Innovation Trends in Computing and Communication, 3(11), 6313–6316.
Kriegeskorte, N. (2015). Deep neural networks: A new framework for modeling biological vision and brain information processing. Annual Review of Vision Science, 1(1), 417–446. doi:10.1146/annurev-vision-082114-035447
Kune, R., Konugurthi, P. K., Agarwal, A., Rao Chillarige, R., & Buyya, R. (2014). Genetic Algorithm based Data-aware Group Scheduling for Big Data Clouds. International Symposium on Big Data Computing, 96-104. doi:10.1109/BDC.2014.15
58

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Le, N. T., Martin, L., Mumme, C., & Pinkwart, N. (2012) Communication-free detection of resource conflicts in multi-agent-based cyber-physical systems. Proceedings of the 6th IEEE International Conference on Digital Ecosystems Technologies (DEST), 1-6. doi:10.1109/DEST.2012.6227952
Leung, S. T., & Gobioff, H. (2003). The Google file system. SOSP’03 Proceeding of Nineteenth ACM Symposium on Operating Systems Principles, 29-43.
Liang, Y., Zeng, Y., Peh, E. C. Y., & Hoang, A. T. H. (2008). Sensing-Throughput Tradeoff for Cognitive Radio Networks. IEEE Transactions on Wireless Communications, 7(4), 1326–1337. doi:10.1109/TWC.2008.060869
Lynggaard, P., & Skouby, K. E. (2015). Deploying 5G-technologies in smart city and smart home wireless sensor networks with interferences. Wireless Personal Communications, 81(4), 1399–1413. doi:10.1007/s11277-015-2480-5
Mane, D., & Salian, S. (2015). Utilizing Big Data, Cognitive Computing and Big Data Testing to deduce optimized result based decisions. International Journal of Engineering Research and General Science, 3(3), 351–356.
Manyika, J., Chui, M., Brown, B., Bughin, J., Dobbs, R., Roxburgh, C., & Byers, A. H. (2011). Big data: The next frontier for innovation, competition, and productivity. San Francisco, CA: McKinsey Global Institute.
Nower, N., Tan, Y. S., & Lim, A. O. (2014). Efficient temporal and spatial data recovery scheme for stochastic and incomplete feedback data of cyber-physical systems. In Proceedings of the 8th IEEE International Symposium on Service Oriented System Engineering (SOSE). Oxford, UK: IEEE. doi:10.1109/SOSE.2014.29
Peng, M., Li, Y., Zhao, Z., & Wang, C. (2015). System architecture and key technologies for 5G heterogeneous cloud radio access networks. IEEE Network, 29(2), 6–14. doi:10.1109/MNET.2015.7064897 PMID:26504265
Prasad, K. K., & Aithal, P. S. (2015). Massive Growth of banking technology with the aid of 5G technologies. International Journal of Management. IT and Engineering, 5(7), 616–627.
Rajkumar, R., Lee, I., Sha, L., & Stankovic, J. (2010). Cyber-Physical Systems: The Next Computing Revolution. Proceedings of Design Automation Conference, 731-736.
Rappaport, T. S. (2012). Wireless Communications (2nd ed.). New Delhi: Pearson Education.
59

Big Spectrum Data and Deep Learning Techniques for Cognitive Wireless Networks
Subhedar, M., & Birajdar, G. (2011). Spectrum Sensing Techniques in Cognitive Radio Networks: A Survey. International Journal of Next Generation Networks, 3(2), 37–51. doi:10.5121/ijngn.2011.3203 Tseng, Y. L. (2015). LTE-Advanced enhancement for vehicular communication. IEEE Wireless Communications, 22(6), 4–7. doi:10.1109/MWC.2015.7368815 Wang, K., Shao, Y., Shu, L., Zhu, C., & Zhang, Y. (2016). Mobile big data faulttolerant processing for eHealth networks. IEEE Network, 30(1), 36–42. doi:10.1109/ MNET.2016.7389829 Xu, Y., Zeng, M., Liu, Q., & Wang, X. (2014). A Genetic Algorithm Based Multilevel Association Rules Mining for Big Datasets. Mathematical Problems in Engineering, 1–9. Zeng, Y., Liang, Y., Hoang, A. T., & Zhang, R. (2009). A Review on Spectrum Sensing for Cognitive Radio: Challenges and Solutions. EURASIP Journal on Advances in Signal Processing, 2010, 15. Zhang, W., Mallik, R. K., & Lataeif, K. B. (2009). Optimization of Cooperative Spectrum Sensing with Energy Detection in Cognitive Radio Networks. IEEE Transactions on Wireless Communications, 8(12), 5761–5766. doi:10.1109/ TWC.2009.12.081710 Zhu, Q. Y., Bushnell, L., & Basar, T. (2013). Resilient distributed control of multiagent cyber-physical systems. In Control of Cyber-Physical Systems. Springer.
60

61
Chapter 4
Efficiently Processing Big Data in Real-Time Employing
Deep Learning Algorithms
Murad Khan Sarhad University of Science and Information Technology, Pakistan
Bhagya Nathali Silva Kyungpook National University, South Korea
Kijun Han Kyungpook National University, South Korea
ABSTRACT Big Data and deep computation are among the buzzwords in the present sophisticated digital world. Big Data has emerged with the expeditious growth of digital data. This chapter addresses the problem of employing deep learning algorithms in Big Data analytics. Unlike the traditional algorithms, this chapter comes up with various solutions to employ advanced deep learning mechanisms with less complexity and finally present a generic solution. The deep learning algorithms require less time to process the big amount of data based on different contexts. However, collecting the accurate feature and classifying the context into patterns using neural networks algorithms require high time and complexity. Therefore, using deep learning algorithms in integration with neural networks can bring optimize solutions. Consequently, the aim of this chapter is to provide an overview of how the advance deep learning algorithms can be used to solve various existing challenges in Big Data analytics.
DOI: 10.4018/978-1-5225-3015-2.ch004
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
INTRODUCTION
Big Data and deep computing have gained a smashing popularity over the past few decades. The emergence of Big Data was accompanied by the exponential growth of digital data. Big Data has been defined in multiple aspects and perspectives. In general, Big Data is a prodigious amount of digital data, which is strenuous to manage and analyze using generic software tools and techniques. According to the National Security Agency, 1826 petabytes are processing by the internet on a daily basis (“National Security Agencey: Missions Authorities, Oversight and Partnerships”, 2013). Surprisingly, in 2011 it was found that the world’s data volume has grown in nine times within five years. This extraordinary growth rate is estimated to reach 35 trillion gigabytes in 2020 (Gantz & Reinsel, 2011). Due to this exponential digital data generation, Big Data continues to receive an extreme attention from the industrial experts as well as from the interested researchers. In fact, Big Data requires expeditious processing over voluminous data sets with high variety and high veracity (Zhang, Yang and Chen, 2016). Therefore, it creates a compelling demand to discover and to adopt technologies capable of speedy processing on heterogeneous data. Numerous embedded devices connected to the network generates heterogeneous data. Figure 1 illustrates a classical architecture of heterogeneous devices connected over different communication technologies. Generic characteristics of Big Data is known as three V’s of Big Data i.e. variety, velocity, and volume. A variety of data is referred to multiple formats of data being stored. For example, a collection of text, image, audio, video, numeric, etc. data types in structured, semi-structured, and unstructured forms are considered as data sets with variety. The size aspect of the data is the volume of data. In a modern technological era, data volume is rapidly growing with the invention of social media and popularity of embedded devices. In fact, the data generation speed is known as the velocity of Big Data. The technological advancements have influenced the dramatic increase in the velocity. Moreover, Big Data includes incomplete, redundant data as well as inaccurate and obsolete data. Thus, it is denoted that Big Data consists of high veracity data. Consequent to the rapid growth in digital data, myriads of opportunities in numerous fields i.e. educational services, enterprises, manufacturing services, social networking and much more are emerging. Consequently, these opportunities of Big Data have geared the research community towards data-driven discovery. Indeed, Big Data phenomenon has influenced all aspects of the social lifestyles in the modern world. Even though, Big Data occupies a colossal amount of data, discovering precise knowledge from the gathered data is not an easy task. Henceforth, the spotlight is focused towards the standard representation, storage, analysis, and mining of Big Data. The extreme heterogeneous nature of Big Data hinders the capability of feature learning by conventional data mining methods and
62

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
algorithms. In fact, not only the advancements of the existing technologies, it is required collaboration among associative teams as well in order to extract valuable knowledge from Big Data. The advancements of the computation capabilities and enhanced machine learning mechanisms have broadened boundaries of data analytics and knowledge discovery procedures. However, the extraction of knowledge from Big Data using conventional learning algorithms is an extremely laborious task. It might be impossible in certain scenarios. The large volumes of data demand the scalability of the algorithm in order to process Big Data. Moreover, the great variety of data requires the algorithm to identify hidden relationships among heterogeneous data. The interest groups have yearned to discover novel mechanisms to accomplish the tedious task, which cannot be fulfilled by the conventional learning algorithms. Efforts in the recent past have identified that the integration of deep learning with high-performance computation offers favorable outcomes in knowledge extraction from Big Data.
The conventional learning algorithms occupy shallow learning architectures. In contrast, the deep learning algorithms incorporate deep architectures (Bengio and Bengio, 2000). The deep learning mechanisms utilize machine-learning techniques such as supervised learning and unsupervised learning to learn hierarchical relationships among heterogeneous data. Accordingly, it classifies the data autonomously (Ranzato, Boureau and Yann, 2007). Deep learning algorithms have gained a wider acceptance from the research community due to its remarkable performance in various domains i.e. speech recognition, computer vision, fraud detection, and advanced search. The deep learning algorithms classify and process natural signals based on the data processing mechanisms of the human brain. In the past few decades, leading global organizations with a massive amount of data collections i.e. Apple, Google, and Facebook has decided to take a step forward towards the deep learning to receive tremendous benefits from Big Data. Deep belief networks (DBN) and convolutional neural networks (CNN) are well established deep architectures. The conventional learning mechanisms tend to trap in local optima, which leads to performance deterioration. Even though the collection of unlabeled data is a cheap task, these data are neglected in conventional algorithms. Thus, DBN architecture is introduced to learn features from both labeled and unlabeled data, while overcoming the above-stated drawbacks. The DBN includes two folds 1) unsupervised pre-training and 2) supervised fine-tuning. DBN utilizes stack/s of restricted Boltzmann machines (RBM) to perform pre-training. This helps the DBN to avoid local optima. Concisely, DBN uses a greedy approach to learn unlabeled data and uses back propagation to fine-tune the learned variables. CNN is another deep learning architecture consists of multiple layers. In CNN, there are separate layers for feature representation and classification. The process initiates with the two altering layers. One performs the convolutional operations and the other one
63

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
Figure 1. Classical network architecture connecting heterogeneous devices and components through multiple communication technologies
reduces the size of the next layers. The CNN follows a bio-inspired process to learn hierarchical features. Further, it automatically learns feature hierarchies and provides translational invariances to a certain extent. The performance of CNN is preserved due to the learning strategies it follows i.e. local receptive field, shared weights, and sub-sampling.
The astounding performance of deep learning in many application domains has made the experts accept deep learning as a promising technology for Big Data analysis. On one hand, training the deep learning architecture for Big Data analysis is not an easy task. On the other hand, it was found that deep learning training process can be improved significantly with the aid of great computing power. Thus, multiple attempts were made to design deep learning architectures, which performs remarkably well in the training process owing to the high-speed computation. The extensive attention of the researchers resulted in a significant improvement in large-scale deep learning mechanisms i.e. large-scale deep belief networks, largescale convolutional neural networks, commodity off-the-shelf high-performance computing (COTS HPC) system, and parallel schemes. A large-scale DBN can train more than 100 million free parameters with millions of unlabeled data. Raina, et al. proposed a framework to parallelize DBN using graphical processing units (GPU). This large-scale DBN stores all parameters and a bigger portion of training
64

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
data on the global memory. Thus, it reduces the data transfer time. The GPU based DBN performance fit for Big Data learning, since it enhances DBN performance up to 70 times (Raina, Madhavan and Ng, 2009). Similarly, CNN occupies GPU to implement large-scale CNN. The training process of large-scale CNN consists with forward and backward propagation. Moreover, it supports data parallelism. The threads perform parallel convolutional operations and store the results in global memory. Later, a software framework called DistBelief was developed to train distributed very large deep networks. It facilitates data parallelism and involves two optimization procedures. Even though DistBelief efficiently learns from very large models, the training requires 16000 central processing unit (CPU) cores. As a solution, Coates, et al. develop a deep network model, which can perform similarly with three machines (Coates, Huval, Wang, Wu, Catanzaro and Andrew, 2013). The COTS HPC is designed with CUDA kernels to manage memory and to perform computations efficiently.
The exponential growth in Big Data requires efficient deep learning methods to manage and analyze rapidly growing digital data. When applying deep computation into large-scale networks, it is essential to meet three V’s characteristics of Big Data for a fruitful learning process. However, centralize processing and storing leads to inefficiencies in deep learning algorithms on massive amounts of data. Therefore, the current trend is deviating towards distributed frameworks and parallel computing to attain the training speed at no accuracy relinquish. Moreover, it is essential for deep learning to adapt the high variety of data caused due to the heterogeneity of the data generation source. Data integration is considered as the fundamental characteristic to meet a high variety of the digital data. The representational learning ability with or without supervision is used to classify or cluster Big Data. Initially, deep learning algorithms identify intermediate or abstract representations. In order to generate a natural solution, identified representations are integrated in a hierarchical manner. Another major concern is to meet the high velocity of data generation in Big Data notion. In fact, deep learning should learn timely to process data efficiently. Thus, online learning has become a prominent technique. Moreover, it is particularly applicable, since the machine cannot hold the complete dataset in the memory. In general, online learning learns a single context at a time and it will be soon after consumable to refine the model. However, the progress of this area is passive in the recent past.
OVERVIEW OF DEEP LEARNING
In general, deep learning consists of a set of learning mechanisms and techniques that learn multiple and hierarchical representations in a deep manner. Moreover,
65

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
the deep learning architectures are widely divided into two main parts, i.e. 1) Deep belief networks (DBN) and convolutional neural network (CNN).
Deep Belief Networks
The performance of conventional neural networks depends on how efficiently it solves the local optimal problem for a non-convex objective function. However, most of the conventional neural networks are affected by the false local optimal problem (Rumelhart et al, 1986), Moreover, such schemes show poor performance in the case of unlabeled data. In addition, unlabeled data mainly affect the performance require extra hard work in the case of big data. In order to address the aforementioned problems, the DBN is implanted which efficiently uses a predefined deep architecture of collecting various important features both for labeled and unlabeled data (G. H., Salakhutdinov, 2006). The DBN uses a two-tier models i.e. pre-training and supervised tuning. The later one is used to perform a local search strategy for fine tuning and the former one is used to learn the distribution of data by skipping label information. The illustration of DBN based on Restricted Boltzmann machines (RBM) and an additional level of discrimination tasks is shown in Figure 2. RBMs have been widely used as a generative model for many different types of data i.e. labeled and unlabeled (Hinton, 2010). However, their main concerned is directly based on learning modules that are consisting of deep belief nets. After the initial structure of the RBM is formed, the next step is to assign weights to layers based on the training. The training module following an initial unsupervised learning. Moreover, it is very important to make decision-based on the units that are employed in the RBM system. These units also help in constructing the states at different levels. In addition, the process of learning is continuously monitored until and unless the entire training process is finished. The RBM also follows an interconnected layering architecture. The nodes in one layer are not connected to the nodes in the same layer instead, they are connected with nodes in different layers. Moreover, each node in one particular layer is completely independent of the nodes in the same layer. In addition, this phenomenon of independence helps in constructing a layer by layer architecture.
A layer-wise pre-training is performed before tuning. In pre-training phase, the output from each RBM of one layer is fed into the other layer. The process is repeated until all the layers are pre-trained. The main advantage of layer-wise training is to address the local optima and overfitting problem. The sampling probabilities of a visible and hidden layer in the case of a simple RBM and implanting Bernoulli distribution is given as follows (Wang and Shen, 2007)..
66

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms

( ) ∑ P Hk = 1 |V ;W

=

ρ 

N
wikVi
i =1

+

αk



(1)

and

( ) ∑ P Vl = 1 | H;W

=

ρ



N
wlj
j =1

H

+ αk 

(2)

where H and V represents a K*1 hidden unit vector and J*1 represents a visible unit vector, respectively. W, α,β and η, represents the weight matrix, bias terms, and a sigmoid function respectively.
Moreover, the weights on each step are updated based on the contrastive divergence approximation (CDA) (Hinton, 2002). For instance following equation 3, shows how to update the weights at step t +1

( ) ( ) ( ) ∆Wkl t + 1 = m∆Wkl t + δ VkHl data − VkHl model

(3)

where m and δ is the momentum factor and learning rate. The expectations for data

and model is represented using ⋅ and ⋅ .

data

model

One of the important features of RBM is the sampling of data without labeling.

This feature helps in processing a large amount of data in less time compared to other

techniques. Thus, it can help in processing big data with reasonable computation and

time. Moreover, the literature consists of several other techniques such as autoencoders

spare coding instead of using RBM for unsupervised feature learning (Vincent, 2008;

Larochelle, 2009, Lee, Battle, Raina, Ng, n.d.) . However, weight computation is

still a challenging job in RBM instead of using above techniques. Therefore, many

researchers suggest using random initial weights instead of computing predetermine

weights. In particular, the DBNs uses a dual strategy of improving the performance

of the network. First, it uses a greedy approach in a layerwise fashion to learn the

estimated weights and then follow a propagation method for tuning.

Convolutional Neural Networks

A CNN is composed of a set of the layer in a hierarchical manner. The layers are normally of two types i.e. convolution and sub-sampling layer (LeCun, Bottou, Bengio, Haffner, 1998). In the case of convolution layer, a number of equal size filters are used to perform convolution operations. Similarly, in the case of subsampling layer,

67

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
Figure 2. A conceptual overview of the deep belief networks

the pixels in a particular region is averaged to reduce the processing for next layers (Ciresan, Meier, Masci, Gamardella, Schmidbuber, 2011). The structure of a typical CNN concept is shown in Figure 3. The initial layer is the input layer represented by a 2d matrix of NXN images. The first convolution (C1) extract some specific visual information by applying some various filter maps. The value of each feature map depends on two factors 1i. 1) The particular receptive field of the input layer and 2) Filter used. This computation is carried out by following Equation 4.

∑ Okl = f  n

Fnk

⊗

t l −1 n

+ ck 

(4)

where O is the output from Kth convolution of the previous layer “l”, f represents a nonlinear functional operates over three different factors i.e. 1) a filter “F”, 2) feature map “t” and 3) bias “C”

68

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
Moreover, the filter directly depends on the type of information. For example, if the filter is set to extract the information from a particular region, then it always connects that particular information from the previous layer to next layer. The researchers suggested various techniques to perform sub-sampling. However, the key functionality of sub-sampling is to reduce the spatial resolution. Deep Belief Networks and Big Data The DBN is used by many researchers to process big data in an efficient way. For instance, a GPU based architectural model is presented to process the massive amount of data in (Raina, 2009). The author suggested the use of stacked RBMs in a parallel fashion to incorporate a huge amount of data with less processing time. Moreover, the proposed model process and train hundred million parameters compared to the previous research work where they process 3.8 million parameters (Raina, 2009). However, implanting the proposed model for large-scale data have several problems such as transferring the data between client and global memory. One of the most efficient work has done in this regard by placing all the parameters and training solution in the global memory during the training phase. Moreover, a data parallel processing can be used to perform concurrent updates across each block of information.
However, the GPU implementation shows efficient result in the case of incorporating several million parameters in RBM. A number of 4.5 million parameters and 1 million examples is passed to RBM for testing. The speed of DBN learning is increased by a factor of 70 (Raina, 2009).
Figure 3. Deep Belief Networks based on Restricted Boltzmann machines
69

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
Convolutional Neural Networks and Big Data
In a CNN, a large number of deep learning methods are connected locally. Therefore, such type of networks is implemented on several hundred cores based on GPU implementation. The feature maps are assigned based on the blocks of information coming from the previous layer. However, it directly depends on the size of feature maps (Ciresan et al, 2011). A single block consists of several threads and each thread is attached to a single neuron. Similarly, the rest of the process is carried out by the convolution of neurons, activation, and summation. Finally, the output from above methods is stored in a global memory. This entire process follows a backward and propagation model for processing data efficiently. However, a single propagation doesn’t generate good results, therefore, the parallelizing of propagation is carried out by pulling or pushing operations (Ciresan et al, 2011). Moreover, such process is affected by the border effects because the neurons in one layer may connect to a different number of neurons (Simard et al, 2003). The data parallelism directly depends on the global memory and feature map size. The shared memory always affect the parallelism process. However, a circular buffer concept of the limited shared memory is suggested in (Scherer, 2010). The operation of convolution is performed by a thread in a parallel fashion and the results are written back to global memory. However, in the case of big data analytics limited shared memory still exists a challenging job. Therefore, researchers suggest a method of combining the convolution and sampling process in one step (Scherer, 2010). Thus, a back propagation is applied with storing the activities and error values in one step. A similar approach of using two GPUs, five convolution, and three classification layers is suggested for high-speed processing of large data in (Krizhevsky, 2012) A layerwise processing is performed by assigning half of the layer processing to one GPU and half to another. Moreover, both the GPU transfer and communicate with each other without affecting host memory.
CHALLENGES FOR LARGE-SCALE BIG DATA
In the past few years, Big Data has been widely accepted by government bodies and public society. Though the capacity of Big Data is remarkable, achieving its full capability is still challenged in the real world. In fact, ideas and algorithms beyond the regular thinking frame help to enrich the concept of Big Data learning to overcome existing challenges. In the past, machine-learning algorithms learned patterns after loading all data into memory. However, this mode of machine learning is no longer valid and realistic for Big Data learning, since the algorithms are supposed to learn from bulky data. As previously mentioned, integrating deep learning mechanisms
70

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
for Big Data learning is a worthy solution. The extreme complexity of Big Data has pulled down the evolution of large-scale deep learning. This sluggish development is mainly due to the challenges arise from three V’s of Big Data. Which is commonly known as massive amounts of data (high volume), various types of data (high variety), and rapid data generation (high velocity). The rest of this section briefly explains three V’s impact with respect to deep learning.
Challenges for High Volume Data
The high volume of data is considered as the greatest challenge for deep learning. Generally, Big Data includes a very large set of output classes and very large number of free parameters. Indeed, these properties immensely increase the processing time and the complexity of the deep network. Consequent to the boundless volumes of data, training of a deep learning network with a centralized architecture (processors and storage) is tedious or might be impossible. Thus, distributed architectures with parallelized machines are favored. The efforts made in the recent past became successful in alleviating certain challenges caused after high volumes. The schemed ideas occupy a collection of CPUs or GPUs to enhance the speed of training. Thus, it achieved efficiency without compromising accuracy. The two main strategies for parallelism i.e. data parallelism and model parallelism have been developed (Coates et al, 2013).
Moreover, the novel deep learning frameworks are scalable according to the number of GPUs and can handle enormous amounts samples and parameters. It expects that computational power and computer memory keep growing continuously. However, that is not enough to scale the existing deep learning frameworks. It is essential to meet the computation related features such as copying large sets of data, in order to facilitate deep learning scalability for very large data sets. Eventually, the realization of scalable deep learning frameworks for Big Data should confirm high-performance architecture along with effective parallel learning algorithms. Incomplete and noisy data included in Big Data is another major challenge. In general, the training data sets of classical machine learning are noiseless and assure completeness. However, Big Data includes noisy labels with incomplete data, as a result of vastly varied data origin and heterogeneity. The consequences are worsened with the larger portions of unlabeled data and noisy labels. Deep learning has a remarkable ability to serve unlabeled data during training. Since it learns the relationships between data without utilizing label information. In that sense, unlike the conventional learning methods, the large portions of unlabeled data are highly supported by the deep learning methods. In deep learning, it is preferable as well as beneficial to use ample data with incomplete and noisy labels instead of using a small amount of complete and carefully labeled data. However, advanced
71

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
deep learning techniques are more efficient in handling noisy and cluttered data. For example, a novel training strategy with effective cost functions can create an advanced deep learning method, which can overcome the effect of noisy labels. In addition, semi-supervised learning mechanisms can be incorporated to reduce the adverse effects of noisy labels (Wang and Shen, 2007).
Challenges for High Variety Data
The variety of Big Data is another key area of concern when proposing learning mechanisms. Nowadays, all connected devices generate vast amounts of data. The invention of smartphones, social media, and the web has influenced the dramatic rise of various multimedia data i.e. audio, video, images, animation, etc. On top of the increased data volumes, the data formats vary from sensor data to satellite data. Moreover, these varieties of data can be unstructured, semi-structured, or structured data. Hence, data integration plays a major role in facilitating learning process among heterogeneous data types. Deep learning is widely known for its ability to representation learning. Certainly, this is a blessing to deal with high variety data. Moreover, representation learning supports supervised, unsupervised, and hybrid learning. Owing to the benefits of representation learning, deep learning can learn decent feature representations for classification. The representation learning follows unsupervised learning and traverse through a hierarchy. It defines one level at a time and follows bottom up approach, which uses lower-level features to define higherlevel features. Consequent to the hierarchical approach, intermediate and abstracted representations can be discovered. Hence, data integration can occupy representational learning to learn about each data source. Learning data representation is supported through deep learning. All the learned features in each level are integrated to assist learning process of heterogeneous data.
Ngiam et.al. integrated audio and video data to develop an innovative application for deep learning, which learns representations of varied data (Ngiam et al, 2011). Worthy to note that deep learning is highly acknowledged for its efficiency in integrating data from different origins. Moreover, Ngiam et.al. confirm that deep learning is fruitful in two aspects 1) learning shared representations for multiple types and 2) learning single representation. The shared representations perceive interrelationships among various types of data. Meanwhile, single representation is capable of capturing single type among various unlabeled types. Srivastav and Salakhutdinov fused two contrasting data types using a multimodal deep Boltzmann machines (DBM) (Srivastava et al, 2014). They fused real-value dense image and text data to find a common representation for multi-modal data. The DBM is a generative model, which is not fine-tuned. The multi-modal DBM is formed from stacked RBMs. Each RBM represents a single modality. In order to assist
72

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
collective representation of RBMs, an additional layer is added to the architecture. The additional layer of binary hidden units (BHU) resides on top of the RBMs and create DBM from RBMs. This layer of BHU learns distribution across the RBMs and allow learning from garbled modalities.
The recent works on deep learning exposed its abilities to use heterogeneous data with a high variety in order to enhance the learning performance. However, challenges in this regard still remain. One common challenge is the conflicts of information. The deep learning process can fuse and learn the common representations, but it cannot resolve the conflicts of data from multiple sources. Moreover, the benefit of deep learning to enhance the performance of multiple types is still questionable. Since existing learning mechanisms are experimented on bi-modals (two types). Further, the required number of layers in deep learning architecture for feature fusion of heterogeneous data remains as another challenge.
Challenges for High-Velocity Data
Big Data learning is further challenged by high-velocity data. An infinite number of connected devices and people generate data at a very high speed. The expeditious data generation requires timely processing of data. Online learning approach is an excellent fit for high-speed learning. Online learning learns a single instance at a time and exposes the true label of the instance soon after learning (Shalev-Shwartz, 2012). Thus, the labels can be used to improve the model. Consequent to the larger data sets, current machines are unable to hold the complete data set. Thus, the sequential processing of online approach is a promising learning method for Big Data. Online learning has been tested for classical neural networks. However, the work done on deep learning networks for online learning is minimal. Usually, deep learning approaches use a training example with a defined label to refine the model parameters. This training method is known as stochastic gradient descent approach (Shalev-Shwartz, Singer, Cotter, 2011). This learning approach is feasible extendable for online learning approach. The processing speed can be upgraded by allowing mini batch processing instead of single instance processing. Moreover, mini batch processing maintains the balance between computer memory and execution time.
The data distribution of high-velocity data shows an extremely changeable (non-stationary) nature, which is another primary challenge for Big Data learning. Non-stationary data are divided into portions, to hold data belongs to a narrow time interval. The division takes place with the assumption that proximal time scales hold approximately stationary data (Chien, Heieh, 2013). Moreover, they represent a correlation among data to a certain extent and follow a similar distribution pattern. Hence, the ability of learning data as a stream considered to be an important feature of deep learning for Big Data. The area to experiment further is deep online learning.
73

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
In general, online learning is memory bound and capable of parallel processing. Essentially, Big Data learning algorithms should be capable of learning nonindependent and identically distributed (non-iid) data.
Certainly, deep learning can transfer learning or follow domain adaption to influence high variety and high velocity of Big Data. These mechanisms sample training data and test data of different distributions. Glorot, et al. developed a deep architecture based on stacked de-noising auto-encoder. It trains a large set of unlabeled data using unsupervised representation (Glorot, Bordes, Bengio, 2011). It classifies unlabeled data into a set of identified domains using few labeled data from each domain. The labeled examples determine domains of the model. The experimental data revealed the ability of deep learning to elicit valid high-level representations, which are shared across disparate domains. Recently, Benjio experimented on transfer learning by applying deep learning of multiple level representations (Bengio, 2012). The finding revealed that many abstract features identified in deep learning are common in training and test data. Therefore, deep learning is a well-fitting approach for transfer learning as it is capable of identifying common features of presented data. However, the practical application of transfer learning based on deep learning is still in its infancy. Finally, the biggest question mark is to determine the potential of transfer learning to benefit Big Data with deep networks.
MOBILE BIG DATA ANALYTICS
Mobile devices became a convenient and trustworthy platform to facilitate ubiquitous computing. The evolution of mobile device i.e. smart phones, tablet pcs, and Internet of Things (IoT) gadgets have resulted in an exponential growth in mobile data generation. The dramatic rise in the volume of mobile data coined the concept of Mobile Big Data (MBD).
MBD Overview
MBD can be defined as the colossal amount of mobile data. MBD includes valuable information to handle fraud detection, marketing, context-aware computing, etc. However, the massive amounts of MBD cannot be processed using a single machine. The benefits of MBD have drawn the attention of experts towards extracting useful information from unprocessed mobile data. This area of interest is known as MBD analytics. Deep learning is a reliable candidate for MBD analytics. Deep learning offers highly accurate results utilizing unlabeled mobile data. It occupies unsupervised feature extraction to learn the relationships among heterogeneous mobile data. However, the efficiency of deep model MBD analytics is diminished due to a large
74

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
number of dimensions and high data volume. In contrast, mobile data systems tend to act real-time, since quicker decisions ensure higher user satisfaction.
MBD collects data from various mobile devices i.e. smart phones, wearable computers, laptops, IoT gadgets, etc. connected to a mobile network. Various mobile applications have come into existence thanks to the deployment of multiple sensors i.e. accelerometers, compasses, and GPS sensors. The mobile devices use stateless data interchange structures like JavaScript object notation (JSON) to wrap the service requests and sensor data, in order to share across the network. The importance of stateless structure is it supports mobile devices operates on different operating systems such as iOS, Android, and Windows. The service server finds hidden structures and patterns of collected MBD with the aid of MBD analytics. MBD analytics play an important role in building complex mobile systems. The flexibility of MBD analytics is comparatively higher than the classical MBD problems since the sources are mobile and data traffic is crowd-sourced. The large amounts of data collected from innumerable mobile devices complicate the learning process. Thus, MBD analytics become harder compared to the analysis of small datasets of mobile data.
Challenges for MDB Analytics
The generic features of MBD introduce challenges to MBD analytics. MBD is a large-scale mobile network, which generates data at a high speed. Mobile networks support mobility and allow distributed sensing via the mobile devices. This section briefly explains impacts of large-scale mobile data, mobility, and crowd sensing on MBD analytics.
The mobile data traffic is continuously increasing due to the proliferation of mobile devices and expansion high-speed mobile networks. The large-scale mobile networks have the adverse effects of high volume and high-velocity data. Importantly, MBD data flows rapidly (high velocity), which may increase the latency due to traffic. Consequently, it results in diminished user satisfaction and incremented cost as a result of delayed decisions. MBD collects data from portable devices. The mobility of the devices leads to the creation of non-stationary MBD. The mobility aspect can significantly reduce the available time duration for decision-making. Since the validity of collected data depends on the nature of mobility. Crowdsensing is another important feature of MBD that can be a challenge at the same time. In crowd sensing, the sensing devices are not of the same type and belongs to multiple users at different places. Due to the fact, MBD analytics face issues arising from the high variety and high veracity. The quality of sensed MBD is not guaranteed since the mobile system does not manipulate the mobile sensing process. Moreover, there are various reasons that increase the amount of incomplete and low-quality MBD. Noise is the most prominent reason for futile MBD. In addition, malfunctioning
75

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
sensors and intruders can result in incomplete data. Indeed, less quality data leads to less accuracy in MBD analytics. The heterogeneity is another concerning factor for MBD analytics. Various types of mobile devices generate MBD traffic and analyzing high variety mobile data is an issue that is worth to address to realize MBD analytics in real world context.
In summary, MBD analytics is all about discovering new patterns and knowledge from collected MBD. Thus, MBD is beneficial to uplift the service provision, while achieving lucrative business goals. However, challenges are existing in the area of MBD analytics, which needs to be addressed to further the evolution of MBD analytics.
CONCLUSION
Big Data notion has developed along with the dramatic rise of the digital data creation consequent to smart devices, social networks, and the web. In generic terms, Big Data large volumes of data generated at a high speed by heterogeneous devices. Big Data analytics is a trending topic in the modern world due to its advantages. The deep learning phenomena such as DBN and CNN is widely used to process the data in real-time. However, the capability of conventional machine learning techniques in Big Data analytics is limited by the volume, variety, and velocity of Big Data. Thus, the experts foresaw deep learning as a potential candidate for Big Data analytics. As mentioned in the previous sections, Big Data learning facilitated through deep learning mechanisms exhibit significantly better performance. However, the applications of deep learning for Big Data should be further extended in order to overcome unresolved challenges. MBD comes under Big Data, which concern about large amounts of mobile data. MBD has become the spotlight among mobile service providers due to its benefits in achieving business goals.
REFERENCES
Bengio, Y. (2012). Deep Learning of Representations for Unsupervised and Transfer Learning. Journal of Machine Learning Research, 27, 17–37.
Bengio, Y., & Bengio, S. (2000). Modeling High-Dimensional Discrete Data. Adv. Neural Inf. Process. Syst.
Chien, J.-T., & Hsieh, H.-L. (2013). Nonstationary Source Separation Using Sequential and Variational Bayesian Learning. IEEE Transactions on Neural Networks and Learning Systems, 24(5), 681–694. doi:10.1109/TNNLS.2013.2242090 PMID:24808420
76

Efficiently Processing Big Data in Real-Time Employing Deep Learning Algorithms
Ciresan, D. C., Meier, U., Masci, J., Gambardella, L. M., & Schmidhuber, J. (2011). Flexible, high performance convolutional neural networks for image classification. Proc. 22nd Int. Conf. Artif. Intell.
Coates, A., Huval, B., Wang, T., Wu, D., Catanzaro, B., & Andrew, N. (2013). Deep learning with COTS HPC systems. Journal of Machine Learning Research, 28(3), 1337–1345.
Gantz, J., & Reinsel, D. (2011). Extracting Value from Chaos. Available: https:// www.emc.com/collateral/analyst-reports/idc-extracting-value-from-chaos-ar.pdf
Glorot, X., Bordes, A., & Bengio, Y. (2011). Domain adaptation for large-scale sentiment classification: A deep learning approach. 28th International Conference on Machine Learning.
Hinton, G. (2002). Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8), 1771–1800. doi:10.1162/089976602760128018 PMID:12180402
Hinton, G. (2010). Apractical guide to training restricted Boltzmann machines. Toronto, Canada: Dept. Comput. Sci., Univ.
Krizhevsky, I. S. G. H. A. (2012). ImageNet classification with deep convolutional neural networks. Proc. Adv. NIPS.
Larochelle, Y. B. J. L. P. L. H. (2009). Exploring strategies for training deep neural networks. Journal of Machine Learning Research, 10, 1–40.
LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278–2324. doi:10.1109/5.726791
Lee, H., Battle, A., Raina, R., & Ng, A. (n.d.). Efficient sparse coding algorithms. Proc. Neural Inf. Procees. Syst.
National Security Agency. (2013). The National Security Agency: Missions, Authorities, Oversight and Partnerships. Available: https://www.nsa.gov/public_ info/_files/speeches_testimonies/2013_08_09_the_nsa_story.pdf
Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H., & Ng, A. Y. (2011). Multimodal Deep Learning. 28th International Conference on Machine Learning.
Raina, A. M. A. N. R. (2009). Large-scale deep unsupervised learning using graphics processors. Proc. 26th Int. Conf. Mach. Learn. doi:10.1145/1553374.1553486
77

