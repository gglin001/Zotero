相关与回归分析
1

相关分析与回归分析
1.相关分析 是指研究一个变量与另一个变量或另一 组变量之间相关方向和相关密切程度的 统计分析方法。
2.回归分析 是指根据相关关系的具体形态，选择一 个合适的数学模型来近似地表达变量间 平均变化关系的统计分析方法。
12

3.相关分析与回归分析的联系 (1)相关分析回归分析是研究现象之间相关关
系的两种基本方法，两者有着密切的联 系，它们不仅具有共同的研究对象，而且 在具体应用时，常常必须互相补充。 (2)相关分析需要依靠回归分析来表明现象数 量相关的具体形式，而回归分析则需要依 靠相关分析来表明现象数量变化的相关程 度。
13

(3)只有当变量之间存在着高度相关时，进 行回归分析寻求其相关的具体形式才有 意义。
(4)由于上述原因，回归分析和相关分析在 一些统计学的书籍中被合称为相关关系 分析或广义的相关分析。
14

4.相关分析与回归分析的区别
(1)相关分析中，变量x与变量y处于平等地
位，不需要区分自变量和因变量；回归
分析中，变量y称为因变量，处在被解 释的特殊地位。变量x称为自变量，可 以通过x的变化来解释y的变化，故亦称
为解释变量。
15

(2)相关分析中所涉及的变量y与x全是随机变量。 而回归分析中，因变量y是随机变量，自变量x 可以是随机变量，也可以是非随机的确定变量。
(3)相关分析的研究主要是刻画两类变量间线性相 关的密切程度。而回归分析不仅可以揭示变量 x对变量y的影响大小，还可以由回归方程进行 预测和控制。
16

相关关系的测度
测度相关 关系的方式

相关表

相关图

相关系数
17

相关系数
1.相关系数概念 是反映变量之间线性相关密切程度的统计分析指标。 相关系数可依总体数据或样本数据计算，分别定义为
总体相关系数  和样本相关系数 r 。
20

3.简单相关系数的计算
设 (xi，yi )(i  1，2，，n) 是 (x，y) 的 n 组样
本观察值，两个变量之间的简单线性相关系数
计算公式如下：

n

r

 ( xi  x )( yi  y )
i 1



L xy

n

n

  ( x i  x ) 2 ( y i  y ) 2

L xx L yy

i 1

i1

21

实际计算时也可以使用下列简捷公式：

r

n xy   x y

n x2   x2  n y2   y2

r 的取值范围是 [-1,1]， |r|=1，为完全相关，r =1， 为完全正相关，r =-1，为完全负正相关， r = 0，不存 在线性相关关系， -1r<0，为负相关， 0<r1，为正相 关，|r|越趋于1表示关系越密切；|r|越趋于0表示关系
越不密切

22

根据相关系数的取值判断相关程度的标准：

相关系数取值

相关程度

︱r︱≥0.8

高度相关

0.8＞︱r︱≥ 0.5

中度相关

0.5＞︱r︱≥ 0.3

低度相关

︱r︱＜0.3

不相关

必须注意，上述判断还只是针对样本而言的，样本范围 内所存在的现象之间的相关程度是否在总体范围内也存 在呢？就需要对总体相关程度进行假设检验。

23

4.相关关系的显著性检验
r是依据样本数据计算的，根据一个样本的相关 系数能否说明总体的相关性呢？这需对样本相关 系数的显著性进行检验。
样本相关系数的理论分布函数是很复杂的。r 的
抽样分布随总体相关系数和样本容量的大小而变 化。 在进行这项检验时，通常假设x与y是正态变量， 如果总体相关系数=0,则样本相关系数r服从t 分布。
24

(二) 相关系数
4.相关关系的显著性检验 检验的步骤为 (1)提出假设：H0：   ；H1：   0 (2)计算检验的统计量：
t  r n  2 ~ t(n  2) 1 r2
(3)确定显著性水平 (4)作出决策
若t>t，拒绝H0 若t<t，不能拒绝H0
25

一元线性回归分析
26

一、一元线性回归模型
(一)回归模型的基本形式 1.总体回归模型
y  0  1x  
式中：y 为因变量（被解释变量），x 为自变量(解释变
量)，0 和1是未知参数，称为回归参数，称 1 为回归
系数， 表示其他随机因素的影响，并假定 是不可观
测的随机误差，它是一个随机变量一般称之为变量y对x 的一元线性理论回归模型，或称为总体回归模型 。
27

(一) 回归模型的基本形式
y  0  1x  

0  1x



线性组合部分：确定部分 随机干扰部分：不确定部分
对于总体中的个体而言，有：
yi  0  1xi  i

28

(一) 回归模型的基本形式

2.总体回归函数（方程）
对于总体回归模型中的 i
E ( i )  0
Var ( i )   2

，通常假设：

对总体回归模型两边取期望，得：

E( yi )  0  1xi

29

(一) 回归模型的基本形式
3.样本回归模型
一般情况下，在研究某个实际问题时，对于获得的n 组
样本观测值来说，如果它们符合总体回归模型，则
yi  ˆ0  ˆ1 xi  ei , i  1, 2, , n
上式为样本回归模型，并假定 n 组数据是独立观测的，
故 y1, y2 ,, yn 都是独立的随机变量，ei 为残差，是对
i 的估计，ˆ0 , ˆ1 是对 0 , 1的估计。
30

(一) 回归模型的基本形式

4.样本回归函数（方程）
对于样本回归模型中的 ei ，通常假设：
E (ei )  0
Var (ei )  ˆ 2
对总体回归模型两边取期望，得：

E( yi )  ˆ0  ˆ1xi

样本回归函数（方程）

yˆi  ˆ0  ˆ1xi

估计的回归方程

(二) 回归模型的基本假设
假设1：误差项的期望值为0，即对所有的i有 E(i) 0
假设2：误差项的方差为常数，即对所有的i有
var(i )  E(i2)   2
假设3：误差项之间不存在自相关关系，其协方差为0，即当
i  j 时，有 cov(i,  j )  0 ；
假设4：自变量是给定的变量，与随机误差项线性无关； 假设5：随机误差项服从正态分布。
以上这些基本假设是德国数学家高斯最早提出的，故也称为高 斯假定或标准假定。
32

二、一元线性回归模型的估计
(一) 参数的最小二乘估计
参数的估计，就是寻求最佳直线来拟合变量间数量变化 关系的过程。

Y

· 。· yˆ  ˆ0 e ˆ1x 最佳直线

· ·· ·

误差 e
实际观测值 y

··

X

(一) 参数的最小二乘估计
基本思想：使误差平方和最小
  数学表达： Q ( ˆ0 , ˆ1 )  ei2  ( yi  yˆi )2   ( yi  ˆ0  ˆ1 xi )2
 min
解决办法：通过对Q求偏导数，确定使 其最小的 ˆ0 , ˆ1

(一) 参数的最小二乘估计

对Q求关于 ˆ0 , ˆ1 偏导数：


 
 
 

Q
ˆ0
Q
ˆ0

 2  2

( yi  ˆ0  ˆ1xi )  0 ( yi  ˆ0  ˆ1xi )xi  0

   nˆ0  ( xi ) ˆ1  yi

   
 (

xi ) ˆ0  (

x

2
i

)

ˆ1



xi yi

(一) 参数的最小二乘估计

 

ˆ

0



y



ˆ1 x

   


ˆ1

  



n

n

xi yi 

x

2 i



(

xi yi xi )2

 

ˆ

0



y



ˆ1 x

 


ˆ1



 

( xi  x )( yi  y ) ( xi  x )2

(三) 最小二乘估计量的性质---期望

最小二乘法是多种估计方法中的一种。按最小二
乘法求得的总体回归系数的估计值被称为最小二 乘估计量。最小二乘估计量的形式是不变的，但 根据所选取的样本不同，ˆ 的具体数值会随之变 化，因此它是一种随机变量。可以证明，在基本 假设能够得到满足的条件下，回归系数的最小二 乘估计量的期望值等于真值，即有

E(ˆ0 )  0

E (ˆ1)  1

39

(三) 最小二乘估计量的性质----方差

ˆ0和 ˆ1的 方 差 为 ：

 v a r( ˆ0

)



  

1 n



(x )2 ( xi 

x )2





2



1

 

n



(x )2 Lxx

 





2

 var(ˆ1 ) 

2

 2

( xi  x )2 Lxx

   Lxx 

( xi  x )2 

xi2  (

xi )2 n

40

(三) 最小二乘估计量的性质----方差

不难证明:

ˆ0



N

(0

,

(

1 n



( x )2 Lxx

)

2)

ˆ1



N (1,

2
Lxx

)

还可以证明 ˆ0 和 ˆ1分别是0 和 1的最佳线性无偏估计, 也称为最小方差线性无谝估计,也就是说,在 0和 1的一切
线性无偏估计中,它们的方差最小.

41

(四) 回归系数的区间估计
回归分析中，有时需要知道回归系数的取值 区间，此时就需要对回归系数进行区间估计。
对回归系数进行区间估计，就是在回归系数 分布的基础上，以回归系数的估计值为中心，构 造一个置信区间，使该区间以较大的概率包含总 体回归系数的真值。
42

(四 ) 回归系数的区间估计

根 据 1

~

N

( ˆ1 ,

2
L xx

)可

得

:

t  ˆ1   1   ˆ1

ˆ1   1 ˆ 2 / L xx

 ˆ1   1 L xx ˆ

服 从 自 由 度 为 n  2和 t分 布 ， 因 而 有

P

 

ˆ1



1



ˆ

L xx

 t


(n  2)  1  

2





P  ˆ1  t ( n  2 )



2

ˆ
L xx

  1  ˆ1  t ( n  2 ) 2

ˆ


 1

L xx 

43

(四) 回归系数的区间估计

即得1的置信度1 的置信区间为:

(ˆ1  t 2

ˆ
Lxx

, ˆ1

 t 2

ˆ
) Lxx

同理,根据ˆ0

~

N

(

0

,

(

1 n



( x )2 Lxx

)

2 ),可以推导出0

的置信区间为

（ˆ0  t 2 ˆ 

1 n



( x )2 Lxx

,

ˆ0



t

2

ˆ



1  (x)2） n Lxx

44

(五) 总体方差的估计
除了参数0，1外，一元线性回归模型还有一个未知 数，即总体随机误差项的方差 2。它是检验模型时必
须利用的一个重要参数，用以反映理论模型误差的大
小。由于随机误差项本身不能直接观测,因此需要用样 本回归模型的残差e代替随机误差项来估计 2。数学上 可以证明， 2的无偏估计ˆ 2可由下式给出:
  ˆ 2  ei2  (yi  yˆi )2 n2 n2
45

(五) 总体方差的估计

  对ˆ 2开平方,得ˆ 

ei2 

( yi  yˆi )2

n2

n2

ˆ 被称为回归标准差或估计标准差.正如标准差可以

说明平均数代表性大小一样,估计标准差则可以说明

回归线代表性的大小.

ˆ越小表明实际观测值与所拟合的样本回归线的离差

程度越小,即回回归具有较强的代表性.反之,ˆ越大表明

实际观测值与所拟合的样本回归线的离差程度越大,即

回归线的代表性越差.

46

(五) 总体方差的估计

如果利用上述定义公式手工计算估计标准误差时需
要求出每一项残差，计算工作较大。因此可以采用 下列简捷公式计算：

   ˆ 

y2 i



ˆ0

yi  ˆ1

xi yi

n2

上述简捷公式中所需的数据与计算相关系数和估计
回归系数时所用数据相同，这样可以大减计算工作 量，当然，如果是利用统计软件计算估计校准差， 则无所谓简捷计算公式。

47

三、显著性检验
当我们建立了一个实际问题的经验回归方程之后，还不能 马上用于分析和预测。因为得到的经验回归方程是否真正 描述了变量之间的统计规律性，还需要运用统计方法对回 归方程进行检验。 回归分析中的显著性包括两方面的内容： 一是对各回归系数的显著性检验（t检验）； 二是对整个回归方程的显著性检验（F检验）。 对于前者，通常采用t检验，而对于后者则是在方差分析的 基础上采用F检验。在一元线性回归模型中，由于只有一个
自变量，对 1  0 的t检验与对整个方程的F检验是一致的。
48

(一) t检验

t检验是统计推断中常用的一种检验方法。在回归分析

中主要用于检验回归系数的显著性。检验的原假设是

H0 : 1  0 ，备择假设是 H1 : 1  0 。
回归系数的显著性检验就是检验因变量y对自变量x的

影响程度是否显著。如果原假设H0成立，则因变量y与 自变量x之间并没有真正的线性关系，也就是说自变量

x的变化对因变量y并没有影响。

由于

1

~

N

(1,

2
Lxx

)

，因而当原假设 H0 : 1  0 成立

时，有

1

~

2
N (0, L xx

)

49

(一) t检验

此时, ˆ1在零附近波动,构造t统计量

t  ˆ1  ˆ1 Lxx

ˆ 2 Lxx

ˆ

  式中:ˆ 2  1 n2

e2  1 i n2

( yi  yˆi )

是 2的无偏估计,称ˆ为回归标准差.

50

(一) t检验
当原假设H0 : 1  0成立时,由式(8.14)构造的t统计量 服从自由度n  2为的t分布.给定显著性水平 ,双侧检 验的临界值为t 2.当时 t  t 2拒绝原假设H0 : 1  0,认 为1显著不为零,因变量y对自变量x的一元线性回归 成立;当 t  t 2时, 接受原假设H0 : 1  0,认为1为零,
因变量y对自变量x的一元线性回归不成立.
51

(二) F检验
1.F检验的意义 t检验主要用来检验各个回归系数是否显著，F检验则主要 用于检验整个回归方程是否有效。对于一元线性回归模 型，由于只有一个回归系数，两种检验所得的结果是相同 的。但对于多元线性回归模型则不同，t检验与F检验的结 果可能相同也可能不相同，即会出现各个回归系数能通过 检验而整个回归方程却不一定能够通过检验的情形，或者 出现相反的情形。F检验的主要目的在于分析各个因变量 值与其均值离差平方和中，由于自变量与因变量之间的回 归关系所产生的影响情况。
54

(二) F检验

2.F检验的思想

F检验的目的，在于对回归方程的线性关系的显著性进行检验。不难

理解，如果Y与X之间的线性关系显著，那么随着X朝某个方向变

动，Y将会比较紧密地围绕一条直线朝某个方向变动，Y绕该条直线

越紧密，则Y与X的线性关系越显著。此时，不论Y的波动变化如

何，它总是以该条直线为中心变动的。这种波动既包括了X对Y的系

统影响，也包括了随机因素对Y的影响。我们可以通过分析Y的总变

动中，是X对Y的系统影响大，还是随机因素对Y的影响大，如果X对

Y的系统影响大，就说明两者之间的线性关系越显著。所以，对回归

方程的线性关系进行显著性检验是从分析Y的总波动原因入手的。

y  0  1x



线性关系：Y直线变动 随机干扰：Y绕直线震荡变化

(二) F检验
3.Y的波动原因分析——总离差平方和分解
n 根据方差分析原理，将 y 的 个观察值之间的差异，用观察值 yi与
其平均值 y 的离差平方各来表示，并称之为总离差平方和，记为
SST。 将SST分解如下:
 SST  ( yi  y)2   ( yi  yˆi  yˆi  y)2     ( yi  yˆi )2  2 ( yi  yˆi )( yˆi  y)  ( yˆi  y)2    ( yi  yˆ)2  ( yˆi  y)2
其中可以证明
 ( yi  yˆi )( yˆi  y)  0
56

(二) F检验

y

(xi , yi )

来自残差


} y  yˆ
yy

yˆ  ˆ0  ˆ1x

} yˆ  y 来自回归

y

x

(二) F检验

n

n

n

 yi  y2   yˆi  y2   yi  yˆ 2

i 1

i 1

i 1

{ { {

总平方和 (SST)

回归平方和 (SSR)

残差平方和 (SSE)

SST = SSR + SSE

(二) F检验
4.三个平方和的意义 (1)总平方和(SST)
反映因变量的 n 个观察值与其均值的总离差
(2)回归平方和(SSR）
反映自变量 x 的变化对因变量 y 取值变化的影 响，或者说，是由于 x 与 y 之间的线性关系引 起的 y 的取值变化，也称为可解释的平方和 (3)残差平方和(SSE) 反映除 x 以外的其他因素对 y 取值的影响，也 称为不可解释的平方和或剩余平方和

(二) F检验
4.检验统计量的构造
直观地看，在SST中，如果SSR大于SSE，说明Y的 变化主要受X的影响，两者之间线性关系明显。但由 于SSR与SSE的大小与各自的自由度有关，故需要将 其除以各自的自由度后才能直接比较。于是构造如下 检验统计量：
F  SSR / p  F ( p, n  p 1) SSE / (n  p 1)
一元回归中：
F  SSR /1  F (1, n  2) SSE / (n  2)
60

(二) F检验
5.检验规则 若 F ≥ F (1, n  2) ： 则拒绝 H 0 :  1  0 ，说明变量之间存在显 著的线性关系； 若 F < F (1, n  2) ： 则接受 H 0 :  1  0 ，说明变量之间没有显 著的线性关系。
61

(二) F检验

6.方差分析表

表8.3

方差分析表

方差来 源
回归

平方和 SSR

自由 度
1

残差 SSE n-2

总和 SST n-1

均方误差 F统计量 显著性水 平（P值）

SSR/1

F检验统计

SSR /1 量大于临

SSE/ n-2 SSE / n  2 界值的概

率

62

(三) 样本决定系数
根据回归平方和与残差平方和的意义，我们知道如 果在总的离差平方和中回归平方和所占的比重越 大，则线性回归效果就越好，这说明回归直线与样 本观测值拟合优度就越好；如果残差平方和所占的 比重大，则回归直线与样本观测值拟合得就不理想。 这里把回归平方和与总离差平方和之比定义为样本
决定系数，记为 r 2 ,即
r 2  SSR  Lxx  (r )2 SST Lxx Lyy
63

(四) 样本决定系数   由关系式: ( yˆi  y)2  ˆ1 (xˆi  x )2 ，可
r 以证明上式的 2 正好是(8.1)式中相关
系数 r 的平方:
r 2  SSR  Lxx  (r )2 SST Lxx Lyy
64

四、回归模型的应用
65

(一)单值预测
yˆ0  ˆ0  ˆ1x0
这就是变量新值: y0  0  1x0  0 的单值预测.
66

(二) 区间预测
1.因变量单个值区间估计
为了给出新值y0的置信区间,需要求出其
估计值yˆ0  ˆ0  ˆ1x0的分布,由于ˆ0与ˆ1都 是y1, y2 ,, yn的线性组合,因而yˆ0  ˆ0  ˆ1x0
也是y1, y2 ,, yn的线性组合,在正态假设定
下yˆ0  ˆ0  ˆ1x0服从正态分布,其期望值为 E( yˆ0 )  0  1x0.其方差计算如下 :
67

1.因变量单个值区间估计

 yˆ0  ˆ0  ˆ1x0  y0  ˆ1x  ˆ0 x0 

  

1 n



( xi



x )(xi Lxx



x

)

  

yi

 var( yˆ0 ) 

1

 

n



( xi



x )(xi Lxx



x ) 2  

var( yi

)



1

 

n



( xi



x )(xi Lxx



x

)

 





2

可得到

yˆ0

~

N

  

0



1

x0

,

  

1 n



( xi



x )(xi Lxx



x

)

 





2

 



68

1.因变量单个值区间估计

yˆ0 是先前独立观测到的随机变量 y1, y2 ,, yn 的线性组合,
新值 y0与先前的观测值是独立的,所以 y0与 yˆ0 是独立的,因而

var( y0  yˆ0 )  var( y0 )  var ( yˆ0 )



2



1

 

n



( x0  x )2 Lxx

 





2



(1 

1 n



( x0  x )2 Lxx

)

2

再 由 E ( yˆ )  E ( y)有 E ( y0  yˆ0 )  0 于是有

y0



yˆ

～
0

N（

0,(1



1 n



(x0  x Lxx

)2

)

2）

69

1.因变量单个值区间估计
可知

t



(1 

1

y 0  yˆ 0
 ( x0  x ) 2 ) 2

~

t(n  2)

n

Lxx

于是有









P

 



 

y 0  yˆ 0

1  1  ( x0  x ) 2 ˆ

n

Lxx



t

2 (n



2

)

 



1





 

70

1.因变量单个值区间估计

由此我们可以求得 y0 的置信概率1 为的置信区间为

yˆ0  t 2 (n  2)

1 1  (x0  x )2 ˆ.........(8.15)

n

Lxx

当样本容量 n 较大, x0  x 较小时, y0 的置信度为95%
的置信区间近似为
yˆ0  2ˆ

71

2.因变量均值区间估计
(8.15)式给出的是因变量单个值的置信区间,我们关 心的另外一种情况是因变量均值的置信区间.对于 前面提出的人均消费性支出问题,如果有好几个地
区的人均可支配收入同为x0 ,那么这些地区对应的
人均消费性支出的平均数为多少? 这个问题就是要估计平均值 E( y0 ) . E( y0 ) 的区间
估计与因变量单个值 y0 的置信区间有所不同,由于
E( y0 )  0  1x0 为常数,由(8.14)可知
72

2.因变量均值区间估计

yˆ0



E(

y0

)～N（0,(

1 n



(x0  x Lxx

)2

)

2）

进而得因变量均值 E( y0 )置信水平为1 的 置信区间为

yˆ0  t 2 (n  2)

1  (x0  x )2 ˆ

n

Lxx

73

第三节 多元线性回归分析
75

一、多元线性回归模型
因为客观现象非常复杂，现象之间的联系方式和性质 各不相同，影响因变量变化的自变量往往是多个而不 只是一个，其中既有主要因素也有次要因素。如果仅 仅进行一元回归分析，不一定能得到满意的结果。因 此，有必要将一个因变量与多个自变量联系起来进行 分析。
在线性相关条件下，研究两个和两个以上自变量对一 个因变量的数量变化关系，称为多元线性回归分析， 表现这一数量关系的数学表达式则称为多元线性回归 方程或多元线性回归模型。
76

一、多元线性回归模型

(一)多元线性回归模型的一般形式

设随机变量y与一组自变量x1

,

x

2

,

x

的线性回归模型为
p

:

y  0  1x1  2 x2   p xp  ..............(8.17)

式中, 0 , 1, 2 ,,  p是个未知参数, 0称为回归常数,

1, 2,,  p称为回归系数.y称为被解释变量(因变量),

而x1,x2, xp是p个可以观测并可控制的般变量, 称为解

释变量(自变量).

77

(一)多元线性回归模型的一般形式
n  对于一个实际问题,如果我们获得了 组观测 数据 (xi1, xi2 ,, xip , yt ),i  1, 2,, n ,则线性回归模型 (8.17)式可表示为  y1  0  1x11  2 x12     p x1p  1 y2 0  1x21  2 x22     p x2 p   2  yn  0  1xn1  2 xn2     p xnp   n
78

(一)多元线性回归模型的一般形式

写成矩阵形式: y  X   .............(8.20)

式中:

y



 y1 

 

y

2

 

 

X



1 1 

x11
x21 

x12
x22 

  

x1p
x2 p 

   





0 1


 





0 1


   

 

yn

 

1 xn1

xn2



xnp

 

n

 



n

 

矩阵X是一个 n  ( p 1) 的矩阵,人们常称为回归设计矩 阵或资料,在实验设计中,X的元素是预先设定并可以控 制的,人的主观因素可作用于其中,因而X称为设计矩阵.
79

(二) 多元线性回归模型的基本假定

1、解释变量 x1, x2 , xp 是确定性变量，不是随机变
量，且要求 rank(X )  p 1  n ；

2、随机误差项具有0均值和等方差，即

E(i )  0,i  1, 2,n


cov( i


,

j

)



 2 ,i  j

 

0,i 

j

(i,

j



1, 2,,

n)

3、正态分布的假定条件为

1i

~
,

N (0, 2 ),i  2 ,n )是iid

1,

2,n

80

(三) 多元线性回归方程的解释

 在建立住房的预测模型时，用y来表示住房的

销售量，用x1表示住房的价格，x2表示消费者 人均可支配收入。则可建立二元线性回归方

程模型：

  

y E

 0  1x1   ( y)  0  1x1

2 x2



2 x2

 在式（8.21）中，假如x2保持不变，为一常数

时，则有：

E( y) x1



1

81

(三) 多元线性回归方程的解释

 即 1 可解释为在消费者人均收入x1保持不变高时，住房价 格般x来1每说变，动随一着个物单价位的，提对高住，房销销售售量量是y减的少平的均，影因响此程度1。将一是
负的。

 在（8.21）式中，假如x1保持不变，为一常数时，则有：

E( y) x2



2

 即 2可解释为在住房价格x1保持不变时，消费者人均可支

配收入x2每变动一个单位，对住房销售量y的平均影响程度。

一般来说，随着消费者人均可支配收入的增加，住房销售量

是增加的，因此 2 将是正的。

82

二、多元线性回归模型的估计

(一)回归系数的估计
多元线性回归方程未知参数 0 , 1,,  p的估计与一元
线性回归方程的参数估计原理一样,仍然可以采用最小二
乘估计.对于(8.20)式矩阵形式表示的回归模型 y  x   ,
所谓最小二乘法,就是寻找参数0 , 1,,  p 的估计值 ˆ0 , ˆ1,, ˆp 使离差平方和

 Q(0, 1,,p )  (yi  0  1xi1  2xi2  pxip )2

达到极小,即寻找

ˆ0

,

ˆ1,,

ˆ

满足以下关系
p

83

(一) 回归系数的估计

 Q(ˆ0 , ˆ1,, ˆp ) 

( yi



ˆ0



ˆ1 xi1



ˆ2 xi2



ˆp xip

2
)

  min 0 ,1,, p

( yi  0  1xi1  2 xi2    p xip )2................(8.22)

依照(8.22)式求出的 ˆ0 , ˆ1,, ˆp就称为回归参数
 0 ,  1 ,  ,  p 的最小二乘估计.

从(8.22)式中求出 ˆ0 , ˆ1,, ˆp 是一个求极值问题,
由于Q是关于  0 ,  1 ,  ,  p的非负二次函数,因而 这的最小值总是存在的.根据微积分中求极值的
原理, ˆ0 , ˆ1,, ˆp 应满足下列方程组

84

(一) 回归系数的估计

  Q

 



0

0 ˆ0  2

( yi  ˆ0  ˆ1xi1  ˆ 2 xi2    ˆ p xip )  0

  Q

 

1

1ˆ1  2

( yi  ˆ0  ˆ1xi1  ˆ 2 xi2    ˆ p xip )xi1  0

 

  Q
  p

 p ˆp  2

( yi  ˆ0  ˆ1xi1  ˆ 2 xi2    ˆ p xip )xip  0

以上方程级经整理后,得到用矩阵形式表示

的正规方程组
X '( y  X ˆ)  0

85

(一) 回归系数的估计
移项得:
X ' X ˆ  X ' y
当存在时,即得回归参数的最小二乘估计为:
ˆ  ( X ' X )1 X ' y
称: yˆ  ˆ0  ˆ1x1  ˆ2x2  ˆpxp
为经验回归方程.
86

(二) 最小二乘估计量的性质
 数学上可以证明,在基本假定条件可以得到满足 的情况下,多元回归模型中回归系数最小二乘估 计量的期望值同样等于总体回归系数的真值,即
ˆ 是  的无偏估计,可以表示为:
E(ˆ)  
 回归系数最小二乘估计量的方差,协方差矩阵为
D(ˆ)  cov(ˆ, ˆ)  E(ˆ   )(ˆ   )   2 ( X ' X )1
87

(二) 最小二乘估计量的性质
该矩阵主对角元素是各回归系数估计量的方 差 E(ˆj   j ),2其他元素是各回归系数估计量之间 的协方差 E(ˆi  i )(ˆj   j ),(i  j) .在此基础上,还可 以进一步证明回归系数的最小二乘估计量是最 优线性无偏估计量和一致估计量,也就是说,在 基本假设条件得到满足的多元线性回归模型中, 高斯·马尔柯夫定理同样成立.
88

(三) 总体方差的估计

 除了回归系数以外,多元线性回归模型中还包含 了另一个未知参数,即随机误差项的方差  2,与一 元母性回归分析相似,多元线性回归模型中的  2 也是利用残差平方和除以其自由度来估计.即有
ˆ 2  1 SSE
n  p 1

  1 (e 'e)  1

n  p 1

n  p 1

ei2

 ˆ是2 误差项方差  2的无偏估计量.

89

三、多元线性回归模型的检验

(一)回归系数的显著性检验(t检验)
多元线性回归模型中回归系数的检验同样采 用t检验,其原理和基本步骤与一元回归模型中 的t检验基本相同,就不在详细说明了.检验自变
量设x: j对H因0变j 量: y的j 影0响, 是j 否1显, 2著,,等,价n于检验假

如果接受原假设 果拒绝原假设 H

0Hj,0则j ,x则j对xjy对的y影的响影是响显不著显的著.;如

90

(一)回归系数的显著性检验(检验)
由上述讨论可知 ˆ 服从均值为  ,方差为 2 (X ' X )1
的正态分布,即
ˆ ~ N ( , 2 ( X ' X )1)
记
( X ' X )1  (cij ).i, j  0,1, 2,, p
91

(一)回归系数的显著性检验(t检验)

 于是有 E(ˆ j )   j , var(ˆ j )  c jj 2 ˆ j ~ N ( j , c jj 2 ), j  0,1, 2,, p

 据此可以构造t统计量：t j 

ˆ j ....(8.26) c jj ˆ

 式中 c jj 为矩阵主对角线 ( X ' X )上1 第个元素

  ˆ 

1

n  p 1

ei2 

1 n  p 1

( yi  yˆi )2 .....(8.27)

 是回归标准差。
92

回归系数的显著性检验(t检验)

当原假设H0 j

:



j



0成立时,

(8.26)式构造的t

统计量
j

服从自由度为n  p 1的t分布.给定显著性水平 , 查出

双侧检验的临界值t 2.当t j  t 2时拒绝原假设H0 j :  j  0, 认为 j显著不为零,自变量x j对因变量y的线性效果显著;

当t j  t 2时接受原假设H0 j :  j  0, 认为 j为零,自变量x j
对因变量y的线性效果不显著.

93

(二) 回归方程显著性的F检验



H0 : 1  2     p  0
如果H0被接受，则表明随机变量

y与

x1, x2 ,, xp之间

的关系用线性回归模型表示不合适。类似一元线性回归

检验，为了建立对H0进行检验的F统计量，仍然利用总离 差平方和的分解式，即；

   (yi  y)2  (yi  y)2  (yi  yˆi)2.........(8.28)

 简写为SST=SSR+SSE  构造F检验统计量如下：
F  SSR / p .............(8.29) SSE / u  p 1
94

(二)回归方程显著性的F检验
在正态假设下，当原假设勤 H0 : 1  2  p  0 成立时，F服从自由度为 ( p, n  p 1) 的F分布。 于是，可以利用F统计量对回归方程的总体显著 性进行检验。对于给定的数据，i  1, 2,, n 计算 出SSR和SSE，进而得到F 的值，其计算过程一 般列在表8.4的方差分析表中，再由给定的显著
性水平 ，查F分布表，得临界值
F ( p, n  p 1)
95

(二)回归方程显著性的F检验

著 关当性系F 水， F平也 (即p,n认下 为p，回y1)对归时方，x程拒1,是绝x2 显原,著假, x的设p有。H显0反，著之认的，为线当在性显

F  F ( p, n  p 1)时，则认为回归方程不显著。

表8.4

方差分析表

方差来源 平方和 自由度 均方误差 F统计量 显著性水 平（P值）

回归 残差 总和

SSR SSE

p n-p-1

SSR/p
SSE/ n-p-1

SSR / p SSE / n  p 1

F检验统计 量大于临 界值的概

SST n-1

率

96

(三) 回归系数的置信区间

由ˆi ~ N ( j , c jj 2 ), j  0,1, 2,, p,可知

tj



ˆ   j c jj ˆ

~ t(n 

p 1)

仿照一元线性回归系数区间估计的推导过程，可 得  j 的置信度为 1的置信区间为：

(ˆi  t 2 c jj ˆ , ˆi  t 2 c jj ˆ )

97

四、拟合优度检验
 在多元线性回归分析中，总离差平方和的分解公式依 然成立。因此，也可以利用上一节所定义的样本决定 系数作为评价模型拟合优度的一项指标。但为了避免 混淆，多元回归的决定系数用R2表示，并称为复决定 系数，即定义样本复决定系数为
R2=SSR/SSE=1-(SSE/SST)………..(8.30)  由样本复决定系数定义可知，R2的大小取决于残差平
方和SSE在总离差平方和SST中所占的比重.在样本容 量一定的条件下,总离差平方和与自变量的个数无关,而 残差平方和则会随着模型中自变量个数的增加而不断 减少,至少不会增加.
98

四、拟合优度检验

因此在多元回归分析中应该使用自由度调整后

的决定系数,即利用各自的自由度对总离差平

方和与残差平方和进行调整,然后再计算调整

后的决定系数

R

2 

.

R2

1

SSE /(n  SST /(n

p 1) 1)

 1 n 1 (1 R2 ) n  p 1

99

