See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/329891470
DEEP LEARNING IN INDUSTRY 4.0 – BRIEF
Article · December 2018
DOI: 10.24867/JPE-2018-02-001

CITATIONS
0
5 authors, including:
Lucijano Berus University of Maribor 3 PUBLICATIONS 0 CITATIONS
SEE PROFILE

READS
36
Simon Klancnik University of Maribor 28 PUBLICATIONS 179 CITATIONS
SEE PROFILE

Some of the authors of this publication are also working on these related projects: Classifying Parkinson’s Disease Based on Acoustic Measures Using Artificial Neural Networks View project Development of a self-optimizing baking system View project

All content following this page was uploaded by Lucijano Berus on 04 February 2019.
The user has requested enhancement of the downloaded file.

http://doi.org/10.24867/JPE-2018-02-001

JPE (2018) Vol.21 (2) Hernavs, J., Ficko, M., Berus, L., Rudolf, R., Klančnik, S.

Review Paper

DEEP LEARNING IN INDUSTRY 4.0 – BRIEF OVERVIEW
Received: 21 September 2018 / Accepted: 10 November 2018
Abstract: In recent years a lot of work has been done in the field of Deep Learning. With the launch of Industry 4.0, it is difficult for a company to stay relevant without implementing some sort of intelligent system. Big data, generated from a high variety of sensors, require elaborate systems which are able to distill useful information and make intelligent decisions. This paper presents a brief overview of Deep Learning techniques and provides some typical use cases from industry. Firstly, commonly used Deep Learning methods will be described, followed by a comparison between them. The significance of the Deep Learning techniques for Industry 4.0 is discussed further, and their application to problems in manufacturing. Finally, an overview of the current state- of-the-art object detection systems is presented, along with the future possibilities and potential development directions. Key words: deep learning, machine learning, manufacturing systems.

Duboko učenje u industriji 4.0 - kratak pregled. Poslednjih godina je urađeno mnogo u oblasti “Dubokog učenja“. Sa lansiranjem Industrije 4.0, teško je da kompanija ostane relevantna bez implementacije neke vrste inteligentnog sistema. Veliki podaci, koji su generisani iz velikog broja senzora, zahtevaju razrađene sisteme koji mogu da filtriraju korisne informacije i donose inteligente odluke. U ovom radu predstavljen je kratak pregled o tehnikama “Dubokog učenja“i pruža neke tipične slučajeve upotrebe u industriji. Prvo, uopšteno se koriste metode dubokog učenja, nakon čega sledi poređenje između njih. Dalje se govori o značaju tehnika dubokog učenja za industriju 4.0, i njihovu primenu na probleme u proizvodnji. Na kraju, predstavljen je pregled trenutnih najsavremenijih sistema za detekciju objekata, zajedno sa budućim mogućnostima i potencijalnim pravcima razvoja. Ključne reči: dubinsko učenje, mašinsko učenje, proizvodni sistemi.

1. INTRODUCTION
Our knowledge is expanding rapidly due to the large number of people involved in the research, and the fact that we are capable of an instant global communication. New findings give rise to the new technologies, which brings a lot of improvement potential to the current industries. It has only been several decades since the first industrial revolution, and we are already on the verge of the fourth. The core of Industry 4.0 can be characterised by the digitalization and integration of industrial manufacturing and logistics processes, and the use of the Internet and »smart« objects (machines and products). Physical and virtual worlds are merging via the Cyber-Physical Production Systems (CPPSs) that consist of online networks of social machines. The modern industry problems are growing in complexity, so there is a strong need for implementation of the intelligent systems that are up to the task. The best results are achieved by the deep machine learning methods in a field of Artificial Intelligence (AI). In the last ten years, the leading branch of AI turned out to be Deep Learning. The main contribution that this paper gives is an overview of the most important Deep Learning methods that have a good predisposition to take industries along the lines of the 4th Industrial Revolution. Some methods and applications of Deep Learning for manufacturing were analysed in [1] by Wang J. et al., where they presented a survey of commonly used Deep Learning algorithms. The paper

also depicts applications that enable turning manufacturing »smart«. Another related work was done by Fonseca L. M., and his article [2] provides an overview of the several industrial revolutions with emphasis on Industry 4.0.
2. DEEP LEARNING METHODS
In this section, some of the most promising methods are presented, portraying reasons for their wide use in industry. The interest and new knowledge acquired in the field of Deep Learning is exploding, so we restrict ourselves, and focus only on the more prominent techniques of Deep Learning. The following methods will be discussed: Convolutional Neural Networks, Autoencoders, Recurrent Neural Networks, Deep Reinforcement Learning and Generative Adversarial Networks.
2.1 Convolutional Neural Networks The method that brought significant success to the
topic of Deep Learning is called the Convolutional Neural Network (CNN or ConvNet), originally proposed by Yann LeCun et al. in 1998. Their paper [3] presents LeNet-5, a seven-layer CNN used for the recognition of handwritten digits from 32x32 pixel images (the structure can be seen in Figure 1). Since then, researchers have been building upon this architecture and started developing nets with higher structural complexity.

1

Fig. 1. Architecture of LeNet-5, a Convolutional Neural Network, for digits` recognition

An important milestone was achieved in 2012 as the team from Toronto (Alex Krizhevsky et al.) won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC). The task was to classify the 15 million highresolution images into roughly 22,000 different categories. They developed a CNN with eight layers – five convolutional and three fully-connected (details in [4]). With the use of some clever techniques, such as training on multiple GPUs, neurons with Rectified Linear Units (ReLU) nonlinearity, dropout, data augmentation, etc., the AlexNet was able to train significantly faster, with enhanced generalization capability, consequently outperforming the competition. The achieved top-5 test error rate was 15.3%, compared to 26.2% attained by the second-best entry. In late 2015, Microsoft Research Asia developed ResNet, which won ILSVRC 2015 with an incredible error rate of 3.6%. Currently, 29 of 38 teams that competed in ISVRC 2017 managed to get less than 5% wrong. Models with such adequate performance have a large potential to be the workhorses of Industry 4.0. Their significance lies in the tasks they are able to perform:  Semantic segmentation (classification of the pixels),  Classification and localization (determine what and
where a single object is in the image – bounding box),  Object detection (classification and localization of multiple objects – bounding boxes),  Object detection with captioning (additional description of objects and their relations in the image is provided),  Instance segmentation (prediction of which region of pixels corresponds to each object instance - masks),  Human pose estimation (prediction of human joints` position).
2.2 Autoencoders A neural network, designed to copy its input to its output is called an Autoencoder (AE). Generally, AEs are comprised of two parts; the encoder and decoder. The former attempts to abstract useful properties of the data, and the latter tries to reproduce the input as accurately as possible. But a network that simply learns to pass given input values to its output is not very useful. The purpose of Autoencoders is to extract representations of the data (i.e. learning correlations between input features). In order to achieve non-trivial training results of an Autoencoder, we have to

implement some kind of information bottleneck to the network structure. The first approach is to constrain a number of the neurons in the hidden layers, as it is in undercomplete autoencoders [5]. Although the likelihood of feature extraction is now increased, there exists a new danger for the Autoencoder not having a sufficient capacity (i.e. an AE that performs a copying task without extracting salient features about the distribution of the data). The alternative method introduces the information limitation without requiring a reduction in the number of nodes in the hidden layer. Sparse Autoencoders penalise activations within a layer, so that given some input certain neurons do not activate. AEs will ideally be sensitive enough to recreate the original observation, but insensitive enough to the training data such that the model learns a generalisable encoding and decoding. The Denoising Autoencoder is an approach that utilises slight corruption of the input data to develop a more generalisable model. This method still maintains the uncorrupted data as a target output. Two noteworthy applications of Autoencoders are information retrieval and dimenstionality reduction tasks. Furthermore, Autoencoders can be applied to anomaly detection, image inpainting or data denoising (e.g. images, audio) problems.
2.3 Recurrent Neural Networks Traditional neural networks are unaware of their
previous states, which is a vital drawback when dealing with time-dependent problems. Solving speech recognition, machine translation, image captioning, sentiment analysis, etc., requires an architecture that can make decisions based on the current input and the information from its previous states combined. This is a property of Recurrent Neural Networks (RNN). Their distinctive design modification is a loop that enables information flow from one step of the network to the next. The detailed principle of operation with helpful diagrams is presented in [6]. Unlike other networks, RNNs are capable of operating with variable-sized input and output vectors. Another characteristic of RNNs is the operation over a sequence of vectors over time and a non-fixed number of computations. We can interpret the structure of the RNN as multiple copies of the same network, each network passing a message to a successor. Figure 2 below demonstrates what happens if we unroll the loop.

2

Fig. 2. An unrolled structure of the RNN

The RNN can use a recent information to perform the present task, but, occasionally, a gap between the relevant information and the place that it is needed is large (i.e. cases where we require more context to execute a task). In such situations, RNNs become unable to connect the information. Long Short Term Memory networks (LSTM) are a special kind of RNNs, designed to avoid long-term dependency problems.
2.4 Deep Reinforcement Learning In March 2016 an algorithm competed against
legendary Go player Mr. Lee Sedol, winner of 18 world titles and widely considered to be the greatest player of the past decade. With the 4-1 victory, AplhaGo [7] proofed the significance of the Deep Reinforcement Learning. The basic concept behind this method is the use of an agent in the environment who performs some action determined by his policy. Executed actions affect the environment, and the response is then observed by the agent, who finds himself in the new state. The success and failure of the agent's actions is measured by a reward (positive for good, negative for bad actions).

Described interactions between an agent and the environment are running repeateadly during learning, which is represented by Figure 3. The purpose of Reinforcement Learning (RL) is to find the best strategy that maximises the reward. Let us consider some of the potential applications of the RL for Industry 4.0. The possibility for a machine to learn through its own experience was shown to be largely successful in Robotics. In [8], the robot arm (agent) was trained to perform real-world manipulation tasks (screwing a cap onto a bottle, inserting a specifically-shaped object through the cutout in a cube, placing a hanger on a stand, etc.), which require close coordination between vision and control. RL can also be used for optimization (supply chain, fleet logistics, product design, process planning, etc.), control (HVAC, autonomous vehicles, factory automation, machine tuning, wind turbine control, etc.), and monitoring (quality control, fault detection and isolation, predictive maintenance and inventory monitoring).

Fig. 3. Reinforcement Learning principle

2.5 Generative Adversarial Networks An interesting Deep Learning method emerged as
Ian Goodfellow et al. published their paper [9] in 2014. Generative Adversarial Networks (GANs) are comprised of two distinct networks – the generator and the discriminator. The generator produces new data
instances, while the discriminator evaluates them for
authenticity. Generator's ambition is to make passable
data, which are indistinguishable from real data. The
discriminator objective is to predict accurately which
data are real (data from a training dataset) and which is
fake (produced by the generator). Figure 4 provides a
more comprehensive representation of the GANs.

It comes as a no surprise that GANs are referred to as
robot artists, considering the impressive output they are
able to produce:  Image-to-image translation (e.g. applying Van Gogh
style to real pictures; CycleGAN [10]),  Text to image synthesis (generating a set of images,
fitting the description; StackGAN [11]),  Video generation (generating videos with scene
dynamics [12]),  3D object generation (3DGAN; [13]),  Music generation (MidiNet; [14]),  Medical applications (tumour, anomaly detection;
AnoGAN [15]).

3

Fig. 4. Generative Adversarial Networks

3. DEEP LEARNING APPLICATIONS IN MANUFACTURING SYSTEMS
Smart manufacturing envisions systems that provide us with insightful information about each of the steps of a product lifecycle. Deep Learning is being used in descriptive analytics for product quality inspection, diagnostic analytics for fault assessment, and predictive analytics for defect prognosis (discussed in [1], p8-9). The first aspect of the Deep Learning implementation in manufacturing can be viewed as a product quality control. Machine vision, connected with Deep Learning was shown to be effective for surface quality inspection [16]. It is used to detect anomalies, such as scratches, wears, dirties, discolouration, and burrs on textured or non-textured surfaces. Moreover, deep convolutional networks allow us to do an object detection, which can be applied to robot-assist tasks (e.g. a robot arm mounting a part on the CNC machine, robot object manipulation or sorting). Tasks for diagnostic analytics and fault assessment represent the second category, where the Deep Learning methods prove themselves necessary. In machinery, CNNs were used to evaluate defects in bearings, gearboxes, rotors, and wind generators. The planetary gearbox diagnosis was conducted with AEs and a five-layer deep neural network under various operating conditions [17]. What these examples show us is that the Deep Learning models outperform traditional Machine Learning techniques such as Support Vector Machine and backpropagation neural network, that have engineered features. The last area of Deep Learning applications is in the predictive analytics for defect prognosis, i.e. maintenance and service prediction. In [18], the longterm prognosis of rolling bearing health status was done with RNN. A combination between the CNN and bidirectional LSTM enabled prediction of machining tool wear. Vanilla LSTM provided good prediction accuracy in the remaining useful life estimation of an aircraft turbofan engine [19]. These and similar applications are crucial for manufacturing productivity growth and diminishing maintenance cost.

tasks and the desired consequences that these techniques induce. With the use of Graphics Processing Units (GPUs) and advanced algoritms, we are capable of solving problems in a domain where computers were never deemed to be adequate. Computers can now solve visual tasks like image recognition – possibly even with higher accuracy than humans (according to Andrej Karpathy's results as he competed against ConvNet on ImageNet dataset [20]), natural language processing and translation, as well as other tasks intrinsic to humans. Not only are we teaching computers things that come easily to us, we are also training them to manage jobs where we fall short. Namely, making sense of the exceedingly large amount of gathered data (e.g. detecting and categorising patterns in the data provided by various sensors in the manufacturing facility), or predicting future states of the elaborate phenomena, like user demand of services and products. The applications discussed in Section 3 are the reason behind a significant improvement of all manufacturing aspects. Deep Learning is bringing benefits to the design phase, testing and evaluation, production, operation control, maintenance, and sustainment. One has to acknowledge the impact of Deep Learning on large systems, where even the slightest of improvements bears considerable profit gains. Today, in the hope of decreasing costs and losses, industry is making efforts to achieve a higher degree of automation and connecting machines into the web for real-time control and monitoring. Regardless of the scale, more companies will try to adopt Deep Learning techniques, as their rivals who have implemented the aforementioned methods thus far are making them obsolete. On the research side, we can expect a marginal progress in already established algorithms and the sprouting of new approaches. Alongside quality control and machine fault detection, Deep Learning has yet to play an important role in areas such as Robotics – machine vision applications, Agriculture, Civil Engineering, and managing the big data challenge.
5. REFERENCES

4. CONCLUSION
The proclivity for an implementation of Deep Learning methods in modern manufacturing systems is quite unsurprising, considering their success at diverse

[1] Wang, J., Ma, Y., Zhang, L., Gao, R., Wu, D. (2018). Deep learning for smart manufacturing: Methods and applications, Special Issue on Smart Manufacturing, Journal of Manufacturing Systems July 2018 48 Part C:144-156.

4

[2] Fonseca, L. M. (2018). Industry 4.0 and the digital

society: concepts, dimensions and envisioned

benefits, Proceedings of the International

Conference on Business Excellence, Vol 12, Iss 1,

Pp 386-397 (2018).

[3] LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.

(1998). Gradient-Based Learning Applied to

Document Recognition, Proceednigs of the IEEE,

Pp 2278-2324 (1998).

[4] Krizhevsky, A., Sutskever, I., Hinton, G. E.

(2017). ImageNet Classification with Deep

Convolutional Neural Networks, Communications

of the ACM. Jun2017, Vol. 60 Issue 6, p84-90.

[5] Goodfellow, I., Bengio, Y., Courville, A. (2016).

Deep Learning, MIT Press, url:

http://www.deeplearningbook.org, Pp 499-508

(2016).

[6] Alom, Z., M., Taha, T., M., Yakopcic, C.,

Westberg, S., Sidike, P., Nasrin S., Van Essen, B.,

C., Awwal, A., A., S., Asari, V., K., (2018). The

History Began from AlexNet: A Comprehensive

Survey on Deep Learning Approaches, Cornell

University Library, 3. 3. 2018, p81-21.

[7] Silver, D., Huang, A., Maddison, C. J., Guez, A.,

Sifre, L., Van den Driessche, G., Schrittwieser, J.,

Antonoglou, I., Panneershelvam, V., Lanctot, M.,

Dieleman, S., Grewe, D., Nham, J., Kalchbrenner,

N., Sutskever, I., Lillicrap, T., Leach, M.,

Kavukcuoglu, K., Graepel, T. & Hassabis, D.

(2016). Mastering the game of Go with deep

neural networks and tree search, Nature;

1/28/2016, Vol. 529 Issue 7587 (2016).

[8] Levine, S., Finn, C., Darrell, T., Abbeel, P. (2015).

End-to-End Training of Deep Visuomotor Policies,

Journal of Machine Learning Research 17, (2016)

ftarxivpreprints,

url:

http://arxiv.org/abs/1504.00702

[9] Goodfellow, I., J., Pouget-Abadie, J., Mirza, M.,

Xu, B., Warde-Farley, D., Ozair, S., Courville, A.,

Bengio, Y. (2014). Generative Adversarial

Networks, arXiv:1406.2661

[10] Zhu, J., Park, T., Isola, P., Efros, A. A. (2017).

Unpaired Image-to-Image Translation Using

Cycle-Consistent Adversarial Networks, 2017

IEEE International Conference on Computer

Vision (ICCV) ICCV Computer Vision (ICCV),

2017 IEEE International Conference on. :2242-

2251 Oct, 2017

[11] Han, Z., Tao, X., Hongsheng, L., Shaoting, Z.,

Xiaogang, W., Xiaolei, H., Metaxas, D. (2017).

StackGAN: Text to Photo-Realistic Image

Synthesis with Stacked Generative Adversarial

Networks, 2017 IEEE International Conference on

Computer Vision (ICCV) ICCV Computer Vision

(ICCV), 2017 IEEE International Conference on.

:5908-5916 Oct, 2017

[12] Vondrick, C., Pirsiavash, H., Torralba, A. (2016).

Generating Videos with Scene Dynamics,

Computer

Science,

url:

http://arxiv.org/abs/1609.02612

[13] Wu, J., Zhang, C., Xue, T., Freeman, W.T.,

Tenenbaum, J.B. (2017). Learning a probabilistic

latent space of object shapes via 3D generative-

adversarial

modeling,

DSpace@MIT

(Massachusetts Institute of Technology),

https://papers.nips.cc/paper/6096-learning-a-

probabilistic-latent-space-of-object-shapes-via-3d-

generative-adversarial-modeling; Advances in

Neural Information Processing Systems 29 (NIPS

2016)

[14] Li-Chia, Y., Szu-Yu, C., Yi-Hsuan, Y. (2017).

MidiNet: A Convolutional Generative Adversarial

Network for Symbolic-Domain Music Generation,

Europe, Europe: ISMIR, 2017, url:

https://zenodo.org/record/1415990

[15] Schlegl, T., Seeböck, P.,Waldstein, S. M.,

Schmidt-Erfurth, U., Langs, G. (2017).

Unsupervised Anomaly Detection with Generative

Adversarial Networks to Guide Marker Discovery,

Computer

Science,

url:

http://arxiv.org/abs/1703.05921

[16] Xie X. A review of recent advances in surface

defect detection using texture analysis techniques.

Elcvia Electron Lett ComputVision Image

Anal2008;7(3):1–22.

[17] Jia F, Lei Y, Lin J, Zhou X, Lu N. Deep neural

networks: a promising tool for fault characteristic

mining and intelligent diagnosis of rotating

machinery with massive data. Mech Syst Signal

Process 2016;7:2–73, 303–315.

[18] Malhi A, Yan R, Gao RX. Prognosis of defect

propagation based on recurrent neural networks.

IEEE Trans Instrum Meas 2011;60(3):703–11.

[19] Wu Y, Yuan M, Dong S, Lin L, Liu Y. Remaining

useful life estimation of engineered systems using

vanilla LSTM neural networks. Neurocomputing

2017;226(5):853–60.

[20] Karpathy,

A.,

http://karpathy.github.io/2014/09/02/what-i-

learned-from-competing-against-a-convnet-on-

imagenet/, published 2 September, 2014

Authors: Jernej Hernavs, Izr. prof. dr. Mirko Ficko
Mag. inž. str. Lucijano Berus, izr. prof. dr. Rebeka Rudolf,
doc. dr. Simon Klančnik, Faculty of Mechanical Engineering Maribor, Smetanova 17, 2000 Maribor, Slovenia, E-mail: jernej.hernavs@um.si
mirko.ficko@um.si lucijano.berus@um.si rebeka.rudolf@um.si simon.klancnik@um.si

5
View publication stats

