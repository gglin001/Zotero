International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com
HRV Analysis for Daignosis: A Review

Desh Deepak Gautam Electrical Engineering Department M.M.M. University of Technology
Gorakhpur, India

V.K. Giri Electrical Engineering Department M.M.M. University of Technology
Gorakhpur, India

K.G. Upadhayay Electrical Engineering Department M.M.M. University of Technology
Gorakhpur, India

Abstract
For health diagnosis, HRV signals have become a promising tool and is being used for patient monitoring. Some linear and nonlinear analysis need to be done and then it becomes mandatory to have a better classification strategy to predict and classify the patients under test into different classes. These classes can be based on the arrhythmias or some other heart issues. This paper presents a brief review about analysis of HRV signals and then describe some classifiers which proves good for predicting the state of the patients under test. Some of the techniques like neural network based, fuzzy based, and SVM have shown better results in the literature. Some feature reduction techniques are also discussed which are used to reduce the feature numbers to increase the classification accuracy and prediction rate.
Keywords: Support Vector Machine; Arrhythmias; Artificial Neural Network; Principal Component Analysi; Feature Extraction

 Pre-processing (noise removal and peak detection)
 Generating HRV signal from ECG signal  Feature Extraction  Classification on the basis of features extracted The flow chart of HRV analysis is shown below.
ECG Data
Noise Removal
R-Peak Detection

INTRODUCTION
Heart rate variability is the variations in heart rate at continuous monitoring. That is that beat to beat variation in time interval is called heart rate variability (HRV). The heart rate which is defined as the number of beats per minute when measured in bpm or beats per minute usually varies at every beat due to the influence of some external disturbances. These disturbances are in the form of some signals propagates in a system known as Autonomic Nervous System (ANS). This autonomic nervous system automates or regulates the body and alters the heart rate by the influence of two of its activities known as sympathetic and asympathetic activities. A sympathetic activity increases the heart rate whereas an asympathetic activity decreases the heart rate. Hence we can define HRV as the irregular heartbeat. When this heart beat becomes abnormal then that situation is called Arrhythmia. Abnormalities in heart rate can be defined on the basis of heart rate i.e. very fast or very slow know as tachycardia and bradycardia respectively, on the basis of rhythm etc. For diagnosis purpose, the various arrhythmias need to be classified on the basis of some features of heart rate variability signal. So that an unhealthy heart can be treated for the proper affected arrhythmia.
The main steps involved in analysis of HRV signal are:
 Data Collection (ECG data)

HRV Signal
Feature Extraction
Feature Reduction
Classification
Figure 1: Flow Chart of HRV Analysis
The ECG data can be taken either from the online available databases or by volunteering process. The recorded or the downloaded data is generally very noisy so it is required to be filtered. Then HRV signal has to be extracted by detecting the R-Peaks as they are the most prominent peaks found in the signal. This generated signal is then analyzed by calculating and extracting some features. On the basis of these features the data is classified into several classes required for health monitoring. Classification is hence a very important step to be done of HRV signals for analysis and diagnosis of patients.

5968

International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com

The feature on the basis of which classification has to be done can be extracted from the HRV signal and can be categorized as linear and non-linear. Linear features are the time and frequency domain features and non-linear features are those features which gives the randomness in the system or the nonlinearity present in the system.

technique. Basheeruddin Shah Shaik et al. in 2015 utilized an adaptive threshold technique for detecting peaks in ECG signals on spectrogram by using STFT [8]. Nopadol Uchaipichat et al. employed STFT for filtering and peak detection of ECG signals [9].

PEAK DETECTION ALGORITHMS
When ECG signals are recorded then they are utilized for the generation of HRV signals. As it is known that the Heart rate variability is the variation found in the heart rate. That is the beat to beat variation in the heart series. This variation can be estimated by calculating the time interval of each beat. These beats can be categorized as five peaks viz P, Q, R, S and T in which R peak is the largest peak, hence easy to analyze. Therefore for generating HRV signal R-Peak detection is an important part. For detecting R-Peaks different algorithms have been given in literature which can be efficiently used for the purpose. The recorded ECG signals are generally found very noisy, hence they are required to be filtered first before going for peak detection.
Some low pass and high pass filters can be used to remove high and low frequency noises present in the signal. These noises can be result of any interference or movement of body while recording. Literature have shown that fourier transform, wavelet transform and discrete wavelet transform can also be used for removing noises from the signal as well as for peak detection.
Other algorithms which can be used for detecting peaks of the ECG signals can be Hilbert transform[1], Pan and Tompkins algorithm[2], Hamilton & Tompkins algorithm[3], Correlation Integral Method (CIM)[4] and Predictive Neural Network approach[5] with better results. Wavelet transform have been accepted and widely used for the noise removal and peak detection purpose for ECG signals[6][7]. Some algorithms are discussed here as follows:
A. Fourier Transform
1) Short Time Fourier Transform: STFT can be understand as a transformation of time domain signals in another domain which is a time frequency domain. The non-stationary signals in time domain are represented as stationary signals defined in a short interval of time within a window function[8]. The mathematical computations of STFT can be shown as

 T ( f , )  [x(t)w(t  )]e j2 ft dt 
In which w(t  ) shown above is the window function. From above equation the STFT represents any signal into 2-d function time, t, and frequency, f. The spectrogram which is the measure of energy surface distribution of STFT can be calculated as below
E( f , )  T ( f , ) 2
STFT represents the signal in time and frequency domain both and hence it is a good tool to analyze the ECG signals by this

B. Wavelet Transform
Wavelets have proved themselves a much better technique for noise removal and peak detection application over other fourier transform techniques as FFT, STFT due to its own advantages. For removing noise with help of wavelets, basically, it is done by three main steps: decomposition of noisy signal into many sub-bands by wavelet transform, filtering noise by removing coefficients which are smaller than the thresholds, reconstructing the signal without noise components. Wavelet transform represents any signal in a time-frequency plane by convoluting the original signal with a defined small interval wave also called wavelets, whose time and frequency can be scaled as per requirement. Peak detection algorithm using wavelets include main three steps as:
1) Decomposing ECG signal: ECG signal is first decomposed into some series of levels. Initial generally contains high frequencies which are out of the range of QRS frequencies hence becomes unnecessary to find peaks in these levels.
2) Defining threshold and coefficients: The frequency range of midrange levels will be chosen such that the baseline wander, T and P waves can be eliminated.
3) Finding QRS: Then an adaptive window size and step is selected to move the window over the signals, and peaks will be identified.
Different researchers have proposed several algorithms of wavelets by modifying it for better results such as Wavelet Transform, discrete wavelet transform (DWT)[10], adaptive wavelet transform[11], Dyadic Wavelet Transform[12] etc. While using discrete wavelet transform, Haar[13] and Daubechies[14] wavelet have shown better results. Some algorithms were tried to be mixed with wavelet transform for better results. H. Rabbani et al. employed Hilbert and wavelet transforms with another method called adaptive threshold for the detection of R-Peaks [15].
C. Hamilton and Tompkins Algorithm
Hamilton and Tompkins proposed a robust and powerful algorithm for detecting in the ECG data and reported the performance of the algorithm on the MIT-BIH database in their 1986 paper. This method works in two stages;
1. First the pre-processing of the available data is carried out including linear and non-linear filtering
2. Then some rules are used for decision making and to identify the necessary sections within the available ECG data to analyze further to detect R-peak referred as the fiducial point ([215]).

5969

International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com

The first stage can be understand in four steps.
1. In the first step, filtering is done in which a low pass filter is used to remove high frequency noise (such as main line interference) and a high pass filter to remove low frequency components.
2. Then differentiation of the signal is done to extract the slope information i.e. the changes occurring in the signal.
3. In the third step, the signal is squared to emphasize the high frequencies. After this step all the data becomes positive.
4. Then in the final step the signal is integrated within a moving window. By doing this a measure of energy distribution is known,
When preprocessing is done some rules are used to find out the peaks as follows:
1. A peak is defined in a segment of a waveform in which the waveform exceeds and falls below a defined threshold. This threshold is defined as a fraction of the median value of last 10 fiducial points.
2. This peak is searched back in the filtered data and the fiducial points are found.
3. The size of window is set within 150 to 200ms when the time packet is usually longer than normal.
4. Due to the fact that tissues require some minimum time for repolarization, two consecutive peaks cannot have a time difference of a minimum value i.e. 200ms.
5. If a peak is not detected for a certain length of time greater than a value, then a secondary search is done through the filtered data for lower threshold values.
FEATURES OF HRV SIGNALS
An HRV signal have mainly three types of features, linear which can further be classified into time domain and frequency domain and non-linear features [16-19]. On the basis of these features an HRV signal can have mainly three types of analysis as,
1) Time domain analysis 2) Frequency domain analysis 3) Non-linear analysis
1) Time Domain Analysis: Time and frequency domain combined are called linear feature or the analysis done based on them is called linear analysis. Time domain features can be defined as the features which are calculated with the time reference. For example, the mean of the R-R variation for all samples ( meannn ), the standard deviation of peak to peak
distances of all samples ( sdnn ). Some features can be calculated on the basis of some reference value, for example, number of consecutive samples having R-R distance more

than 50msec or 10msec ( pnn50 or pnn10 ). These values can be calculated by using these expressions:

k

 ( Rn1Rn )

meannn  n1

k

(1)

k 

(n (n1n2 ...nk )

)2

sdnn  n1

k k

(2)

samples ( RRlenght 50ms )

pnn50 % 

k

(3)

2) Frequency Domain Analysis: In frequency domain analysis the heart rate variability signal which was initially defined in time domain i.e. plotted against time or samples, is first converted into the frequency domain. This can be done by taking its Fourier transform. When any signal is converted into frequency domain, then in that domain the signal is represented by its several constituents of different frequencies. When this HRV signal is plotted in frequency domain, various frequency components come into picture. The overall frequency domain plot was divided into mainly three frequency bands,
 Very low frequencies (VLF) = 0-0.04Hz  Low frequencies (LF) = 0.04-0.4Hz  High frequencies (HF) = 0.4Hz-above

3) Non-Linear Analysis: Non-linear analysis is a very important analysis as it gives very useful information about the HRV signal. There are various methods for this non-linear analysis, some of them are: a) Poincare Plot: Poincare plot is a graphical representation
of the present sample and the next sample. That is it is the plot between successive samples of the signals. It can be calculated mathematically as SD1/SD2 [20]. SD1 and SD2 are the standard deviation of the distances of the points calculated from two lines having expression y=x and y=x+Rm, where Rm is the mean of the distances of the successive heart beats respectively. b) Correlation Dimension: This feature shows the measure of complexity of the heart rate variation and describes the minimum number of dynamic variables which are used to model the systems [21]. c) Largest Lyuponov Exponent: Largest Lyuponov Exponent (LLE) shows the dependencies of the system on the initial conditions. If chaos is present in the system the LLE will have a positive value. For calculating this exponent a value is first selected in a phase space and then the other points are calculated residing in the predefined circle of some defined radius [22]. d) Spectral Entropy: This variable shows the complexity present in the system. Greater values of spectral entropy shows greater irregularities and lesser values represents more regularity in the system [24].
Poincare Plot is a very effective tool for analyzing the nonlinearity in any signal plotted between the present sample and the upcoming sample. Hence it gives a detailed knowledge of the variations present between the samples. This plot gives

5970

International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com

information about short term heart rate variability as well as the long term heart rate variability [25].
VARIOUS METHODS FOR CLASSIFICATION OF HRV SIGNALS
The features discussed above differentiates data for several classes, either it is healthy or unhealthy, if unhealthy, then the class of arrhythmia. There are various method discussed in the literature for classifying the data of HRV signals into various arrhythmia classes and normal class like ANN based, Fuzzy based methods, Support Vector Machine, k-Nearest Neighbors algorithm etc.
Fuzzy based methods are one of the simplest method which can be used for predicting different heart series by applying some fuzzy rules for input output relations. ANN based methods works well and based on the training the system. Support vector classiﬁers have become very popular in last few decades and proved an efficient and effective method for machine learning applications. This method is based on recent advances in statistical learning theory [26]. It utilizes a hypothesis space of linear functions in a high-dimensional feature space, trained with a learning algorithm from optimization theory that implements a learning bias derived from statistical learning theory. In the last decade, SVM learning has found a wide range of applications [27], including image segmentation [28] and classiﬁcation [29], object recognition [30], image fusion [31], and stereo correspondence [32]. More recently, SVMs have been employed in several applications in biomedicine: gait degeneration due to age [33], EEG signal classiﬁcation [34], brain computer interfacing (BCI) [35], [36], analysis and prediction of scoliosis [37], [38], electrogastrogram analysis [39], and color Doppler echocardiography [40].
ANN based methods have also been used and give good results. Artificial Neural Network (ANN) which has various architectures like Single Layer Perceptron, Multi-Layer Perceptron, RBF etc. were used by different researchers and showed efficient classification results. Ali Sadr et al. show RBF a better option on MLP architecture with 2% better accuracy. Backpropagation algorithm for calculating weights of neural network architecture is proved better for prediction or classification [41].
ANN method is widely being used for classification and prediction purposes either alone or combined with some other method like Fuzzy [42], SVM, wavelets [43] etc. for increasing the prediction rate and accuracy.
A. Artificial Neural Network
After the advancements in Artificial Intelligence several methodologies were proposed for optimization, classification and regression purposes. Artificial Neural Network is one of them and finds application in various fields like biomedical signal, finance, mathematical modeling, engineering etc. This is a specially designed network inspired by biological neuron which gets trained for selection after going through a large

data. As the human brain classifies objects on the basis of experience of past data, neural network is also gets training first with some training data, and then the test data is applied for classification.
Figure 2: A Sample Neural Network
The weights of neural network are regularly adjusted while training to such as to minimize the error or to increase the classification boundary. Classification boundary differentiates the available data into two or more classes. This boundary is required to be maximum so as have best separable data. Neural Networks have various architectures defined by various researchers to efficiently calculate the weights of NN architectures which can be broadly categorized as:
 Feedforward ANN  Feedback ANN Feedback ANNs are those with feedback path and Feedforward ANNs are those with no feedback path for propagation. Most of the architectures and algorithms used for classifying data comes under feedforward ANN, such as MLP, Back Propagation Algorithm (MLP), Radial Basis Function (RBF), etc. These algorithms train the neural network by calculating and adjusting the weights.
B. Fussy Based Classifier In this classifier some if-then rules are used to define the input targets and the output classes. The complete input pattern space is divided into several sub sets or sub input classes. Then for each these sub classes the defined rules are applied to establish a relation between input and output. By defining these rules the input can be easily classified in different output classes by defining a classifying boundary. The advantage of this classifier is that is can be implemented for nonlinear classification as it can define nonlinear classifying boundary.

5971

International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com

The algorithm for this classifier is as follows:

Step 1- Fuzzify Inputs: The input is fuzzified using symmetric gaussian membership function given by

f

( x; 

,

)



e( x )2 22

(4)

Step 2 - Fuzzy inference: In this process the input output relations are established by defining some rules for different input output classes. The output decisions are made on the bases of these fuzzy rules. This whole system is known as fuzzy inference system. In this method,

 A data point which is having highest potential to be the first cluster center is selected

 All data points in the vicinity of the first cluster center (as determined by radii) is removed in order to determine the next data cluster and its center location

 The whole process is repeated until all the data points lie within the circle defined above.

Step 3 - Final output: Then the sugeno fuzzy model is used to have the output. The membership function used in this process
usually linear and is given by r  ax  by  cz  d

Some weights are provided by using a firing strength wi to the output level ri. Then the final output is computed as the average of these weighted rule outputs as

N

finaloutput



 i1

wi ri

N

(5)

 i1

wi

C. Support Vector Machine
Support Vector Machine is a novel technique for classification and regression developed by Vladimir Vapnik and co-workers at AT&T Bell Laboratories in 1995 [44].

Figure 3: Support Vector Machine

The basic principle of this technique is to maximize the margin of hyperplane as shown in above figure. An optimal hyperplane is developed to distinguish two different class of data or objects and the margin of that plane is kept at maximum value so as to have the best classification. This is done by calculating the distance of nearest data points from the hyperplane on both the sides. This distance is represented by vectors and known as support vectors.
These support vectors are utilized to have maximum margin as combined on both the sides they give the length of margin. This technique is best suited for exactly two classes and has proved itself a superior technique then the other ones. A hyperplane is defined in this technique which is used to separate the different classes. For the data which are nonlinearly separable a nonlinearity is introduced in the hyperplane.
Let if a vector x  Rn signifies a pattern to be classify and scalar y is its class given as ( y {1}) . Also say
{(xi , yi ); i  1, 2,...l} is a set of training examples. Now the challenge is to build a decision function f (x) that effectively classiﬁes an input pattern into various classes that is not necessarily in the above defined training set [45].

1) Linear SVM classifier

If the data or input points which are given as training patterns found to be linearly separable, then a linear function of the form exists as f (x)  wT x  b such that yi f (xi )  0 , or
f (xi )  0 for yi  1 and f (xi )  0 for yi  1 . Vector w and scalar b represent the hyperplane f (x)  wT x  b  0
separating the two classes. There may be many hyperplanes or boundaries which can separate the two given classes, the SVM classiﬁer go for the hyperplane that maximizes the margins which seperates the two classes. This can be done by minimizing the cost function

J (w)



1 2

wT

w



1 2

w2

(6)

Subject

to

the

separability

constraints

yi (wT xi  b)  1, i  1, 2,..., l . If the given training data is not completely separable by a hyperplane, a set of slack variable

i  0; i  1, 2,..., l , l is introduced that gives the amount of

violation

of

linearity

constraint

yi (wT xi  b)  1  i ,i  0, i  1, 2,..., l . The cost function is then modiﬁed to take into consideration the amount of the constraint violations. Hence, the function to be minimized becomes

J (w, ) 

1 2

w2

l  C  i
i1

(7)

5972

International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com

After some small chnges, it is seen that the vector w is formed by the linear combination of the training vectors

l w   i yi xi

(8)

i1

Where i  0, i  1, 2, ..., l are the Lagrange multipliers associated with the constraints in (7). The Lagrange multipliers are solved for the dual problem of (8), which is expressed as

  l
maix{i1i



1l 
2 i 1

l  i j 1

yi y j xi x j

 j}

(9)

Subject to the constraints

l

i



0,  i yi 0 i1

(10)

2) Kernel Based SVM classifier
For some datasets, it becomes necessary to introduce some nonlinearity in the classifying boundary or hyperplane as the data which has to be classified is not linear in the plane. For that situation some nonlinearity has to be introduced in the hyperplane.

Let Φ(·) be a nonlinear operator mapping the input vector x to a higher dimensional space. The optimization problem for the new points Φ(x) becomes

 min J (w, )  1
2

l
w 2  C i
i 1

(11)

Subject

to

the

constraints

yi (wT(xi )  b)  1  i,i,  0, i  1, 2, ..., l following the same

principles as in the linear case, we note that the only form in

which the mapping appears is in terms

of K (xi , x j )  T (xi )(x j ) . Finally, the dual problem to be

solved is

l maix{i1i



1l 
2i1

l  i j1

(

yi

y

j

)k

(

xi

x

j

)

j}

(12)

l

Subject

to

the

constraints i



0,  i yi 0 i1

,

and

the

classiﬁer

l becomes f (x)  sign(  i yik(xix j )b) .
i1

FEATURES REDUCTION BASED CLASSIFICATION
As it is clear that the classification is done on the basis of the features extracted from the HRV signal. These features differ from class to class and help in defining the class boundary. But some features spread over multiple classes and creates confusion for the classifier. Hence these features are needed to be ignored while classifying the data. Therefore features are reduced before going for data classification to increase the

efficiency and true prediction rate. Several methods are available in literature for feature reduction purpose such as Principal Component Analysis (PCA)[46], Linear Discriminant Analysis (LDA)[47], General Discriminant Analysis (GDA)[48] etc. These methods reduce the dimension of the feature matrix by eradicating the feature values which are common in more than one class for classification.

A. Principal Component Analysis
PCA works on maximizing the variation present in the data need to be classified. The following steps are involved for reducing dimensionality of data matrix X which consists n ECG samples xi (i {1, 2,..., n}) having D number of features from each sample,

1) Zero mean data points: In this step some data points are defined which is having their mean x as zero.

2) Evaluating a co-variance matrix

C  (x  x)(x  x)T

3) Then the eigenvectors V and eigen values E are determined

V 1CV  E

4) Sorting of eigen vectors: The principal component is chosen as the eigen vector having highest eigen value.

5) Projection of data

  Projected data = V T

 

xx

T T 

Different classification by this technique is done by moving the selection of components from the value 1 to 10 and the results are analyzed[49-51].

B. Multi-Dimensional Scaling (MDS)
MDS does a geometric mapping of the input data matrix X with n ECG samples to a new dimension space known as Euclidean space with n samples. The steps involved in dimensionality reduction are stated as[52-53],
1) First the samples are assigned with arbitrary coordinates in a p-dimensional space.
2) Then distance between all pairs of these samples is calculated in all the dimensions, known as Euclidean distances. A matrix is formed using all these calculated values called Dhat matrix.
3) Then this Dhat matrix is compared with the input matrix by using stress function.
4) The coordinates of each sample is adjusted such as to achieve maximum stress.

5973

International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com

5) Repeat above steps (2 to 4) until the stress value gets a lower value. And finally a low dimensional mapping is done on the basis of significant Eigen values.

C. Linear Discriminant Analysis (LDA)
This technique gives the highest possible discrimination within ECG classes so that the classification can be done more accurately and efficiently. This is done by removing the features which tends to decrease the discriminating margin and takes into consideration the features which are more suited for better classification. The steps involved in this technique are shown as follows[54-56],
1) First the within class covariance is evaluated as,

k

Ws

  Wk k 1

where, VWk  nCk (xn xk )(xn xk )T and K is the total number of output classes, Nk is the total number samples in output class Ck and xn is the DWT coefficient vector of nth sample in class Ck .
2) Then the between class covariance is evaluated as,

Bs



k


Nk (mk m)(mk m)T

k 1

Where,

m



1 N

k  Nkmk k 1

3) Then finally the total covariance is obtained by,

ST  Ws  Bs 4) Now the projection matrix is calculated,
  W  argw max (WBsWT )1(WBsWT )
5) And then the LDA coefficients are computed,

y  WT x
The LDA components are varied from values 1 to 10 columns in y for classification of Arrhythmias and the results are analyzed.

D. Generalized Discriminant Analysis
GDA is a higher version of LDA. The non-linear problems which cannot be solved by linear discriminant analysis, the generalized discriminant analysis is used in that case. Hence it can be said that the GDA is a nonlinear version of LDA[57].
GDA was introduced by Baudat G. et al. in their paper [26] to deal with the nonlinear problems using kernel function operator. This theory maps the given input vectors into a higher dimensional space. The linear properties of this new

space makes possible to generalize the LDA analysis to nonlinear problems.
Babak Mohammadzadeh Asl et al. shows an efficient classification of HRV signals by using GDA based support vector machine classifier. They took initially 15 linear and nonlinear features and then reduced them to 5 with the help of GDA algorithm[55]. They showed 98.94%, 98.96%, 98.53%, 98.51%, 100% and 100% accuracy for six different arrhythmias including normal sinus rhythm, premature ventricular contraction, atrial fibrillation, sick sinus syndrome, ventricular fibrillation and 28 heart block respectively.
DISCUSSIONS
The various techniques discussed in this study performs well as a classifier. Fuzzy based, ANN based, SVM methods proves themselves as a great choice for classification of heart beats for better patient monitoring. Some statistical measures have been defined in literature to evaluate the performance of the classifier which are as follows.
True Positive (TP): When the classifier correctly predicts the data affected with some arrhythmia.
False Positive (FP): When the classifier wrongly predicts some arrhythmia while the data is normal.
True Negative (TN): When the data or subject under test is normal and the classifier too says it is normal.
False Negative (FN): If the data is said to have some arrhythmia but the classifier fails to predict it as arrhythmia.
Sensitivity: This shows the ability of any classifier for predicting any arrhythmia when the subject having really some arrhythmia.
Sensitivity  TP / (TP  FN )
Specificity: This shows the ability of any classifier for predicting normal when the subject is really normal.
Specificity  TN / (TN  FP)
Positive Predictive Value (PPV): This gives the probability of the subject to have some arrhythmia, when the same subject is classified in the arrhythmia class.
PPV  TP / (TP  FP)
Negative Predictive Value (NPV): This gives the probability of the subject to be healthy, when the same subject is classified as healthy.
NPV  TN / (TN  FN)
Classification Accuracy of the Classifier: This parameter is the ratio of the total number of correct assessments to the total number of assessments.
Accuracy  (TP  TN) / (TP  TN  FP  FN)

5974

International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com

Table I: Comparison of Different Classifiers according to Literature based on the above Mentioned Performance Parameters

Sensitivity Specificity Accuracy Ref.

ANN

99-100 99-100 99-100 [41],[45],[47],[50],[52]

Linear SVM 93-97 95-97 93-98 [52],[55],[56],[57]

Non-Linear 98-100 98-100 98-100 [40],[51],[52],[54],[56] SVM

Table I shows a comparison between performances of some classifiers according to literature based on some parameters defined above. These parameters are sensitivity, specificity and accuracy. Fuzzy and ANN classifiers are good at prediction with accuracy of greater than 98% but when they are used combined, fuzzy estimates the weights of the neural network and neural net then defines the classifying boundary, the prediction efficiency increases. SVM classifier performs much better when there are exactly two classes for classification. SVM can also be used with some other method to predict combined gives accuracy greater than 99%.
Feature reduction methods are also generally used before classification to increase the prediction accuracy up to 100% by excluding the features which creates confusion as they belongs to more than one class.

CONCLUSION
Various techniques have been discussed in this paper for handling ECG and HRV signals, from preprocessing of the signals i.e. noise removal and peak detection to finally classifying them in different arrhythmia classes so as to have proper health monitoring of the patient. Fuzzy and ANN based methods have shown good results in the past and have been widely used. Support Vector Machine has proved itself a good choice and an effective classifier with an accuracy of upto 100%.

REFERENCES
[1] T. Chanwimalueang, W. Von Rosenberg, and D. P. Mandic, “Enabling R-peak Detection in Wearable ECG : Combining Matched Filtering and Hilbert Transform,” pp. 134–138, 2015
[2] T. Chanwimalueang, W. Von Rosenberg, and D. P. Mandic, “Enabling R-peak Detection in Wearable ECG : Combining Matched Filtering and Hilbert Transform,” pp. 134–138, 2015.
[3] R. Alonso, A. J. Méndez, and X. A. Vila, “A comparison of three QRS detection algorithms over a public database,” Procedia Technol., vol. 9, pp. 1159– 1165, 2013.
[4] Y. Li and X. Chen, “A Robust R-Wave Detection algorithm in ECG Signal,” pp. 2433–2436, 2011
[5] P. Taylor, G. Vijaya, V. Kumar, and H. K. Verma, “Artificial neural network based wave complex

detection in electrocardiograms Artificial neural network based wave complex detection in electrocardiograms,” no. April 2015, pp. 37–41, 2007.
[6] S. Lecturer, “Signal Processing of Heart Rate Variability using Wavelet Transform for Mental Stress,” 2010.
[7] S. Bensegueni, A. Bennia, and I. T. Qrs, “R-Peak Detection using Wavelet Transforms,” vol. 77, 2015..
[8] B. S. Shaik, G. V. S. S. K. R. Naganjaneyulu, T. Chandrasheker, and A. V. Narasimhadhan, “A Method for QRS Delineation Based on STFT Using Adaptive Threshold,” Procedia Comput. Sci., vol. 54, pp. 646– 653, 2015.
[9] N. Uchaipichat and S. Inban, “Development of QRS Detection using Short-time Fourier Transform based Technique,” Int. J. Comput. Appl., vol. CASCT, no. 1, pp. 7–10, 2010.
[10] H. Lin, S. Liang, Y. Ho, and Y. Lin, “Discrete-WaveletTransform-Based Noise Reduction and R Wave Detection for ECG Signals,” no. Healthcom, pp. 355– 360, 2013.
[11] W. Zhang, X. Wang, L. Ge, and Z. Zhang, “Noise Reduction in ECG Signal Based on Adaptive Wavelet Transform,” pp. 2699–2702, 2005
[13] P. Taylor, “P- and T-wave Delineation in ECG Signals using Support P ‑ and T ‑ wave Delineation in ECG Signals using Support Vector Machine,” no. December 2014, pp. 37–41.
[14] H. M. R. A. Trivedi and K. C. S. Shukla, “R-Peak Detection using Daubechies Wavelet and ECG Signal Classification using Radial Basis Function Neural Network,” vol. 95, no. March, pp. 63–71, 2014.
[15] H. Rabbani, M. P. Mahjoob, E. Farahabadi, and A. Farahabadi, “R Peak Detection in Electrocardiogram Signal Based on an Optimal Combination of Wavelet Transform , Hilbert Transform , and Adaptive Thresholding,” vol. 1, no. 2, pp. 91–98, 2011.
[16] G. Kheder, A. Kachouri, R. Taleb, B. M. M, and M. Samet, “Feature extraction by wavelet transforms to analyze the heart rate variability during two meditation technique,” pp. 374–378, 2007.
[17] M. Migliorini, S. Mariani, and A. M. Bianchi, “Decision tree for smart feature extraction from sleep HR in bipolar patients,” pp. 5033–5036, 2013.
[18] I. I. Conference, A. C. Control, C. Technologies, S. Devi, and M. Electronics, “Cardiac Arrhythmia Detection using Linear and Non - linear Features ofHRV Signal,” no. 978, pp. 795–799, 2014.
[19] V. R. Pamula, M. Verhelst, C. Van Hoof, and R. F. Yazicioglu, “A Novel Feature Extraction Algorithm for On the Sensor Node Processing of Compressive Sampled Photoplethysmography Signals,” pp. 3–6, 2015.

5975

International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com

[20] De Carvalho, J.L.A. et al., “Development of a MATLAB software for analysis of heart rate variability”, In Signal Processing, 6th international conference, 2002.

[21] Grassberger et al., “Characterization of Strange Attractors”, Physical Review Letters 50 (5): 346, 1983.

[22] Eckmann, J.-P. et al., “Liapunov exponents from time series. Physical Review”, A 34 (6): 4971, 1986.

[23] Rezek, I.A. and S.J. Roberts, “Stochastic complexity measures for physiological signal analysis” Biomedical Engineering. IEEE Transactions, 45 (9): 1186-1191, 1998.

[24] K. Tajane, “Non-Linear Feature Extraction for Heart Rate Variability : An Overview,” vol. 89, no. 10, pp. 17–19, 2014.

[26] H. Byun and S. W. Lee, “A survey of pattern recognition applications of support vector machines,” Int. J. Pattern Recognit. Artif. Intell., vol. 17, no. 3, pp. 459–486, 2003.

[27] I. El-Naqa, Y. Yang, M. Wernick, N. Galatsanos, and R. Nishikawa, “A support vector machine approach for detection of microcalciﬁcations,” IEEE Trans. Med. Imag., vol. 21, no. 12, pp. 1552–1563, Dec. 2002.

[28] K.I.Kim,K.Jung,S.H.Park,andH.J.Kim,“Supportvecto
rmachinesfor texture classiﬁcation,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 24, no. 11, pp. 1542– 1550, Nov. 2002.

[29] M. Pontil and A. Verri, “Support vector machines for

3D

object

recogni-

tion,”

IEEETrans.PatternAnal.Mach.Intell.,vol.20,no.6,pp.637

–646, Jun. 1998.

[30] S. Li, T. Y.Kwok, I. Wai-Hang, andY.Wang, “Fusing imageswith differ- ent focuses using support vector machines,” IEEE Trans. Neural Netw., vol. 15, no. 6, pp. 1555–1561, Nov. 2004.

[31] G. Pajares and J. M. de la Cruz, “On combining support vector machines and simulated annealing in stereovision matching,” IEEE Trans. Syst., Man, Cybern. B, Cybern., vol. 34, no. 4, pp. 1646–1657, Aug. 2004.

[32] R. Begg, M. Palaniswami, and B. Owen, “Support vector machines for automated gait classiﬁcation,” IEEE Trans. Biomed. Eng., vol. 52, no. 5, pp. 828–838, May 2005.

[33] I. G¨uler and E. D. ¨Ubeyli, “Multiclass support vector machines for EEG signals classiﬁcation,” IEEE Trans. Inf. Technol. Biomed., vol. 11, no. 2, pp. 117–126, Mar. 2007.

[34] T. N. Lal, M. Schroder, T. Hinterberger, J. Weston, M. Bogdan, N. Bir- baunner, and B. Scholkopf, “Support vector channel selection for BCI,” IEEE Trans. Biomed. Eng., vol. 51, no. 6, pp. 1003–1010, Jun. 2004.

[35] M. Kaper, P. Meinicke, U. Grossekathoefer, T. Lingner,

and

H.

Ritter,

“BCIcompetition2003-

DatasetIIb:SupportvectormachinesfortheP300 speller

paradigm,” IEEE Trans. Biomed. Eng., vol. 51, no. 6,

pp. 1073– 1076, Jun. 2004.

[36] L. Ramirez, N. Durdle, D. Hill, and J. Raso, “A support vector classiﬁer approach to predicting the risk of progression of adolescent idiopathic scoliosis,” IEEE Trans. Inf. Technol. Biomed., vol. 9, no. 2, pp. 276– 282, Jun. 2005.

[37] L. Ramirez, N. Durdle, J. Raso, and D. Hill, “A support vector machines classiﬁer to assess the severity of idiopathic scoliosis from surface topog- raphy,” IEEE Trans. Inf. Technol. Biomed., vol. 10, no. 1, pp. 84–91, Jan. 2006.

[38] H.Liang and Z.Lin, “Detection of delayed gastric emptying from electro-gastrograms with support vector machines,” IEEE Trans. Biomed. Eng., vol. 48, no. 5, pp. 601–604, May 2001.

[39] J. L. Rojo-Alvarez, J. Bermejo, V. M. Juarez-Caballero, R. Yotti, C. Cortina, M. A. Garcia-Fernandez, and J. C. Antoranz, “Support vector analysis of color-doppler images: A new approach for estimating indices of left ventricular function,” IEEE Trans. Med. Imag., vol. 25, no. 8, pp. 1037–1043, Aug. 2006.

[40] F. Yaghouby, A. Ayatollahi, and R. Soleimani, “Classification of Cardiac Abnormalities Using Reduced Features of Heart Rate Variability Signal,” vol. 6, no. 11, pp. 1547–1554, 2009

[41] J. P. Kelwade, “Prediction of Cardiac Arrhythmia using Artificial Neural Network,” vol. 115, no. 20, pp. 30–35, 2015.

[42] F. M. Ham and S. Han, “Classification of Cardiac Arrhythmias Using Fuzzy ARTMAP,” vol. 43, no. 4, 1996.

[43] M. K. Sarkaleh and A. Shahbahrami, “Classification of ECG arrhythmias Using Discrete Wavelet Transform and Neural,” Int. J. Comput. Sci. Eng. Appl., vol. 2, no. 1, pp. 1–13, 2012.

[44] V. Vapnik, Statistical Learning Theory. New York: Wiley, 1998

[45] E. Tejera, M. J. Areias, A. N. A. Rodrigues, A. N. A. Ramo, J. M. Nieto-villar, and I. Rebelo, “Artificial neural network for normal , hypertensive , and preeclamptic pregnancy classification using maternal heart rate variability indexes,” vol. 24, no. 164, pp. 1147–1151, 2011.

[46] P. Taylor, N. Kannathal, U. R. Acharya, C. Lim, P. K. Sadasivan, and S. S. Iyengar, “Intelligent Automation & Soft Computing Cardiac Health Diagnosis Using Heart Rate Variability Signals – A Comparative Study,” no. January 2015, pp. 37–41.

[47] U. Rajendra Acharya, P. Subbanna Bhat, S. S. Iyengar, A. Rao, and S. Dua, “Classification of heart rate data

5976

International Journal of Applied Engineering Research ISSN 0973-4562 Volume 13, Number 8 (2018) pp. 5968-5977 © Research India Publications. http://www.ripublication.com

using artificial neural network and fuzzy equivalence relation,” Pattern Recognit., vol. 36, no. 1, pp. 61–68, 2003.
[48] D. Sen, V. Singhal, and V. Kumar, “Solar DC Microgrid for Rural Electrification: A Case Study,” Int. Adv. Res. J. Sci. Eng. Technol., vol. 2, no. 1, pp. 1–5, 2015.
[49] T. Barrella and S. Mccandlish, “Identifying Arrhythmia from Electrocardiogram Data,” pp. 1–5, 2014.
[50] J. Yang et al., “Artificial Intelligence in Medicine Channel selection and classification of electroencephalogram signals : An artificial neural network and genetic algorithm-based approach,” Artif. Intell. Med., vol. 55, no. 2, pp. 117–126, 2012.
[51] I. Saini, D. Singh, and A. Khosla, “Classification of RR-Interval and Blood Pressure for Different Postures using KNN Algorithm,” vol. 5, no. 1, pp. 13–20, 2012.
[52] A. Jovic and N. Bogunovic, “Electrocardiogram analysis using a combination of statistical , geometric , and nonlinear heart rate variability features,” Artif. Intell. Med., vol. 51, no. 3, pp. 175–186, 2011.
]53] N. Twomey, A. Temko, S. Member, J. O. B. Hourihane, and W. P. Marnane, “Physiology During Oral Food

Allergen Challenge in Children,” vol. 18, no. 3, pp. 1051–1057, 2014.
[54] M. G. Poddar, V. Kumar, and Y. P. Sharma, “Automated diagnosis of coronary artery diseased patients by heart rate variability analysis using linear and non-linear methods,” J. Med. Eng. Technol., vol. 0, no. 0, pp. 1–11, 2015.
[55] B. Mohammadzadeh and S. Kamaledin, “Support vector machine-based arrhythmia classification using reduced features of heart rate variability signal,” 2008.
[56] I. I. Conference, A. C. Control, C. Technologies, S. Devi, and M. Electronics, “Cardiac Arrhythmia Detection using Linear and Non - linear Features ofHRV Signal,” no. 978, pp. 795–799, 2014.
[57] I. Saini, A. Khosla, and D. Singh, “Classification of RR-Interval and Blood Pressure Signals Using Support Vector Machine for different Postures,” vol. 4, no. 3, 2012.
[58] C. Cortes and V. Vapnik, “Support-Vector Networks,” vol. 297, pp. 273–297, 1995.

5977

