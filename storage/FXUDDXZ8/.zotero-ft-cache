THAOWANNA MARIA UNATAATAUPAMINUMAIMULT

US 20180249964A1

(19) United States

(12) Patent Application Publication (10) Pub.No.: US 2018/0249964A1

Qian et al.

(43) Pub. Date: Sep. 6, 2018

(54) DEEP LEARNING ALGORITHMS FOR
HEARTBEATS DETECTION

(71) Applicant: Logos Care, Inc.,Mountain View , CA
(US )

(72) Inventors: Kaizhi Qian , Champaign, IL (US); Yang Zhang, Urbana, IL (US); Thomas
Y. Lo, Fremont, CA (US)

(21) Appl. No.: 15/819,763

(22) Filed: Nov. 21, 2017

Related U .S.Application Data (60 ) Provisional application No.62/466,288, filed on Mar.
2 , 2017.

Publication Classification

(51) Int. CI. A61B 5/00 A61B 5/024 A61B 5/0404
A61B 5 /0245
A61B 5/04

(2006 .01)
(2006 .01) (2006 .01) (2006 .01) (2006 .01)

A61B 5/0255 (30 A61B 8/02
A61B 5/0255

(2006 .01) (2006 .01)

(52) U.S. CI.

CPC ........ A61B 5 /7267 (2013.01); A61B 2503/ 10

(2013.01); A61B 5/7207 (2013.01); A61B

5 /0404 (2013.01); A61B 5 /0245 (2013 .01);

A61B 5/04011 (2013.01); A61B 5/6823

(2013 .01); A61B 5 /6831 ( 2013.01); A61B

5 /02416 (2013.01); A61B 8/02 (2013 .01);

A61B 5/02444 (2013.01); A61B 5/0255

(2013 .01); A61B 5 /02405 (2013.01); A61B

5/7278 (2013 .01); A61B 5/02438 (2013.01)

(57)

ABSTRACT

A system that detects heartbeats includes a sensor or a transducer and algorithms based on deep learning. The
algorithms employ techniques of artificial intelligence that
enable the system to extract heartbeat features under low signal-to-noise-ratio (SNR ) conditions when a user is exer
cising. The algorithms can be applied to various technolo
gies for heart rate monitoring such as ultrasound Doppler,
photoplethysmogram (PPG ), electrocardiogram (EKG ), acoustic , pressure/force sensing and laser/RF Doppler, among other types of sensing methods.

Target (subject)
1050

L - - --
-

-- - -

- - - - - - - - - --

Heart Rate System

1100

Optical Module A

LED + Photodetector

-

1055

-

-
OpticalModule B

-

LED + Photodetector

-

1065

Amplifier A 1060
Amplifier B
1070

AID Converter
1025

-

-
-
-

om det inte UserInterface 1035

Display Unit
1040

twoMicrocontroller 1030
Flash Memory 1045

-

-

-

-

-

--

Patent Application Publication Sep. 6, 2018 Shet 1 of 12
100
Data Collection
110

US 2018/0249964 A1

Sensor signal &
reference signal

Label & Feature
Extraction
120

Label signals & feature

Heartbeat
Detection
130
Score signals

Heart rate
Computation
140
Heart rate

FIG. 1

Patent Application Publication Sep. 6, 2018 Sheet 2 of 12 US 2018/0249964 A1

*1-*11*1*
Features 1 2 3 4 5 6 7 8 9 **
Frames

Token 1

w 123 I

Token 2

234 ... Lyk5+1

X .

:

Last Token

N - TH • N

FIG . 2 .

Patent Application Publication Sep. 6, 2018 Sheet 3 of 12 US 2018/0249964 A1

..

O

****..

1
** ... 1

1

01 01*

1

p.REiudsigneg

IN 1

1
3rd Stage

1

.**
1

. . .

, 4

LS

1

*** ******
***

2nd Stage

1

h

1

wi...

Stagepost
1. 0* 1* 200

I

1 www

. in

1

1

1

1 1
1
REidsgineg 1 1 1

F. 3IG

***
***** * ww w

XL

1 1
1
1 1
, . 1

1Sta8ge 3Stragde

Seingsoarl

RESidsgnaegl RL2SatanbegwdSfglirgoaonartlef

Patent Application Publication Sep. 6, 2018 Sheet 4 of 12 US 2018/0249964 A1

33367777777777777****** ********** ** *** *********** ***.777777777****** *********** ***.777777777****** ***********s**s*s*ss*s**s**** **
* * * **** ******** * *** * *** **** **** * *** * *

Time .

' LSf1iatgobnegarl(ad)owfnstampelirng the to

0

* .

*

. . . :: : .

.. . . . .. :::::: : . . :::: : : :: :::: ::: :: :::::

wwwwww
1·11

w 1.0 01 1.0000000

. *
?

.LI

1.0101000 1 / RF

. *

;

w Ww 0.,011
1 0.101011 1

2-pF(of)or5Fnianm6Tet
. . .

0.00110

*

.
. 2
2

II

. . .. . . . .. .... .. ..

FramedRLabewlSfiognralS1tage

RLabewlSfigonarlS1tage

F. 4IG

Patent Application Publication Sep. 6, 2018 Sheet 5 of 12 US 2018/0249964 A1

Ele

PP

EL

Oat+{uttput BLuaSnsTiMtc ?, BLuaSnsTiMtc BLuaSnsTiMtc iFa+1enalptutre

Oautput BLuaSnsTiMtc - - BLuaSnsTiMtc BLuaSnsTiMtc IFaentputre F. 5IG

Oa-1uttputt BLuaSnsTiMtc an

iFa-1enatputre
BLuaSnsTiMtc BLuaSnsTiMtc

LL.ayer

L2ayer Layer1

Patent Application Publication Sep. 6, 2018 Sheet 6 of 12 US 2018/0249964 A1

ScenarioDetcor Heartb dfetoctrosKcenario

Control X . 1

weightedcombinat Heartb Ss(s)icgonrael Sowirtch

dfetoctro s2cenario IFenapturte

F. 6IG

www

Heartb dfetoctros1cenario

Patent Application Publication Sep. 6, 2018 Sheet 7 of 12 US 2018/0249964 A1
Hreatre
Hreatretsmothing

-Pheradtibceatds

F. 7IG

Thresolding

Ssoaicgonfraelhseatrbgeat

Patent Application Publication Sep. 6, 2018 Sheet 8 of 12 US 2018/0249964 A1

788
787 w w
wt,yohetwarylem w. W* **
w?
Sseingsoarl ww78123456Ssfa&thictreognashrgoaled
ww 780
w w 779 w w
778 indo

788

788 irogoro

*
787

786
wivomrpsw
785 78234567
w78234Pheradtibces Theartbueas

781

781 *** ***** * *

780

780 ????

779

w

********************** ***
779

778

778 ** **** * *** ** ** *** ** ******

788
787
786
** * * ** ** * *
785
7834Seconds F.8IAG
782
781
780
779
778

PatentApplication Publication _ Sep. 6,2018 Sheet 9 Of 12 _ US 2018/024996441

.…. . .…. . . . .. .. ? ?? ? ?? . . .
-

?'.'. -" * * * * * * * ; ; ;

;, ;??? ?
-
-

-

-

-
????

? ?? ?

-

????? ?

?? ?

-

;-? -;. ;----

??: :

;

?? ? ? ?? ? ???? ? ???? ? ? ? ? ? ??? ?

? '- * * *

??? )

?. ?or-

", .-, - .-.-.-. ??.

??

.

?

? .

??

?. ? ??? .1..1;

; **

)

?

? ??????? ? ? ? ?? - - - - - -

* * *.- '

? ? ? ? ????? ? ??? ...? . ? ':

??? ???? ? ? ? ? ?

.??

?....?........

.:? ? ... . ?.

?? ;-

.

?

?.

.?.…?.?.… …

? ?

? ??

? ?

?? ? ?? ?? ?

? ?

? ?

?? ? ? ? ?? ? ?? ???

? | ????? ?? ??

?

?

?.'.".'."

?.??? ? .'":

-

????

- - - - - - " " " " -.* * * *:? ???. ? ?? ???? ?? ?? ??????
? ? ? ??? ? ?… - :; - ; - -. - - .. .. . . , -.; . ?. ;-,' 1 - ; . ; ;' .-. . . . 1,'.'.".'.-
?? ?? ? ? ? ? ???,",.-. . .:? ?? ? ?
? . . " " ' - - - ". ', ".'-* ?
?? ????? ?????? "'." ..
- -.-:-.- - -.-. .'.' *.".'.". -?? . ?
? ? ? ? ? ? . . ?. ?. ? ? ? ? ? ? ? ? ?? ? ??? ????. . .' ?????? * * * - -. -;
" '.".';- - - - ---.- - - - - " * *.".'." ?
-.-. . ... ... . ..…... … . . . . . ..-,). ;- ? ? ? ? ? ' . ??.?.?.... ....... ?? ? ? ?
????? . .. . ---- - ? ? ? ?"-* * * * * * * * * * - ??? ?????????????
? ?????? ??
?? ? ? ?? ? ? ? ? ??? ?? ? ? ? ?
- - - ". .'.".'. . ? . . - - .-. . . . .' ;

? ? ? ? ? ?? ?" " "," ' " -.* * * * * * * * * *. ? . . . ... ... . . ... . ." " ' - *.- *.- * * ???
? ?? ? ? ?. ." ..- -. - ? ?? ? ??. . ; .-. . . °. …..... . -.-. ;
? ? ? ? ?? ?? ?? ? ?? ? ??? ??? ?? ??? ? ? ?????? ?? ?? ? -..- -.-. .' ".'. ".'. . ;

? . . . . . . . . . .. . . .….'.".* ? ? ? * * * * * * * * * * *. - ? ? ???|? ? ? ?

. .". ??????????? ? ? ? ?. " * * * * ' f ? ? ? ? ? ? ? ? ? ? ? ? ???? . ?

? ??? ????-...??????????????.? ? ? ? ?? ???? .- ????????....

?

? ? ?? ? ? ? ? ? ? ??? ?? ?? ?.,-.;" ?"?????

? ????? -.-;-.-;'. ;",-: : ? . ' -. .1;
. . . .-.-.;-. x."? ? ? ?? ?? ?

?

? ? ? ?? ?? ? "."-*-: ". ".".????????????????. . "

"

??

? ?? ??? ?? ?.. ... .. . . ... .. ?.?.? ?..???

?* - : ?.-.-.-.-.-.-. ," " ' " " ' -

-- ?

??????? . : ??. . .-. .….'.'. . . . . . . . .. .-. ... .-.*. ".

-
-
?????;-.
-
? ??;-.-- - ---
-
?? ? ? ? ? ? ? ????
* - * *
Signal? ?
*

. : ? : ??????????????* * * * * * *-

?????? . ? ??????

? ?? ??? ? . ?. .... ...".*.*.* *.* * *?*

? ?. ???????

""" -:; ? . ?

?

Pheradtibceds ?

?? ?

??????

???????

?

?? ?

58Sscigonrael? ? ? 68

?..? ?
. ? ? ??? ?? ? ???

*

*

?*

*

*

?

'.'

' *.".'.";

? ? ?.??????? ???? ?? ?????????..?.-?.*?."?.?' ? ?

.

? ? ??? ? ? ?'.'* ."'.".'.".'.".'.".'.".? ??????•••••... .. . ... . . . ; ???????? ? ? ?? ?? ? ?? ? ??? ??? *,',',- ', ? ? ?? ?-:-.---.-. ..- ? .'.".'.". ;??

? ? ? ? ". .'.".'- : : '. -.- - ? « ? ? '. !
? ? ? ? ??? ? ? ? ??? ? ?? ? ?

? ? ? ? ? ????? ?? ??? ??????'. -.-:- ? ? ? ? ? ?
? ??? ? ?? ?????? ?? ? ? ?? ??? ?- ? ?

? ???? ? .????????
..…..…...... ... ... . .??

? .?? ?? ........ ...
? ? ? ? ? ?.1 .1.n.' : ' * " . .- '-".;

?? ? ? ? ? ?? ? ? ,. ..-. .. ? ?

?? ? ?? ? 1: ?? ?? ? ? ? ? ? ??????? ?.-

".. .. ?. ?????? . . . - . ?

? ????????? ?. ??????? ? ??

. .... ..

? ? ? ? ? ? ? ? ? ?. ??? ? ? ? ?? ? ? ? ? ?? ? ? .

58° ? ?? ?? ?? ? ?? ??? * * * ,' ,', '9 ',' ,- ' ":

Theartubeas ?

? ???? ???

?

???? ????????????

? ?? ?? ??? ? ??????

? ? ? ?. . .-. . ? ? ? ? ??????? ????? ? - - -
?
? ? ?? ???????( : : : - ? ? ? ?
? .? ? " -. .:?. .. ?. .. . . . . .-. ? ? ? ??...-.f.-.-.-.-."". '.".'." ? ?
?? .';- - - :- -:-.- - -:-.- -. - xxx -
? ??.. .. ;

* *. ". '.' - ' ."
? ? ? ? ? ? ? ? ? ? ? * * * -. *????
? ? ? ? ? ? ? ? ???????

??????????????? ?????? ?? ? ?? ? ?
? ? ? ?? * * * * * * *.".'." .'.".'.".'; ?

SecondsF.8IBG

? / / \ /

; ... ? ??? ? ? ???

?

?? ??

? ? ? ? ????? ??????????? "....

»

? ?? ? ????? ? ".'; :'"???? ? ? ?

?? .…?. .…?.?.…?.?.?.?. .?.??.?.???? . . .

?????????????? ? ? ? ??????????
[ 56
* * ??????? ?? ?????????????????? ????.

?? ? ? ? ? :: :-, .-, .-, :??
?. ?. ?. ??. ??? ??????????????????

?

? ?. ? ? ? ? ? ? . ?

??? .?? .? ? ? ? ?
???????????????????
* * - - -; -.-.-.- ?????????????
?? ? ??????????? , * * * *
??????? ?...........

?????????????? ? ?
se ".' "- " ***?????? ????.?????.
- -.-...-... .???????
* * * * * * * * - '.' *. ".' ." : ?
?? ??? ? ???.??? ?????
.-.-.-:-.- -. .?? ?? ? ? ? ?? ?? ? ? ? ? ? ? ? ? ???
????? .. . ......... ?
??????. .??..?. ? ? ?
???????????????????? ?.
?????????? - , ? . . . ."
? ? ? ? ? ? ??;-, .-,?.: ?
??? ? . ....... .. ... ?
" " " " -.* * * * * *
- * * * * * * * *; . - ;'. - "

*

? ?? ?|??? ? ? ?? ?? ? ??????????

???????????r - - - -
? ??? ?? ? ? ? ?? .. . . .-. .... . ?

???? * * * .- - - - - - - - - . .". '." ! * * - '.' *. ".'.". '." .' ." .'. ".' ." ? ?

? ? ? ? ??? ?. ; -.r.-.* ? ? ?? ? ??? ?? ? ????????????? ?

? ???? ???? ??? ? " ' " ? ?????????.. ?. ?. -

???????????????* * ? ? ? ? ? :":" ?? ??? ? ? ? ? ?? ?? ? ? .-.- -- - .-,, ????

?? ?

. ? . . .-.- -. ? ?? ?? ?? ??? . . . ??

? ? ??? ? ??? ??..??????????????? - . -
* * - ' - -.','. .';'.-.' « ?

? ? ?????????????????????????? - *
?? ????? ? ??????????

*

? ??????.- " *: ? . .-- ? ?

? ?.??. -

???????????????
? :-. ; . ? ? ? ? ? ?

.???

?

??? ? ??

? , - 111
? ?. ; . . ." ??? ? ? . .????

.".'.".'.".' " ' " ? ? ? ? ? ? ? ? ??????? ???

x1084 ? ? ?

? * ""'-',', ? ????...

N7 oC

?8?

?????????????? * *
?????? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
?? ? 0 . 5

????? ?? ??
?? 8 esse0 . 2

Patent Application Publication Sep. 6, 2018 Sheet 10 of 12 US 2018/0249964 A1

Inimild Heartbeatstage 1: 1

29 9 9

0 2 4 6 8 10 12 14

Heartbeatstage 2: 1

Score signalof:

0.5 0 1991

Perele

0 2 4 6 8 10 12 14

Heartbeat stage 3 : 1
0.5
Leheheel O o
0 2 4 6 8 10 12 14
Frame

Dynamic programming

Optimal stage chain :
1112223333111
A complete traverse
from stage 1 through 3
Predicted one heartbeat cycle

Traverse duration measure

Heart rate
FIG . 9

Patent Application Publication Sep. 6, 2018 Sheet11 of 12 US 2018/0249964 A1

? min are in more we was are in moreto more in the moreto mentcont color more intcolore are on me

? ?ADConvert1025 Buterwoh Amplifer 1020
HRSyeastrem100 MixerCircuit1015
Amplifer 1010
Ultrasound Transducer 105

Microntle1030 FMelmaosrhy1045
DUinspilaty 1040
UIntserfarce 1035

F. 1I0G

Target (S)ubject1050

Patent Application Publication Sep. 6, 2018 Sheet 12 of 12 US 2018/0249964 A1

D / A 1025
ConvertAAmplifer1060 ABmplifier1070
HRSyeastretm10
w MAOoptdiuclaeL+PhotEdeDctor1055 OMBpotdiuclaeL+PhotEdeDctor1065

Microntle1030

w

w

FMlemaosrhy 1045

w w

w

w w

w w w

w

w

DUinspilaty1040

w w

w

w

w

w

w w

F. 1I1G

UIntserfarce 1035

w w
w

w

w

w

w

ww

www w w w w

ww ww

w w w w w w wwwwwwwwwwwwwwwww

Target(s)ubject1050

US 2018 /0249964 A1

Sep. 6, 2018

DEEP LEARNING ALGORITHMS FOR
HEARTBEATS DETECTION
CROSS REFERENCE TO RELATED
APPLICATION
[0001] This application claimsthe benefit ofpriority under 35 USC § 119(e) to U .S . Provisional Application No. 62/466 ,288, filed on Mar. 2, 2017, which is incorporated herein in its entirety for all purposes.
BACKGROUND
1. Field of Art
[0002] This disclosure generally relates to a sensor system for detecting heartbeats and to signal processing to identify heartbeats from noisy sensor data .
2 . Description of the Related Art
[0003] Heart rate tracking has become a function in many
of today 's mobile health monitoring devices. However, existing technologies are unable to accurately measure heart rate when subjects are jogging or running. The muscle
artifacts compromise the signal-to -noise-ratio (SNR) that makes heartbeat detection difficult. Swimming, rowing, and
weightlifting present even tougher challenges, for example, also due to low corresponding SNR . [0004 ] An existing system for monitoring heart rate is
based on electrocardiograms (EKG or ECG ). The user is
required to wear a chest strap and a wristwatch to display heart rate in real time. The electrodes on the chest strap pick up QRS waves (i.e.,particular graphical features thatmay be
shown on the EKG ) as heartbeats. Heart rate can be com
puted based on theheartbeats. However,this system requires at least two separate hardware devices (chest strap and wrist watch ), and wearing a chest strap is not particularly user
friendly. Additionally, motion in the upper body may cause the electrodes to miss heartbeats frequently .
[0005] Other devices and methods to monitor heart rate
without chest straps may use optical means to detect blood
flow from the user's wrist. Photoplethysmography (PPG ) is a general term of this approach that is usually applied to
fingertips, earlobes, or wrist. PPG uses one ormore light emitting diodes (LED ) with different wavelengths and one
ormore photodetectors. The LEDs shine light to the capil lary arteries or arterioles underneath the skin. The reflected light sensed by the photodetectors changes in intensity , due to absorption of lightby the red blood cells, at the samerate
of the pulsating blood flow that is equivalent to heart rate .
This approach may be simpler and easier to use than a chest
strap. However, variations in skin pigmentation , ambient
light, and outdoorclimate conditions can limitthe sensitivity
and the dynamic range of the device because these variations
may result in a low signal-to -noise-ratio (SNR ). Further, digital signal processing (DSP) employed in such devices thus may require additional signals from motion sensors such as a multi-axis accelerometer to identify the rhythmic muscle motion in exercise.
SUMMARY
[0006 ] In an embodiment, a method for determining a heart rate of a subject includes obtaining temporal sensor
data generated by a sensor worn by the subject (also referred
to herein as a user), where the temporal sensor data repre

sented by frames of data samples. The method further
includes generating, for each of the frames, a feature vector
based on a frequency domain representation of the corre sponding data samples of the frame. The method further
includes inputting the feature vectors to a model to generate
a series of heartbeat determinations of the subject for each of the frames. The model includes a first set of parameters
and associated weights that represent likelihoods of heart beats of the subject as a function of time. Themethod further
includes providing the heart rate of the subject determined
based on the series ofheartbeat determinations. [0007] In some embodiments,the method further includes inputting the feature vectors to a scenario classifier to
determine one ofmultiple scenarios for the temporal sensor
data . The scenario classifier includes a second set of param
eters and associated weights that represent likelihoods ofthe
temporal sensor data corresponding to each of scenarios. The method further includes identifying the model from a set of trained models based on the determined scenario . In
some embodiments, the method further includes identifying
from the series of heartbeat determinations, one or more
transitions between the stages of the plurality of heartbeat stages. Additionally, the method includes determining the
hheeanrnt rate ofthe subject based at least in part on a duration
in time of the one or more transitions. 0008] In another embodiment, a non-transitory computer readable storage medium stores instructions that when executed by a processor causes the processor to execute the above-described method.
[0009] In yet another embodiment, a computer system
includes a sensor, processor, and a non -transitory computer
readable storage medium that stores instructions for execut ing the above-described method . The sensor may be con
figured to be worn by a subject and generated temporal
sensor data represented by frames of data samples.
BRIEF DESCRIPTION OF DRAWINGS
10010 ]. FIG . 1 is a flowchart of a method for determining
heart rate according to one embodiment.
[0011] FIG . 2 is a diagram of features for determining
heart rate according to one embodiment.
[0012] FIG . 3 is a diagram illustrating label extraction from a sensor signal according to one embodiment.
[0013] FIG . 4 is another diagram illustrating label extrac
tion from a sensor signal according to one embodiment.
[0014 ] FIG .5 is a diagram ofa classifier according to one
embodiment. [0015 ) FIG . 6 is a diagram of a process for heartbeat
detection using switching according to one embodiment.
[0016 ] FIG . 7 is a diagram of a process for determining
heart rate using a score signalaccording to one embodiment. [0017] FIG . 8A illustrates signals for heart rate computa
tions using ultrasound sensor data according to one embodi
ment, and FIG . 8B illustrates signals for heart rate compu
tations using optical sensor data according to one embodiment.
[0018 ] FIG . 9 is a data flow diagram for heart rate com putation using score signals ofmultiple stages according to
one embodiment.
[0019] FIG . 10 is a block diagram ofa heart rate system using ultrasound sensors according to one embodiment.
0020 ] FIG . 11 is a block diagram of a heart rate system
including optical sensors according to one embodiment.

US 2018 /0249964 A1

Sep.6, 2018

[0021] The figures depict embodiments of the present
invention for purposes of illustration only . One skilled in the
art will readily recognize from the following discussion that alternative embodiments of the structures and methods illus
trated herein may be employed without departing from the
principles of the invention described herein .
DETAILED DESCRIPTION
[0022] The following description discloses systems and
methods for using deep learning to extract vital sign signals from sensor data having low SNR or low signal energy to
begin with . These techniques can be used for blood flow /
heart ratemonitoring using, ultrasound Doppler technology, PPG , among other types of sensors technologies. These
techniques may outperform conventional EKG and PPG
devices for heart rate determination in accuracy and user experience especially under heavy thumping conditions
(e.g.,noisy sensordata ). In some embodiments, a wristband detects blood flow signals by either ultrasound or PPG to compute heart rate , without requiring a separate chest strap .
[0023] The techniques described herein can detect heart
beats and calculate heart rate accurately in low SNR situa
tions. Other applications of continuousheart ratemonitoring include Atrial Fibrillation (AF) detection and Heart Rate Variability (HRV ) monitoring. Deep learning techniques may be employed for accuracy and reliability regardless of
using EKG , PPG , or ultrasound. [0024] FIG . 1 is a flowchart of a method 100 for deter mining heart rate according to one embodiment. In one
embodiment, a heart rate system (also referred to herein as a " system ” ) performs stepsofthemethod 100, for example, including algorithms or steps for data collection, label and
feature extraction , heartbeat detection , and heart rate com
putation. In the data collection step 110, theheart rate system
collects a sensor signal and reference signalusing ultrasonic
sensors, acoustic sensors, optical/PPG sensors, electrodes/
EKG or pressure /force sensors and transducers , or other
suitable types of sensors. Additionally, the heart rate system may collect a reference signal from a known reliable source,
e.g., an EKG chest strap heart rate monitor, to guide the training of a classifier (also referred to herein as a model). In the label and feature extraction step 120, the heart rate system preprocesses the sensor signal and the reference
signal to output a spectrogram feature and label signals. In
theheartbeatdetection step 130, theheart rate system detects the timestamps of heartbeats from the sensor signal. In the heart rate computation step 140, the heart rate system calculatesheart rate based on the timestamps. The heart rate detection algorithms disclosed herein may be applied to any
of the above-mentioned sensing technologies.
0025 ] Themethod 100 may include differentor additional steps than those described in conjunction with FIG . 1 in some embodiments or perform steps in different orders than
the order described in conjunction with FIG . 1 . Steps of the method 100 are further described below , with reference to the other figures as well.
I. DATA COLLECTION
[0026 ] In the data collection step 110, theheartrate system may acquire sensor signals (or sensor data ) from an ultrasound transducer coupled to an amplifier and a mixer circuit
(e.g., as shown in FIG . 10 ), in one embodiment. The
ultrasound generator can output signals at frequencies

between 1 to 10 megahertz (MHz). The output Doppler
signal in audio range is sampled at 100 Hz to 10 KHz. In one
use case, the output signals are at 5 MHz and the sampling rate is 4000 Hz. In another embodiment, the sensor data is
acquired by an opticalmodule ( e.g ., as shown in FIG . 11 )
including a light-emitting diode and a photo sensor followed by an amplifier. The output signalmay be sampled at 100 Hz to 1 KHz. In one use case, the sampling rate is 500 Hz. The
heart rate system may collect data for various scenarios, for
example, no exercise (standing still), moderate exercise (slow and fast walking) and hard exercise (jogging and running), which may represent data with high SNR , mod erate SNR , and low SNR , respectively .
[0027] In some embodiments, to build an artificial intel
ligence (AI) classifier that detects heartbeat features with precision , the heart rate system trains a classifier with a
known reliable reference signal to identify the onsetof each heartbeat in addition to the heartbeat signals itself. This
reference signal is used in the training of the classifier. The
reference signal may be provided by a chest strap including
electrodes that detect the QRS wave of the subject's EKG . The chest strap may generate a narrow pulse signal for each heartbeat. The rising edge of the pulse can be used to mark the onset of a heartbeat.
II. LABEL AND FEATURE EXTRACTION
10028 ] In the label and feature extraction step 120 , the
heart rate system may determine features using collected or processed sensor signals and/or other inputs to theheart rate
system , e.g., a classifier. In an embodiment, the heart rate
system derives label signals from the reference signals, and
uses the label signals to guide the training of the classifier.
II. A . Feature Extraction
[0029] The heart rate system processes and obtains fea tures from the sensor signal. In one embodiment, the sensor
signal is framed with frame length LF ( samples per frame)
and frame rate Re (frames per second ). Le may be any
positive integer less than Fs, where Fs is the sampling rate
ofthe sensor signal.An example value ofLemay be 256 .Rp
may be any positive number greater than F / LF . An example value ofRemay be 10 . In some embodiments, the heart rate
system transforms each frame into a frequency representa
tion using short-time Fourier transform (STFT), or other
signal processing techniques. The frequency representation for each frame is a vector of length Lr. The heart rate system
may truncate the frequency representation vectors, and
retain a portion of the vectors with dimension 1 to dimension
Lp/2 + 1. The heart rate system may remove or not process
data in the other dimensions of the vector, e.g., including
redundant information . The vector with retained dimensions
is referred to as the feature vector for that frame. [0030] FIG . 2 is a diagram of features for determining
heart rate according to one embodiment. In an embodiment, the heart rate system facilitates training by grouping feature
vectors for frames into training tokens on a sliding window
basis. As an example , a training token is a sequence of
feature vectors of Ly consecutive frames. Ly may be any
positive integer, and an example value may be 150 . The frame range ofthe proceeding training token shifts from that
ofthe currenttoken by a predetermined value, e.g., one.FIG .
2 illustrates how feature vectors may be grouped into

US 2018 /0249964 A1

Sep . 6 , 2018

training tokens, which may help prevent the vanishing gradient problem or exploding gradient problem when train ing classifiers.
II. B . Label Extraction
[0031] FIG . 3 is a diagram illustrating label extraction
from a sensor signal according to one embodiment. The
heart rate system may derive the label signals using a reference signal. In one embodiment, a system performs a
label extraction process in steps as described below .
[0032] A reference signal includes, e.g., samples of O's
and l' s over time, where a 0 and 1 indicate no presence or presence of a heartbeat at a given timestamp, respectively .
The heart rate system constructs the rising edge signal, which equals 1 at samples where the reference signal transitions from 0 to 1 (e.g., indicted by the dotted lines in FIG . 3), and equals 0 otherwise. These rising edgesmark the determined onsetoftheheartbeats. FIG . 3 showsan example
rising edge signal, as well as the amplitude (e.g., in milli
volts) for an example sensor signal over time.
[0033] In some embodiments, the heart rate system divides each individual heartbeat cycle into N stages. N may
be any positive integer, and an example value of N may be 3. Each stage is of length Ls (in number of samples), and an
example value of Ls may be 250 . The first stage starts at the
rising edge and marks the start of a heartbeat cycle . Subse quentstages represent the later stages of the heartbeat cycle.
An example is shown FIG . 3 with N = 3 , but N can be any
positive integer. The heart rate system constructs raw label
signals (also referred to as assigning labels to the training data). For each ofthe N stages, there is a corresponding raw
label signal. Thus, there are a total of N raw label signals. Each raw labelsignalmay include consecutive l’s within the
corresponding stage and O 's otherwise. FIG . 3 shows
examples of raw label signals for three stages.
[0034] FIG . 4 is another diagram illustrating label extrac tion from a sensor signal according to one embodiment. In some embodiments, the heart rate system downsamples the
raw label signals to the frame rate to match the temporal
resolution of the features. The resulting downsampled sig nals are referred to herein as label signals. An example downsampling process is as follows. Each raw label signal is framed with thematching framelength and the framerate
ofthe feature, i.e., Lp and Rp, respectively. For each frame,
the label signal equals 1 if more than half of the raw label signal within that frame is 1, and 0 otherwise. FIG . 4
illustrates an example downsampling process. The horizon
tally -oriented “raw label signal for stage 1” shown at the bottom of FIG . 4 showsone particular raw label signal. The vertically -oriented “ label signal for stage 1” is the resultant
label signal. The rectangular frames illustrate how the raw
label signal is framed .
III. HEARTBEAT DETECTION
[0035] In the heartbeat detection step 130, the heart rate
system takes the features extracted as input and outputs one or N score signals , which each correspond to a particular
heartbeat stage detected, in one embodiment. There are N heartbeat stages per heartbeat cycle, and hence the number of score signals. In an embodiment, each score signal is a series of real numbers between 0 and 1 , indicating the
probability that each frame belongs to the corresponding
heartbeat stage. The nth score signaldetects the nth stage of

the heartbeat, and thus the heart rate system uses the nth label signal to guide the training. This is an example
multi-class classification problem where the number of
classes is N . [0036 ] Long-Short Term Memory (LSTM ) and Recurrent Neural Networks (RNN )may be used as classifiers because they can capture and utilize useful temporal structures to
achieve frame classification and temporal smoothing at the
same time, in some embodiments. A LSTM and RNN are
example types of classifiers known to one skilled in the art,
which are used to determine which class a sample belongs
to by taking a feature vector of the sample as input. Other example types of techniques that may be used include attention mechanisms, pooling, and batch normalization in
neural networks. A label signal is the ground truth , which is
useful for training.
100371. FIG . 5 is a diagram of a classifier according to one
embodiment.In the embodiment shown in FIG .5 ,the LSTM
classifier includes a stack of LSTM layers, where the input is fed into the first layer, and the output is the output of the last layer. Each layeris a concatenation LSTM units through time. Each unit takes charge of a single time stamp. Each
LSTM unit accepts the information from the pastLSTM unit
as well as the current input, determines what information to
remember from the past and current inputs, and passes the
information to its future LSTM unit. A LSTM unit may be
parameterized by number of hidden nodes and type of nonlinearity . The LSTM classifier is trained before use . A purpose of training is to find the parameters of the various nodes/edges within and between each LSTM unit using the reference labels and corresponding data by minimizing the
loss function , where the loss function measures the distance
between the output of the classifier and the reference labels . The parametersmay include (or are associated with ) weights
or biases for the various nodes/ edges.
[0038 ]. In one embodiment, the heart rate system uses a
LSTM or RNN configuration that takes the features
described above as input, and outputs an N -dimensional vector (e.g., each output dimension corresponds to a score
signal aforementioned ) with softmax as output activation
function . Softmax is an example function used for neural
network modeling discrete distributions. The number of hidden layers and hidden nodes within each layer can be any positive integers. An example value for the number of
hidden layers may be 2 ; an example value for the number hidden nodes in each basic LSTM unit may be 64. An example hidden node activation function applied may be
hyperbolic tangent. The output is an N -dimensional vector at
each frame, whose dimension n is the nth score signal aforementioned . An example error criterion may be cross entropy.
[0039] In other embodiments, the heart rate system may use other types classifiers including, e.g., Vanilla RNN , GRU (Gated Recurrent Unit) RNN , Skip RNN , Dilat edRNN , CNN (Convolutional Neural Network ), Dialted
CNN , Residual Net, as well as their variants by adding or
deleting weights and modules. The possible modules that
can be added or removed from the aforementioned classi fiers include, e.g., dropout, pooling, input normalization,
batch normalization, and weight regularization.
[0040] Theheart rate system may record sensorsignals for a number of different scenarios, for example, silence (mini
mal or no motion ), walking, jogging/running etc. Each of
these scenarios may correspond to different signal charac

US 2018 /0249964 A1

Sep . 6 , 2018

teristics. To account for these different scenarios, the heart rate system may use a combining or a switching method as described below . The number of scenarios is denoted as K , which may be any positive integer.An example value for K
may be 3 . [0041] In one embodiment for a combining method, the heart rate system combines and shuffles training features and labels from all different K scenarios. The heart rate system
trains a single RNN or LSTM using the combined data . [0042] FIG . 6 is a diagram of a process for heartbeat
detection using switching according to one embodiment. In
another embodiment for a switching method, for each of the
K scenarios, the heart rate system trains a differentdetection
RNN or LSTM . Thus, there are a total of K detection RNNS or LSTMs. Training data for each scenario may also be manually labeled. Each scenario detection neural network may be of the same architecture as described above.
[0043] In some embodiments,theheart rate system selects
which detection RNN or LSTM to use based on a scenario classifier. The scenario classifier may be of a similar archi
tecture to each of the detection RNN or LSTM , and take the same input features. However, the output of the scenario classifiermay have a dimension K for each frame, instead of
N . The kth output represents the probability that the frame
is recorded under the kth scenario,where k may be a value
from 1 to K . The heart rate system may output a weighted combination of the outputs of the K detection neural net
works (e.g ., by generating a weighted score ); the weights
may be based on the K -dimensional output of the scenario
classifier.
IV . HEART RATE COMPUTATION
[0044] In the heart rate computation step 140, the heart
rate system takes in the N score signals as input to generate
real-time heart rate estimations, in one embodiment. The
heart rate system may use any one of a variety of different
methods, for example, using one score signal or using N . score signals, which are further described below .
IV. A . Single Score Signal
[0045] FIG . 7 is a diagram of a process for determining
heart rate using a score signalaccording to one embodiment.
In an embodiment, the heart rate system selects one score signal. An example choice may be the 1st score signal,
though any other score signal may also be selected . The heart rate system may apply a threshold to the selected score
signal. The threshold may be pre -determined or adjustable
based on other information . The heart rate system deter
mines a heartbeat responsive to determining that the score
signal exceeds the threshold . The heart rate system deter
mines a heartbeat period by determining an interval (e.g.,of
time)between two adjacentheartbeats. The heart rate system
may apply a smoothing algorithm to mitigate sudden changes in heartbeat period , e.g., due to missed detection of
heartbeats . The heart rate system may also apply an adaptive threshold algorithm to prevent or account for missed heart beats . 100461. FIG . 8A illustrates signals for heart rate computa
tions using ultrasound sensor data according to one embodi
ment. FIG . 8B illustrates signals for heart rate computations using optical sensor data according to one embodiment. The
example results shown in FIGS. 8A -B may be determined by
the heart rate system using the process shown in FIG . 7.

Additionally , the ultrasound sensor data may be obtained using the heart rate system 1000 shown in FIG . 10 , which is further described below . The optical sensor data may be
obtained using the heart rate system 1100 shown in FIG . 11 ,
which is also further described below. The y-axis may
represent the amplitude (e.g., in millivolts) of the corre
sponding signals. The sensor signal shown is a section of
real-time heartbeat data sampled from the output of an
ultrasound amplifier with the subject performing a running
exercise . The score signal represents the output of the
classifier. When thumping occurs in running exercise, the heart rate system still detects the heartbeats butoccasionally
with a lower score. The heart rate system uses a constant
threshold (e.g ., indicated by the horizontal line at 0.5 ) to demonstrate an example approach to identify heartbeats . The heart rate system may generate a heart rate determina tion based on the identified heartbeats, which may be
consistent with the true heartbeat data .
IV . B . Multiple Score Signals
[0047] FIG . 9 is a data flow diagram forheart rate com
putation using score signals ofmultiple stages according to
one embodiment. In some embodiments , the heart rate system determines an optimized stage chain using the score signals. In an example, a stage chain is defined as a predic
tion of which of the N heartbeat stages each frame is in . A heartbeat cycle is completed when the stage chain finishes a
one-time sequential traversal from stage 1 to stage N .
Therefore , heart rate can be computed by measuring each
traverse duration . In the example plots shown in FIG . 9 , the heart rate system detects a repeating sequence of heartbeat
stage 1, heartbeat stage 2, and heartbeat stage 3 , as indicated
by the dotted rectangles .
[0048]. The heart rate system may determine the optimized stage chain using standard dynamic programming algo rithms using state chains (e.g., where each state corresponds to a stage of the heartbeat stage chain ). For example, the
heart rate system uses a dynamic programming algorithm to
determine the optimized stage chain (e.g., one stage for each
timestamp) that minimizes a target function . The target function may include two parts. Onepart is state cost, which measures the appropriateness of each stage for each specific timestamp. The otherpart is transition cost,which penalizes
frequent state jump between adjacent timestamps, and can
prohibit certain types of state jump. [0049] In an example dynamic algorithm , each timestamp corresponds to a frame. Each state of the algorithm corre
spondsto a heartbeat stage. The heart rate system determines
the state cost using the negative of the N score signals. The transition cost may permit self-transitions, transitions from
stage n - 1 to stage n , and transitions from stage N to stage
1 . The actual values of the transition costs can be determined heuristically or by some estimation schemes.
V . SYSTEM BLOCK DIAGRAMS
[0050 ] The systemsdescribed herein can use deep learning
algorithms for physical heart rate monitors based on ultra
sound sensors, optical sensors/transducers, or other types of
sensor technologies . FIG . 10 is a block diagram of a heart
rate system 1000 using ultrasound sensors according to one
embodiment. FIG . 11 is a block diagram of a heart rate system 1100 including optical sensors according to one
embodiment.

US 2018 /0249964 A1

Sep . 6 , 2018

[0051] For the embodiment shown in FIG . 10, a target location for contact between the heart rate system 1100 and
a subject 1050 is the inner side of the wrist of the subject
1050, e.g., either at the Radial artery position or the Ulnar
artery position. The ultrasound transducer 1005may include
two piezoelectric (e .g., Lead Zirconate Titanate or PZT)
slabs; one PZT slab transmits ultrasound energy to thetarget
and another receives the reflected RF signal that carries the
pulsating blood flow information . An ultrasound frequency
is provided by the microcontroller 1030 as the Carrier
Frequency, which may drive both the ultrasound transducer
1005 and the mixer circuit 1015 . At the output of the mixer circuit 1015 is the Doppler signal in audio range that
contains the blood flow information, which may be passed
through a Butterworth amplifier 1020 . The mixer circuit
1015 removes the carrier frequency from the receiver PZT slab . [0052] In someembodiments, the A / D converter 1025 is a
high resolution (e.g., up to 24 -bit) and high sampling rate
(e.g.,up to 10 KHz)unit of either Sigma-Delta or Successive Approximation type. The microcontroller 1030 may be a high performance 16 -bit or 32-bit chip . External flash memory 1045 may store heart rate determinations. One or more display units 1040 or user interfaces 1035 may vary
between different types of devices worn on a wrist of the
subject 1050, e.g., watch, sleeve, or wristband .
[0053] For the embodiment shown in FIG . 11, a target
location for contact between the heart rate system 1100 and
a subject 1050 is the center of an outer side of the wrist of the subject 1050 . In one embodiment, there are two sets of
optical sensor modules (e.g., opticalmodule A 1055 and
optical module B 1065), each containing a light- emitting diode (LED ) and a photodetector. The wavelength of the light for each module is different; onewavelength is chosen
to optimize efficiency in absorption by the red blood cells
and the other is chosen for ambient light calibration and
compensation purposes. Thus, two input channels in the A /D
converter 125 may be required. In some embodiments , the
outputs of opticalmodule A 1055 and opticalmodule B 1065 may pass through amplifier A 1060 and amplifier B 1070 ,
respectively, before being input to the A/D converter 1025.
VI. ADDITIONAL CONSIDERATIONS
[0054 ] The foregoing description of the embodiments of
the invention has been presented for the purpose of illus
tration ; it is not intended to be exhaustive or to limit the
invention to the precise forms disclosed . Persons skilled in the relevant art can appreciate that many modifications and
variations are possible in light of the above disclosure.
[0055] Some portions of this description describe the
embodiments of the invention in terms of algorithms and
symbolic representations of operations on information .
These algorithmic descriptions and representations are com
monly used by those skilled in the data processing arts to
convey the substance of their work effectively to others skilled in the art. These operations, while described func
tionally, computationally, or logically, are understood to be
implemented by computer programsor equivalent electrical
circuits, microcode, or the like. Furthermore, it has also proven convenient at times, to refer to these arrangements of
operations as modules, without loss of generality. The
described operations and their associated modules may be
embodied in software, firmware, hardware, or any combi
nations thereof.

[0056 ] Any ofthe steps, operations, or processes described herein may be performed or implemented with one or more
hardware or softwaremodules, alone or in combination with
other devices. In one embodiment, a software module is
implemented with a computer program product including a
computer-readable non -transitory medium containing com puter program code, which can be executed by a computer
processor for performing any or all of the steps, operations, or processes described .
[0057] Embodiments of the invention may also relate to a
product that is produced by a computing process described
herein . Such a product may include information resulting from a computing process, where the information is stored on a non-transitory, tangible computer readable storage
medium and may include any embodiment of a computer
program productorother data combination described herein .
[0058) Finally, the language used in the specification has
been principally selected for readability and instructional
purposes,and itmay not have been selected to delineate or
circumscribe the inventive subject matter. It is therefore
intended that the scope ofthe invention be limited notby this detailed description, but rather by any claims that issue on
an application based hereon. Accordingly, the disclosure of
the embodiments of the invention is intended to be illustra tive, but not limiting, of the scope of the invention, which is
set forth in the following claims.
What is claimed is: 1. A method for determining a heart rate of a subject, comprising the steps of:
obtaining temporal sensor data generated by a sensor
worn by the subject, the temporal sensor data repre
sented by a plurality of frames of data samples ; generating, for each frame of the plurality of frames, a
feature vector based on a frequency domain represen
tation of the corresponding data samples ofthe frame; inputting the feature vectors to a model to generate a
series of heartbeat determinations of the subject for
each frame of the plurality of frames , wherein the model comprises a first set of parameters and associ
ated weights that represent likelihoods ofheartbeats of
the subject as a function of time; and providing the heart rate of the subject determined based
on the series of heartbeat determinations. 2 . The method of claim 1, further comprising: inputting the feature vectors to a scenario classifier to
determine a scenario of a plurality of scenarios for the
temporal sensor data , wherein the scenario classifier comprises a second set of parameters and associated
weights that represent likelihoods of the temporal sen sor data corresponding to each of the plurality of
scenarios; and
identifying the model from a plurality of trained models
based on the determined wseclelnaarrlioo ..
3. The method of claim 2, wherein the plurality of
scenarios includes at least a first scenario and a second
scenario , the first scenario associated with a first set of one
or more types of athletic activity and corresponding with a
first average signal-to-noise ratio of temporal sensor data,
the second scenario associated with a second set of one or
more types of athletic activity and corresponding with a
second average signal-to -noise ratio of temporal sensor data
greater than the first average signal-to -noise ratio .
4 . The method of claim 3 , wherein the first set of one or
more types of athletic activity includes at least one of

US 2018 /0249964 A1

Sep . 6 , 2018

jogging and running, and wherein the second set of one or
more types ofathletic activity includes walking.
5 . The method of claim 1 , further comprising : inputting the feature vectors to a scenario classifier to
determine a set of weights for a plurality of scenarios for the temporal sensor data , wherein the scenario
classifier comprises a second set of parameters and
associated weights that represent likelihoods of the
temporal sensor data corresponding to each of the
plurality of scenarios .
6. Themethod of claim 5,wherein each of the plurality of
scenarios is associated with one of a plurality of models including themodel, wherein each ofthe plurality ofmodels comprises a corresponding set of parameters and associated
weights that represent likelihoods of heartbeats of the sub ject as a function of time, and wherein themethod further
comprises :
determining the heart rate of the subject by applying the set of weights to outputs of the plurality of models.
7 . The method of claim 1 , wherein the first set of parameters and associated weights represent likelihoods of
heartbeats for each heartbeat stage of a plurality ofheartbeat
stages, and wherein the model generates the series ofheart
beat determinations using a cost function that penalizes
transitions between stages of the plurality of heartbeat
stages .
8. The method of claim 7, further comprising:
identifying from the series of heartbeat determinations,
one or more transitions between the stages of the
plurality of heartbeat stages; and determining the heart rate of the subject based at least in
part on a duration in time of the one ormore transitions. 9 . The method of claim 8 , wherein the plurality of
heartbeat stages includes at least a first heartbeat stage, a
second heartbeat stage, and a third heartbeat stage , and
wherein the one or more transitions includes (i) a first
transition from the first heartbeat stage to the second heart
beat stage and ( ii ) a second transition from the second
heartbeat stage to the third heartbeat stage.
10 . The method of claim 9 , wherein the duration in time
is from a start timestamp ofthe firstheartbeat stage to an end
timestamp of the third heartbeat stage .
11. The method of claim 1, wherein themodel is trained
using feature vectors based on reference signals generated
by electrocardiogram sensors worn on subjects, and wherein each of the reference signals is associated with a sensor
signal generated by other sensors worn on the subjects simultaneously with the corresponding reference signal.
12 . Themethod of claim 11, wherein the modelis trained further using label signals that indicate the presence of
heartbeats at timestamps of the reference signals .
13 . The method of claim 12, wherein the label signals
indicate the presence of heartbeat stages of a plurality of
heartbeat stages at the timestamps of the reference signals.
14. The method of claim 11, wherein the electrocardio
gram sensors are coupled to a chest strap . 15 . The method of claim 1 , wherein the other sensors
include at least one of an ultrasound sensor, an optical sensor, and a force sensor.
16 . The method of claim 1 , wherein the sensor worn by
the subject is not configured to be worn on a chest of the
subject.
17. The method of claim 1,wherein each of the plurality
of frames includes at least 256 of the data samples.

18. Themethod of claim 1, wherein the model is trained using a plurality of tokens including consecutive overlap
ping subsets of feature vectors .
19 . The method of claim 1 , wherein the model is a
long-short term memory (LSTM ) type neural network,
includes 2 hidden layers, and includes 64 hidden nodes in each LSTM unit of themodel.
20 . The method of claim 19 , wherein the model uses softmax as an output activation function , and wherein the
model uses a hyperbolic tangent as an activation function for
the hidden nodes. 21. The method of claim 1, further comprising:
determining one or more heartbeats of the subject not
identified by the series of heartbeat determinations by
applying at least one of a smoothing algorithm or an
adaptive threshold algorithm ; and wherein the heart rate of the subject is determined further
based on the one or more heartbeats .
22. The method of claim 1, further comprising:
determining an atrial fibrillation diagnosis for the subject
based on the series of heartbeat determinations .
23. The method of claim 1, further comprising:
determining a variability ofa plurality ofheart ratesofthe
subject based on the series of heartbeat determinations. 24 . A computer program product comprising a non
transitory computer readable storage medium having
instructions encoded thereon that, when executed by a
processor, cause the processor to :
obtain temporal sensor data generated by a sensor worn by a subject, the temporal sensor data represented by a
plurality of frames of data samples;
generate, for each frame of the plurality of frames, a feature vector based on a frequency domain represen tation of the corresponding data samples of the frame;
inputthe feature vectors to amodel to generate a series of heartbeat determinations of the subject for each frame
of the plurality of frames, wherein the model comprises a first set of parameters and associated weights that
represent likelihoods of heartbeats of the subject as a
function of time; and
provide a heartrate of the subject determined based on the series ofheartbeat determinations.
25 . A system comprising : a sensor configured to be worn by a subject and generate
temporal sensor data represented by a plurality of
frames of data samples;
a non -transitory computer readable storage medium hav
ing instructions encoded thereon that, when executed
by a processor, cause the processor to:
obtain the temporal sensor data from the sensor ;
generate, for each frame of the plurality of frames, a
feature vector based on a frequency domain repre sentation of the corresponding data samples of the
frame; input the feature vectors to a model to generate a series
of heartbeat determinations of the subject for each frame of the plurality of frames, wherein the model comprises a first set of parameters and associated
weights that represent likelihoods of heartbeats of the subject as a function of time; and
provide a heart rate of the subjectdetermined based on the series of heartbeat determinations.
*****

